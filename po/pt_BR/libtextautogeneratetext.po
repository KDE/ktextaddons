# Copyright (C) 2025 This file is copyright:
# This file is distributed under the same license as the ktextaddons package.
#
# SPDX-FileCopyrightText: 2025 Marcus Gama <marcus.gama@gmail.com>
msgid ""
msgstr ""
"Project-Id-Version: ktextaddons\n"
"Report-Msgid-Bugs-To: https://bugs.kde.org\n"
"POT-Creation-Date: 2025-08-15 00:43+0000\n"
"PO-Revision-Date: 2025-08-13 14:40-0300\n"
"Last-Translator: Marcus Gama <marcus.gama@gmail.com>\n"
"Language-Team: Brazilian Portuguese <kde-i18n-pt_BR@kde.org>\n"
"Language: pt_BR\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
"X-Generator: Lokalize 25.04.3\n"

#: core/models/textautogeneratechatsmodel.cpp:78
#, kde-format
msgid "New Chat..."
msgstr "Novo bate-papo..."

#: core/models/textautogeneratechatsmodel.cpp:150
#, kde-format
msgid "Favorite"
msgstr "Favoritos"

#: core/models/textautogeneratechatsmodel.cpp:152
#, kde-format
msgid "Today"
msgstr "Hoje"

#: core/models/textautogeneratechatsmodel.cpp:154
#, kde-format
msgid "7 days previous"
msgstr "7 dias anteriores"

#: core/models/textautogeneratechatsmodel.cpp:156
#, kde-format
msgid "30 days previous"
msgstr "30 dias anteriores"

#: core/models/textautogeneratechatsmodel.cpp:158
#, kde-format
msgid "Later"
msgstr "Mais tarde"

#: core/models/textautogeneratechatsmodel.cpp:160
#, kde-format
msgid "Unknown"
msgstr "Desconhecido"

#: core/models/textautogeneratemessagesmodel.cpp:70
#, kde-format
msgid ""
"Engine: %1\n"
"Model: %2\n"
"Instance Name: %3"
msgstr ""
"Motor: %1\n"
"Modelo: %2\n"
"Nome da instância: %3"

#: core/textautogeneratesearchmessageutils.cpp:35
#, kde-format
msgid "Go to message"
msgstr "Ir para a mensagem"

#: core/textautogeneratesettings.cpp:44
#, kde-format
msgid ""
"You are an AI assistant. You are speaking to a person named %1. Be helpful, "
"professional, and courteous. Do not give inaccurate information."
msgstr ""
"Você é um assistente de IA. Você está falando com uma pessoa chamada %1. "
"Seja prestativo, profissional e cortês. Não forneça informações imprecisas."

#: core/textautogeneratetextplugin.cpp:241
#, kde-format
msgid "Local"
msgstr "Local"

#: core/textautogeneratetextplugin.cpp:243
#, kde-format
msgid "Network"
msgstr "Rede"

#: plugins/genericnetworkplugin/genericnetworkclient.cpp:29
#, kde-format
msgid "Generic"
msgstr "Genérico"

#: plugins/genericnetworkplugin/genericnetworkconfiguredialog.cpp:28
#, kde-format
msgctxt "@title:window"
msgid "Configure %1"
msgstr "Configurar %1"

#: plugins/genericnetworkplugin/genericnetworkconfiguredialog.cpp:31
#: plugins/ollama/ollamaconfiguredialog.cpp:49
#, kde-format
msgctxt "@title Preferences page name"
msgid "General"
msgstr "Geral"

#: plugins/genericnetworkplugin/genericnetworkconfiguredialog.cpp:36
#: plugins/ollama/ollamaconfiguredialog.cpp:54
#, kde-format
msgctxt "@title Preferences page name"
msgid "Available Models"
msgstr "Modelos disponíveis"

#: plugins/genericnetworkplugin/genericnetworkmanager.cpp:48
#: plugins/ollama/ollamamanager.cpp:166
#, kde-format
msgid "Failed to connect to interface at %1: %2"
msgstr "Falha ao conectar-se ao servidor em %1: %2"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:24
#, kde-format
msgid "Mistral AI"
msgstr "IA Mistral"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:26
#, kde-format
msgid "OpenAI"
msgstr "OpenAI"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:28
#, kde-format
msgid "Kluster AI"
msgstr "IA Kluster"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:30
#, kde-format
msgid "Groq Cloud"
msgstr "Nuvem Groq"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:32
#, kde-format
msgid "Cerebras AI"
msgstr "IA Cerebras"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:34
#, kde-format
msgid "Venice"
msgstr "Venice"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:36
#, kde-format
msgid "Llama Api"
msgstr "API do Llama"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:38
#, kde-format
msgid "Anthropic"
msgstr "Antrópico"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:129
#, kde-format
msgid "Mistral AI large language models"
msgstr "Modelos de linguagem grandes da IA Mistral"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:136
#, kde-format
msgid "Kluster AI cloud inference API"
msgstr "API de inferência da nuvem da IA Kluster"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:138
#, kde-format
msgid "Cerebras AI cloud inference API"
msgstr "API de inferência da nuvem da IA Cerebras"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:140
#, kde-format
msgid "Meta AI Llama API"
msgstr "API do Llama para a IA do Meta"

#: plugins/ollama/modelsmanager/ollamamodelavailabledialog.cpp:28
#, kde-format
msgctxt "@title:window"
msgid "Manage Ollama Models"
msgstr "Gerenciar modelos Ollama"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:83
#, kde-format
msgid "Tools"
msgstr "Ferramentas"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:85
#, kde-format
msgid "Small"
msgstr "Pequena"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:87
#, kde-format
msgid "Medium"
msgstr "Média"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:89
#, kde-format
msgid "Big"
msgstr "Grande"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:91
#, kde-format
msgid "Huge"
msgstr "Gigante"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:93
#, kde-format
msgid "Multilingual"
msgstr "Multilíngue"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:95
#, kde-format
msgid "Code"
msgstr "Código"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:97
#, kde-format
msgid "Math"
msgstr "Matemática"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:99
#, kde-format
msgid "Vision"
msgstr "Visão"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:101
#, kde-format
msgid "Embedding"
msgstr "Incorporação"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:103
#, kde-format
msgid "Reasoning"
msgstr "Raciocínio"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfowidget.cpp:47
#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:104
#, kde-format
msgid "Languages Supported"
msgstr "Idiomas suportados"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfowidget.cpp:61
#, kde-format
msgid "Models"
msgstr "Modelos"

#: plugins/ollama/modelsmanager/ollamamodelavailablesearchwidget.cpp:39
#, kde-format
msgctxt "@info:tooltip"
msgid "Add Model"
msgstr "Adicionar modelo"

#: plugins/ollama/modelsmanager/ollamamodelcategoriesmodel.cpp:41
#, kde-format
msgid "Categories"
msgstr "Categorias"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:31
#, kde-format
msgid "Base:"
msgstr "Base:"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:34
#: plugins/ollama/ollamaconfigurewidget.cpp:46
#: widgets/networkpluginconfigure/textautogeneratenetworkpluginconfigurewidget.cpp:47
#, kde-format
msgid "Name:"
msgstr "Nome:"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:37
#, kde-format
msgid "Tag:"
msgstr "Etiqueta:"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:40
#, kde-format
msgid "Prompt:"
msgstr "Prompt:"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:45
#, kde-format
msgctxt "@action:button"
msgid "Create"
msgstr "Criar"

#: plugins/ollama/modelsmanager/ollamamodelcreatewidget.cpp:41
#, kde-format
msgctxt "@action:button"
msgid "Load GGUF File…"
msgstr "Carregar arquivo GGUF..."

#: plugins/ollama/modelsmanager/ollamamodelcreatewidget.cpp:45
#, kde-format
msgctxt "@title:window"
msgid "Select GGUF File"
msgstr "Selecionar arquivo GGUF"

#: plugins/ollama/modelsmanager/ollamamodelcreatewidget.cpp:51
#, kde-format
msgctxt "@action:button"
msgid "Create Model"
msgstr "Criar modelo"

#: plugins/ollama/modelsmanager/ollamamodeldownloadfromnamedialog.cpp:19
#, kde-format
msgctxt "@title:window"
msgid "Download Model"
msgstr "Baixar modelo"

#: plugins/ollama/modelsmanager/ollamamodeldownloadfromnamewidget.cpp:23
#, kde-format
msgid "Please enter model name as \"name:tag\""
msgstr "Digite o nome do modelo como \"nome:etiqueta\""

#: plugins/ollama/modelsmanager/ollamamodeldownloadprogresswidget.cpp:47
#: widgets/view/textautogeneratelistviewdelegate.cpp:389
#, kde-format
msgctxt "@info:tooltip"
msgid "Cancel"
msgstr "Cancelar"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:26
#, kde-format
msgid "Family:"
msgstr "Família:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:35
#, kde-format
msgid "Parameter Size:"
msgstr "Tamanho do parâmetro:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:44
#, kde-format
msgid "Quantization Level:"
msgstr "Nível de quantização:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:53
#, kde-format
msgid "Modified At:"
msgstr "Modificado em:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:88
#, kde-format
msgid "Parent Model:"
msgstr "Modelo pai:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:126
#, kde-format
msgid "Features Supported"
msgstr "Recursos suportados"

#: plugins/ollama/modelsmanager/ollamamodelinstalledwidget.cpp:108
#, kde-format
msgid "Do you want to remove this model (%1)?"
msgstr "Deseja remover este modelo (%1)?"

#: plugins/ollama/modelsmanager/ollamamodelinstalledwidget.cpp:109
#, kde-format
msgctxt "@title"
msgid "Remove Model"
msgstr "Remover modelo"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:17
#, kde-format
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to the Llama 3.1 405B model."
msgstr ""
"Novo modelo 70B de última geração. O Llama 3.3 70B oferece desempenho "
"semelhante ao modelo Llama 3.1 405B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:18
#, kde-format
msgid "QwQ is the reasoning model of the Qwen series."
msgstr "QwQ é o modelo de raciocínio das séries Qwen."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:19
#, kde-format
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""
"O Llama 3.2 Vision é uma coleção de modelos generativos de raciocínio por "
"imagem ajustados por instruções, nos tamanhos 11B e 90B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:20
#, kde-format
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr "O Llama 3.2 da Meta fica pequeno com modelos 1B e 3B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:21
#, kde-format
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr ""
"O Llama 3.1 é um novo modelo de última geração da Meta, disponível nos "
"tamanhos de parâmetros 8B, 70B e 405B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:22
#, kde-format
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3: O LLM mais capaz e disponível abertamente até o momento"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:23
#, kde-format
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr "O modelo 7B lançado pela Mistral AI, atualizado para a versão 0.3."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:24
#, kde-format
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr ""
"Um modelo de incorporação aberta de alto desempenho com uma grande janela de "
"contexto de token."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:25
#, kde-format
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr ""
"Gemma é uma família de modelos abertos leves e de última geração, "
"desenvolvidos pelo Google DeepMind. Atualizado para a versão 1.1"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:26
#, kde-format
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr ""
"Qwen 1.5 é uma série de grandes modelos de linguagem do Alibaba Cloud "
"abrangendo dos parâmetros 0,5B a 110B"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:27
#, kde-format
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr ""
"Qwen2 é uma nova série de grandes modelos de linguagem do grupo Alibaba"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:28
#, kde-format
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 é uma família de modelos abertos de última geração, leves, 3B (Mini) e "
"14B (Médio), da Microsoft."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:29
#, kde-format
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr ""
"Llama 2 é uma coleção de modelos de linguagem de base que variam dos "
"parâmetros 7B a 70B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:31
#, kde-format
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""
"Os modelos Qwen2.5 são pré-treinados com base no mais recente conjunto de "
"dados de larga escala do Alibaba, abrangendo até 18 trilhões de tokens. O "
"modelo suporta até 128 mil tokens e oferece suporte multilíngue."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:33
#, kde-format
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr ""
"O Google Gemma 2 é um modelo eficiente e de alto desempenho, disponível em "
"três tamanhos: 2B, 9B e 27B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:35
#, kde-format
msgid ""
"LLaVA is a novel end-to-end trained large multimodal model that combines a "
"vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"LLaVA é um novo modelo multimodal de grande porte, treinado de ponta a "
"ponta, que combina um codificador de visão e Vicunha para compreensão visual "
"e de linguagem de uso geral. Atualizado para a versão 1.6."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:37
#, kde-format
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr ""
"Um grande modelo de linguagem que pode usar prompts de texto para gerar e "
"discutir código."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:39
#, kde-format
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""
"A mais recente série de modelos Qwen específicos de código, com melhorias "
"significativas na geração, raciocínio e correção de código."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:40
#, kde-format
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr ""
"Um modelo 12B de última geração com comprimento de contexto de 128k, "
"desenvolvido pela IA da Mistral em colaboração com a NVIDIA."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:41
#, kde-format
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"O projeto TinyLlama é um esforço aberto para treinar um modelo Llama 1.1B "
"compacto em 3 trilhões de tokens."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:42
#, kde-format
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "Modelo de incorporação grande de última geração da mixedbread.ai"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:44
#, kde-format
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 é a próxima geração de LLMs de código aberto com treinamento "
"transparente que vem em três tamanhos: parâmetros 3B, 7B e 15B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:45
#, kde-format
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"Um conjunto de modelos de Mistura de Especialistas (MoE) com pesos abertos "
"da IA Mistral em tamanhos de parâmetros 8x7b e 8x22b."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:47
#, kde-format
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"Modelos 8x7b e 8x22b sem censura, ajustados com precisão, baseados na "
"mistura de modelos de especialistas da Mixtral, que se destacam em tarefas "
"de codificação. Criado por Eric Hartford."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:50
#, kde-format
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"O CodeGemma é uma coleção de modelos leves e poderosos que podem executar "
"uma variedade de tarefas de codificação, como preenchimento de código "
"intermediário, geração de código, compreensão de linguagem natural, "
"raciocínio matemático e seguimento de instruções."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:53
#, kde-format
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"Um modelo de linguagem de código de Mistura de Especialistas de código "
"aberto que alcança desempenho comparável ao GPT4-Turbo em tarefas "
"específicas de código."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:54
#, kde-format
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr ""
"Phi-2: um modelo de linguagem 2.7B da Microsoft Research que demonstra "
"excelentes capacidades de raciocínio e compreensão da linguagem."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:55
#, kde-format
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "Modelo Llama 2 sem censura por George Sung e Jarrad Hope."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:56
#, kde-format
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"O DeepSeek Coder é um modelo de codificação capaz, treinado em dois trilhões "
"de códigos e tokens de linguagem natural."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:57
#, kde-format
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr ""
"Um conjunto de modelos de incorporação de texto da Snowflake, otimizados "
"para desempenho."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:59
#, kde-format
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"Modelo de linguagem de última geração da IA da Microsoft com desempenho "
"aprimorado em chats complexos, multilíngues, raciocínio e casos de uso de "
"agentes."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:61
#, kde-format
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr ""
"O modelo Dolphin sem censura baseado no Mistral, que se destaca em tarefas "
"de codificação. Atualizado para a versão 2.8."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:63
#, kde-format
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"O Dolphin 2.9 é um novo modelo com tamanhos 8B e 70B, desenvolvido por Eric "
"Hartford e baseado no Llama 3, que oferece uma variedade de habilidades de "
"instrução, conversação e codificação."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:65
#, kde-format
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 é um modelo de linguagem bilíngue de alto desempenho."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:66
#, kde-format
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr ""
"O Command R é um modelo de linguagem grande otimizado para interação "
"conversacional e tarefas de contexto longo."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:67
#, kde-format
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr ""
"Um modelo de uso geral que varia de 3 a 70 bilhões de parâmetros, adequado "
"para hardware de nível básico."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:68
#, kde-format
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr ""
"Um modelo LLaVA aprimorado a partir do Llama 3 Instruct com melhores "
"pontuações em vários benchmarks."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:69
#, kde-format
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr é uma série de versões aprimoradas dos modelos Mistral e Mixtral que "
"são treinados para atuar como assistentes úteis."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:70
#, kde-format
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr ""
"Um modelo de IA leve com 3,8 bilhões de parâmetros com desempenho superando "
"modelos semelhantes e de tamanho maior."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:71
#, kde-format
msgid "Embedding models on very large sentence level datasets."
msgstr ""
"Incorporação de modelos em conjuntos de dados muito grandes em nível de "
"frases."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:72
#, kde-format
msgid ""
"Codestral is Mistral AI’s first-ever code model designed for code generation "
"tasks."
msgstr ""
"Codestral é o primeiro modelo de código da IA da Mistral projetado para "
"tarefas de geração de código."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:73
#, kde-format
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr ""
"StarCoder é um modelo de geração de código treinado em mais de 80 linguagens "
"de programação."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:74
#, kde-format
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr ""
"Modelo de bate-papo de uso geral baseado em Llama e Llama 2 com tamanhos de "
"contexto de 2K a 16K."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:75
#, kde-format
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr "Uma família de modelos de base aberta da IBM para Code Intelligence"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:76
#, kde-format
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"O Mistral OpenOrca é um modelo de 7 bilhões de parâmetros, ajustado com base "
"no modelo Mistral 7B usando o conjunto de dados OpenOrca."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:77
#, kde-format
msgid ""
"A family of small models with 135M, 360M, and 1.7B parameters, trained on a "
"new high-quality dataset."
msgstr ""
"Uma família de pequenos modelos com parâmetros de 135M, 360M e 1,7B, "
"treinados em um novo conjunto de dados de alta qualidade."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:78
#, kde-format
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored é um modelo de parâmetros 7B, 13B e 30B baseado em "
"Llama 2 sem censura de Eric Hartford."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:79
#, kde-format
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr ""
"Modelo baseado no Llama 2 ajustado para melhorar a capacidade de diálogo em "
"chinês."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:81
#, kde-format
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr ""
"O BGE-M3 é um novo modelo da BAAI que se destaca pela sua versatilidade em "
"multifuncionalidade, multilinguidade e multigranularidade."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:82
#, kde-format
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr ""
"Um modelo versátil para cenários de desenvolvimento de software de IA, "
"incluindo completamento de código."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:84
#, kde-format
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"Uma família de modelos de código aberto treinados em uma ampla variedade de "
"dados, superando o ChatGPT em vários benchmarks. Atualizado para a versão "
"3.5-0106."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:85
#, kde-format
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr ""
"O Aya 23, lançado pela Cohere, é uma nova família de modelos multilíngues de "
"última geração que oferecem suporte a 23 idiomas."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:86
#, kde-format
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr ""
"CodeQwen1.5 é um grande modelo de linguagem pré-treinado com uma grande "
"quantidade de dados de código."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:87
#, kde-format
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr ""
"A poderosa família de modelos da Nous Research que se destaca em discussões "
"científicas e tarefas de codificação."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:88
#, kde-format
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"O Command R+ é um modelo de linguagem poderoso, escalável e de grande porte, "
"desenvolvido especificamente para se destacar em casos de uso corporativo do "
"mundo real."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:89
#, kde-format
msgid "State-of-the-art code generation model"
msgstr "Modelo de geração de código de última geração"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:91
#, kde-format
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"O Código Estável 3B é um modelo de codificação com variantes de instrução e "
"conclusão de código no mesmo nível de modelos como o Code Llama 7B, que são "
"2,5 vezes maiores."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:92
#, kde-format
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"Um modelo experimental de 1,1B de parâmetros treinado no novo conjunto de "
"dados Dolphin 2.8 por Eric Hartford e baseado no TinyLlama."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:93
#, kde-format
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"O OpenHermes 2.5 é um modelo 7B aprimorado pela Teknium no Mistral com "
"conjuntos de dados totalmente abertos."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:95
#, kde-format
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""
"O Mistral Large 2 é o novo modelo principal da Mistral, que é "
"significativamente mais capaz de gerar código, realizar cálculos matemáticos "
"e raciocinar, com janela de contexto de 128k e suporte para dezenas de "
"idiomas."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:98
#, kde-format
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""
"Qwen2 Math é uma série de modelos de linguagem matemática especializados, "
"desenvolvidos com base nos Qwen2 LLMs, que superam significativamente as "
"capacidades matemáticas de modelos de código aberto e até mesmo de modelos "
"de código fechado (por exemplo, GPT4o)."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:100
#, kde-format
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr ""
"Um forte modelo de linguagem geral multilíngue com desempenho competitivo "
"para o Llama 3."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:102
#, kde-format
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"O Stable LM 2 é um modelo de linguagem de parâmetros 1.6B e 12B de última "
"geração treinado com dados multilíngues em inglês, espanhol, alemão, "
"italiano, francês, português e holandês."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:104
#, kde-format
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr ""
"BakLLaVA é um modelo multimodal que consiste no modelo base Mistral 7B "
"aumentado com a arquitetura LLaVA."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:106
#, kde-format
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""
"Um modelo de alto desempenho treinado com uma nova técnica chamada "
"Reflection- tuning, que ensina um LLM a detectar erros em seu raciocínio e "
"corrigir o curso."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:108
#, kde-format
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr ""
"Um modelo de linguagem avançado criado com 2 trilhões de tokens bilíngues."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:109
#, kde-format
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr ""
"Este modelo amplia o comprimento de contexto do LLama-3 8B de 8 mil para "
"mais de 1 milhão de tokens."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:110
#, kde-format
msgid "Model focused on math and logic problems"
msgstr "Modelo focado em problemas de matemática e lógica"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:111
#, kde-format
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr ""
"O moondream2 é um pequeno modelo de linguagem de visão projetado para rodar "
"eficientemente em dispositivos de ponta."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:112
#, kde-format
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr ""
"Um modelo aprimorado baseado em Mistral com boa cobertura de domínio e "
"linguagem."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:114
#, kde-format
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"Um modelo da NVIDIA baseado no Llama 3 que se destaca na resposta a "
"perguntas conversacionais (QA) e na geração de recuperação aumentada (RAG)."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:115
#, kde-format
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr ""
"Modelo de conversação baseado no Llama 2 com desempenho competitivo em "
"vários benchmarks."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:116
#, kde-format
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr ""
"SQLCoder é um modelo de complementação de código aprimorado no StarCoder "
"para tarefas de geração de SQL"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:117
#, kde-format
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr "Modelos de uso geral baseados em Llama e Llama 2 da Nous Research."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:118
#, kde-format
msgid "Code generation model based on Code Llama."
msgstr "Modelo de geração de código baseado no Code Llama."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:119
#, kde-format
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr "Uma extensão do Llama 2 que suporta um contexto de até 128 mil tokens."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:120
#, kde-format
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr ""
"Uma variante sem censura 7B e 15B da família de modelos Dolphin que se "
"destaca na codificação, baseada no StarCoder2."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:121
#, kde-format
msgid "General use model based on Llama 2."
msgstr "Modelo de uso geral baseado no Llama 2."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:122
#, kde-format
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr ""
"Um modelo de linguagem forte de mistura de especialistas, econômico e "
"eficiente."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:124
#, kde-format
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling é um grande modelo de linguagem treinado por aprendizado de reforço "
"a partir de feedback de IA com foco em melhorar a utilidade do chatbot."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:125
#, kde-format
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr ""
"Uma assistente de companhia treinada em filosofia, psicologia e "
"relacionamentos pessoais. Baseada em Mistral."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:126
#, kde-format
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr ""
"Hermes 3 é a versão mais recente da principal série de LLMs da Hermes, da "
"Nous Research"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:128
#, kde-format
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""
"Yi-Coder é uma série de modelos de linguagem de código aberto que oferece "
"desempenho de codificação de última geração com menos de 10 bilhões de "
"parâmetros."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:131
#, kde-format
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""
"Um grande modelo de linguagem desenvolvido pelo Instituto de Inovação "
"Tecnológica (TII) para uso em sumarização, geração de texto e bots de bate-"
"papo."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:132
#, kde-format
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr ""
"O InternLM2.5 é um modelo de parâmetro 7B desenvolvido para cenários "
"práticos comexcelente capacidade de raciocínio."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:133
#, kde-format
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr ""
"Um modelo de linguagem grande, compacto, porém poderoso, de 10,7 bilhões de "
"caracteres, projetado para conversas em um único turno."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:134
#, kde-format
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""
"Athene-V2 é um modelo de parâmetro 72B que se destaca em tarefas de "
"complementação de código, matemática e extração de logs."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:135
#, kde-format
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr "Um novo modelo pequeno de LLaVA aprimorado a partir do Phi 3 Mini."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:137
#, kde-format
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"O Orca 2 foi desenvolvido pela Microsoft Research e é uma versão aprimorada "
"dos modelos Llama 2 da Meta. O modelo foi projetado para se destacar, "
"principalmente em raciocínio."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:139
#, kde-format
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr ""
"Uma série de LLMs multimodais (MLLMs) projetados para compreensão da visão e "
"da linguagem."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:140
#, kde-format
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"Modelo baseado no Llama 2, ajustado com precisão em um conjunto de dados do "
"tipo Orca. Originalmente chamado de Free Willy."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:141
#, kde-format
msgid ""
"Mistral Small 3 sets a new benchmark in the “small” Large Language Models "
"category below 70B."
msgstr ""
"O Mistral Small 3 estabelece um novo padrão na categoria \"pequenos\" "
"Modelos de Linguagem Grande abaixo de 70B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:142
#, kde-format
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"Modelo Dolphin 2.7B sem censura de Eric Hartford, baseado no modelo de "
"linguagem Phi da Microsoft Research."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:143
#, kde-format
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""
"SmolLM2 é uma família de modelos de linguagem compactos disponíveis em três "
"tamanhos: parâmetros de 135M, 360M e 1,7B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:144
#, kde-format
msgid "Uncensored version of Wizard LM model"
msgstr "Versão sem censura do modelo Wizard LM"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:145
#, kde-format
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""
"Um pequeno modelo de linguagem comercial da NVIDIA otimizado para roleplay, "
"RAG QA e chamada de função."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:146
#, kde-format
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr ""
"Uma extensão do Mistral para suportar janelas de contexto de 64K ou 128K."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:148
#, kde-format
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"Uma expansão do Llama 2 especializada na integração da compreensão geral da "
"linguagem e do conhecimento específico de um domínio, particularmente em "
"programação e matemática."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:150
#, kde-format
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr ""
"Modelo Llama 2 aprimorado para responder a perguntas médicas com base em um "
"conjunto de dados médicos de código aberto."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:151
#, kde-format
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr ""
"Modelo de linguagem médica de código aberto adaptado do Llama 2 para o "
"domínio médico."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:153
#, kde-format
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""
"Uma série de modelos da Groq que representam um avanço significativo nos "
"recursos de IA de código aberto para uso de ferramentas/chamada de funções."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:155
#, kde-format
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""
"Llama-3.1-Nemotron-70B-Instruct é um grande modelo de linguagem "
"personalizado pela NVIDIA para melhorar a utilidade das respostas geradas "
"pelo LLM às consultas dos usuários."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:157
#, kde-format
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr ""
"Nexus Raven é um modelo ajustado de instruções 13B para tarefas de chamada "
"de função."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:158
#, kde-format
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr "O modelo Nous Hermes 2 da Nous Research, agora treinado no Mixtral."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:159
#, kde-format
msgid "Great code generation model based on Llama2."
msgstr "Ótimo modelo de geração de código baseado no Llama2."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:160
#, kde-format
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr ""
"Modelo baseado em Llama2 sem censura com suporte para uma janela de contexto "
"de 16K."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:162
#, kde-format
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""
"Os modelos IBM Granite 2B e 8B foram projetados para oferecer suporte a "
"casos de uso baseados em ferramentas e suporte para geração aumentada de "
"recuperação (RAG), simplificando a geração de código, tradução e correção de "
"bugs."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:165
#, kde-format
msgid ""
"Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"Magicoder é uma família de 7B modelos de parâmetros treinados em 75K dados "
"de instruções sintéticas usando OSS-Instruct, uma nova abordagem para "
"esclarecer LLMs com trechos de código de código aberto."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:167
#, kde-format
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr ""
"Um modelo de bate-papo leve que permite uma saída precisa e responsiva sem "
"exigir hardware de última geração."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:168
#, kde-format
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr ""
"Um modelo de instrução de código de alto desempenho criado pela fusão de "
"dois modelos de código existentes."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:169
#, kde-format
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2 é um modelo decodificador causal de 11B parâmetros, construído pela "
"TII e treinado em 5T tokens."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:170
#, kde-format
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr ""
"Wizard Vicuna é um modelo de parâmetro 13B baseado no Llama 2 treinado por "
"MelodysDreamj."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:171
#, kde-format
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr ""
"MistralLite é um modelo aprimorado baseado no Mistral com capacidades "
"aprimoradas de processamento de contextos longos."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:172
#, kde-format
msgid ""
"MathΣtral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr ""
"MathΣtral: um modelo 7B projetado para raciocínio matemático e descoberta "
"científica pela IA da Mistral."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:173
#, kde-format
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr ""
"Modelo de texto para SQL de 7 parâmetros feito pela MotherDuck e Numbers "
"Station."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:174
#, kde-format
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b é uma transformação do Dolphin-2.2-70b criada pela "
"intercalação do modelo consigo mesmo."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:175
#, kde-format
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""
"Prévia do Solar Pro: um modelo avançado de grande linguagem (LLM) com 22 "
"bilhões de parâmetros projetados para caber em uma única GPU"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:176
#, kde-format
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""
"Uma série de modelos que convertem conteúdo HTML em conteúdo Markdown, o que "
"é útil para tarefas de conversão de conteúdo."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:177
#, kde-format
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr ""
"Uma mistura de modelos de especialistas de alto desempenho, ajustados com "
"dados de alta qualidade."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:178
#, kde-format
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr ""
"Um modelo de bate-papo 7B ajustado com dados de alta qualidade e baseado no "
"Zephyr."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:179
#, kde-format
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"Fusão do modelo OpenChat do Open Orca com o modelo Platypus 2 do Garage-"
"bAInd. Projetado para bate-papo e geração de código."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:180
#, kde-format
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr ""
"Um modelo de linguagem criado pela combinação de dois modelos Llama 2 70B "
"ajustados em um."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:182
#, kde-format
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"Os modelos IBM Granite 1B e 3B são a primeira combinação de especialistas "
"(MoE) Modelos Granite da IBM projetados para uso com baixa latência."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:183
#, kde-format
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""
"Um modelo 3.8B ajustado com precisão em um conjunto de dados sintéticos "
"privados de alta qualidade para extração de informações, com base em Phi-3."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:184
#, kde-format
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr ""
"Os modelos de linguagem do Cohere For AI foram treinados para ter um bom "
"desempenho em 23 idiomas diferentes."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:185
#, kde-format
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr "O DBRX é um LLM aberto e de uso geral criado pela Databricks."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:186
#, kde-format
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""
"Um modelo de raciocínio aberto e amplo para soluções do mundo real, "
"desenvolvido pelo Alibaba International Digital Commerce Group (AIDC-AI)."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:187
#, kde-format
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr "Incorporação de modelo de mapeamento de textos em vetores do BAAI."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:188
#, kde-format
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr ""
"Um modelo de chamada de função de pesos abertos baseado no Llama 3, "
"competitivo com os recursos de chamada de função do GPT-4o."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:189
#, kde-format
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr ""
"Um modelo de conversação robusto projetado para ser usado em casos de uso de "
"bate-papo e instrução."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:191
#, kde-format
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""
"Uma versão atualizada do DeekSeek-V2 que integra os recursos gerais e de "
"codificação do DeepSeek-V2-Chat e do DeepSeek-Coder-V2-Instruct."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:193
#, kde-format
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""
"ShieldGemma é um conjunto de modelos de instruções ajustadas para avaliar a "
"segurança de respostas de entrada e saída de texto em prompts de texto em "
"relação a um conjunto de políticas de segurança definidas."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:195
#, kde-format
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr ""
"Um modelo de verificação de fatos de última geração desenvolvido pela "
"Bespoke Labs."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:196
#, kde-format
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""
"O Llama Guard 3 é uma série de modelos aprimorados para classificação de "
"segurança de conteúdo de entradas e respostas do LLM."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:197
#, kde-format
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr ""
"Modelo de transformadores de frases que pode ser usado para tarefas como "
"agrupamento ou busca semântica."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:199
#, kde-format
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""
"OpenCoder é uma família de LLM de código aberto e reproduzível que inclui "
"modelos 1.5B e 8B, com suporte para chat em inglês e chinês."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:201
#, kde-format
msgid ""
"Tülu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""
"Tülu 3 é uma família líder de modelos de instruções, oferecendo dados, "
"códigos e receitas totalmente de código aberto do The Allen Institute for AI."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:203
#, kde-format
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""
"Modelo de incorporação de ponta da Snowflake. O Arctic Embed 2.0 adiciona "
"suporte multilíngue sem sacrificar o desempenho ou a escalabilidade do "
"inglês."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:204
#, kde-format
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr ""
"Os modelos IBM Granite Guardian 3.0 2B e 8B foram projetados para detectar "
"riscos em prompts e/ou respostas."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:206
#, kde-format
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""
"O EXAONE 3.5 é uma coleção de modelos generativos bilíngues (inglês e "
"coreano) ajustados por instruções, variando de 2,4 bilhões a 32 bilhões de "
"parâmetros, desenvolvidos e lançados pela LG AI Research."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:208
#, kde-format
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr ""
"Sailor2 são modelos multilíngues desenvolvidos para o Sudeste Asiático. "
"Disponível nos tamanhos de parâmetros 1B, 8B e 20B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:210
#, kde-format
msgid ""
"A family of efficient AI models under 10B parameters performant in science, "
"math, and coding through innovative training techniques."
msgstr ""
"Uma família de modelos de IA eficientes com parâmetros 10B, com alto "
"desempenho em ciências, matemática e codificação por meio de técnicas de "
"treinamento inovadoras."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:212
#, kde-format
msgid ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."
msgstr ""
"Os modelos IBM Granite 2B e 8B são LLMs densos somente em texto, treinados "
"em mais de 12 trilhões de tokens de dados, e demonstraram melhorias "
"significativas em relação aos seus predecessores em desempenho e velocidade "
"nos testes iniciais da IBM."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:215
#, kde-format
msgid ""
"The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"Os modelos IBM Granite 1B e 3B são uma mistura de especialistas de longo "
"contexto (MoE). Os modelos Granite da IBM foram projetados para uso com "
"baixa latência."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:217
#, kde-format
msgid ""
"The IBM Granite Embedding 30M and 278M models models are text-only dense "
"biencoder embedding models, with 30M available in English only and 278M "
"serving multilingual use cases."
msgstr ""
"Os modelos IBM Granite Embedding 30M e 278M são modelos de incorporação de "
"codificadores biencoder densos, com o 30M disponível apenas em inglês e o "
"278M atendendo a casos de uso multilíngues."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:219
#, kde-format
msgid "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft."
msgstr ""
"Phi-4 é um modelo aberto de última geração, com 14B parâmetros, da Microsoft."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:220
#, kde-format
msgid ""
"A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model."
msgstr ""
"Um novo modelo de raciocínio pequeno, aprimorado a partir do modelo Qwen 2.5 "
"3B Instruct."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:222
#, kde-format
msgid ""
"Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of "
"instruct-tuned models designed to be the ultimate general purpose local "
"model, enabling coding, math, agentic, function calling, and general use "
"cases."
msgstr ""
"Dolphin 3.0 Llama 3.1 8B 🐬 é a próxima geração da série Dolphin de modelos "
"ajustados por instrução, projetados para serem o modelo local de uso geral "
"definitivo, permitindo codificação, matemática, agentes, chamadas de funções "
"e casos de uso geral."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:225
#, kde-format
msgid ""
"DeepSeek's first-generation of reasoning models with comparable performance "
"to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on "
"Llama and Qwen."
msgstr ""
"Primeira geração de modelos de raciocínio do DeepSeek com desempenho "
"comparável ao OpenAI-o1, incluindo seis modelos densos extraídos do DeepSeek-"
"R1 com base em Llama e Qwen."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:227
#, kde-format
msgid ""
"A strong Mixture-of-Experts (MoE) language model with 671B total parameters "
"with 37B activated for each token."
msgstr ""
"Um forte modelo de linguagem de Mistura de Especialistas (MoE) com 671 "
"bilhões de parâmetros no total, com 37 bilhões ativados para cada token."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:229
#, kde-format
msgid ""
"OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. "
"These models are on par with or better than equivalently sized fully open "
"models, and competitive with open-weight models such as Llama 3.1 on English "
"academic benchmarks."
msgstr ""
"O OLMo 2 é uma nova família de modelos 7B e 13B treinados em tokens de até "
"5T. Esses modelos estão no mesmo nível ou são melhores do que modelos "
"totalmente abertos de tamanho equivalente e são competitivos com modelos de "
"peso aberto, como o Llama 3.1, em benchmarks acadêmicos de inglês."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:232
#, kde-format
msgid ""
"The smallest model in Cohere's R series delivers top-tier speed, efficiency, "
"and quality to build powerful AI applications on commodity GPUs and edge "
"devices."
msgstr ""
"O menor modelo da série R da Cohere oferece velocidade, eficiência e "
"qualidade de ponta para criar aplicativos de IA poderosos em GPUs comuns e "
"dispositivos de ponta."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:234
#, kde-format
msgid ""
"A fully open-source family of reasoning models built using a dataset derived "
"by distilling DeepSeek-R1."
msgstr ""
"Uma família de modelos de raciocínio totalmente de código aberto, construída "
"usando um conjunto de dados derivado da destilação do DeepSeek-R1."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:236
#, kde-format
msgid ""
"A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the "
"performance of OpenAI’s o1-preview with just 1.5B parameters on popular math "
"evaluations."
msgstr ""
"Uma versão aprimorada do Deepseek-R1-Distilled-Qwen-1.5B que supera o "
"desempenho do o1-preview da OpenAI com apenas 1,5 bilhão de parâmetros em "
"avaliações matemáticas populares."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:239
#, kde-format
msgid ""
"A version of the DeepSeek-R1 model that has been post trained to provide "
"unbiased, accurate, and factual information by Perplexity."
msgstr ""
"Uma versão do modelo DeepSeek-R1 que foi pós-treinada para fornecer "
"informações imparciais, precisas e factuais pela Perplexity."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:240
#, kde-format
msgid "The current, most capable model that runs on a single GPU."
msgstr "O modelo atual e mais capaz que roda em uma única GPU."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:242
#, kde-format
msgid ""
"Phi-4-mini brings significant enhancements in multilingual support, "
"reasoning, and mathematics, and now, the long-awaited function calling "
"feature is finally supported."
msgstr ""
"O Phi-4-mini traz melhorias significativas em suporte multilíngue, "
"raciocínio e matemática, e agora, o tão aguardado recurso de chamada de "
"função finalmente é suportado."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:245
#, kde-format
msgid ""
"A compact and efficient vision-language model, specifically designed for "
"visual document understanding, enabling automated content extraction from "
"tables, charts, infographics, plots, diagrams, and more."
msgstr ""
"Um modelo de visão e linguagem compacto e eficiente, projetado "
"especificamente para a compreensão visual de documentos, permitindo a "
"extração automatizada de conteúdo de tabelas, gráficos, infográficos, "
"gráficos, diagramas e muito mais."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:247
#, kde-format
msgid ""
"Granite-3.2 is a family of long-context AI models from IBM Granite fine-"
"tuned for thinking capabilities."
msgstr ""
"Granite-3.2 é uma família de modelos de IA de longo contexto da IBM Granite "
"ajustados para capacidades de pensamento."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:249
#, kde-format
msgid ""
"A new state-of-the-art version of the lightweight Command R7B model that "
"excels in advanced Arabic language capabilities for enterprises in the "
"Middle East and Northern Africa."
msgstr ""
"Uma nova versão de última geração do modelo leve Command R7B que se destaca "
"em recursos avançados de idioma árabe para empresas no Oriente Médio e Norte "
"da África."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:251
#, kde-format
msgid ""
"111 billion parameter model optimized for demanding enterprises that require "
"fast, secure, and high-quality AI"
msgstr ""
"Modelo de 111 bilhões de parâmetros otimizado para empresas exigentes que "
"exigem IA rápida, segura e de alta qualidade"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:253
#, kde-format
msgid ""
"EXAONE Deep exhibits superior capabilities in various reasoning tasks "
"including math and coding benchmarks, ranging from 2.4B to 32B parameters "
"developed and released by LG AI Research."
msgstr ""
"O EXAONE Deep demonstra capacidades superiores em diversas tarefas de "
"raciocínio, incluindo benchmarks de matemática e codificação, variando de "
"2,4 bilhões a 32 bilhões de parâmetros, desenvolvidos e lançados pela LG AI "
"Research."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:256
#, kde-format
msgid ""
"Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-"
"art vision understanding and enhances long context capabilities up to 128k "
"tokens without compromising text performance."
msgstr ""
"Com base no Mistral Small 3, o Mistral Small 3.1 (2503) adiciona compreensão "
"de visão de última geração e aprimora recursos de contexto longo de até 128 "
"mil tokens sem comprometer o desempenho do texto."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:259
#, kde-format
msgid ""
"Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that "
"outperform the best available open models of the same size, including "
"counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks."
msgstr ""
"O Cogito v1 Preview é uma família de modelos de raciocínio híbridos da Deep "
"Cogito que superam os melhores modelos abertos disponíveis do mesmo tamanho, "
"incluindo contrapartes do LLaMA, DeepSeek e Qwen na maioria dos benchmarks "
"padrão."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:261
#, kde-format
msgid ""
"DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a "
"1.5B version also available."
msgstr ""
"O DeepCoder é um modelo de codificador 14B totalmente de código aberto no "
"nível O3-mini, com uma versão 1.5B também disponível."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:263
#, kde-format
msgid ""
"Qwen3 is the latest generation of large language models in Qwen series, "
"offering a comprehensive suite of dense and mixture-of-experts (MoE) models."
msgstr ""
"Qwen3 é a última geração de grandes modelos de linguagem da série Qwen, "
"oferecendo um conjunto abrangente de modelos densos e de mistura de "
"especialistas (MoE)."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:265
#, kde-format
msgid "Meta's latest collection of multimodal models."
msgstr "A mais recente coleção de modelos multimodais da Meta."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:267
#, kde-format
msgid ""
"IBM Granite 2B and 8B models are 128K context length language models that "
"have been fine-tuned for improved reasoning and instruction-following "
"capabilities."
msgstr ""
"Os modelos IBM Granite 2B e 8B são modelos de linguagem com comprimento de "
"contexto de 128K que foram ajustados para melhorar o raciocínio e as "
"capacidades de seguir instruções."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:270
#, kde-format
msgid ""
"Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight "
"reasoning models that rival much larger models on complex reasoning tasks."
msgstr ""
"O raciocínio Phi 4 e o raciocínio plus são modelos de raciocínio aberto com "
"14 bilhões de parâmetros que rivalizam com modelos muito maiores em tarefas "
"de raciocínio complexas."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:272
#, kde-format
msgid ""
"Phi 4 mini reasoning is a lightweight open model that balances efficiency "
"with advanced reasoning ability."
msgstr ""
"O Phi 4 Mini Raciocínio é um modelo aberto e leve que equilibra eficiência "
"com capacidade avançada de raciocínio."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:273
#, kde-format
msgid ""
"Gemma 3n models are designed for efficient execution on everyday devices "
"such as laptops, tablets or phones."
msgstr ""
"Os modelos Gemma 3n são projetados para execução eficiente em dispositivos "
"do dia a dia, como laptops, tablets ou celulares."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:274
#, kde-format
msgid "Magistral is a small, efficient reasoning model with 24B parameters."
msgstr ""
"Magistral é um modelo de raciocínio pequeno e eficiente com 24B parâmetros."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:275
#, kde-format
msgid ""
"An update to Mistral Small that improves on function calling, instruction "
"following, and less repetition errors."
msgstr ""
"Uma atualização do Mistral Small que melhora a chamada de funções, o "
"acompanhamento de instruções e reduz os erros de repetição."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:276
#, kde-format
msgid ""
"Flagship vision-language model of Qwen and also a significant leap from the "
"previous Qwen2-VL."
msgstr ""
"Modelo de visão e linguagem emblemático do Qwen e também um salto "
"significativo em relação ao anterior Qwen2-VL."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:277
#, kde-format
msgid "Devstral: the best open source model for coding agents."
msgstr ""
"Devstral: o melhor modelo de código aberto para agentes de codificação."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:278
#, kde-format
msgid ""
"OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, "
"and versatile developer use cases."
msgstr ""
"Os modelos de peso aberto da OpenAI foram projetados para raciocínio "
"poderoso, tarefas de agente e casos de uso versáteis para desenvolvedores."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:279
#, kde-format
msgid "Alibaba's performant long context models for agentic and coding tasks."
msgstr ""
"Modelos de contexto longo de alto desempenho do Alibaba para tarefas de "
"codificação e agentes."

#: plugins/ollama/ollamaclient.cpp:27 plugins/ollama/ollamaplugin.cpp:76
#, kde-format
msgid "Ollama"
msgstr "Ollama"

#: plugins/ollama/ollamacomboboxwidget.cpp:30
#, kde-format
msgctxt "@info:tooltip"
msgid "Reload Model"
msgstr "Recarregar modelo"

#: plugins/ollama/ollamaconfiguredialog.cpp:34
#, kde-format
msgctxt "@title:window"
msgid "Configure Ollama"
msgstr "Configuração do Ollama"

#: plugins/ollama/ollamaconfiguredialog.cpp:59
#, kde-format
msgctxt "@title Preferences page name"
msgid "Installed Models"
msgstr "Modelos instalados"

#: plugins/ollama/ollamaconfiguredialog.cpp:64
#, kde-format
msgctxt "@title Preferences page name"
msgid "Create Models"
msgstr "Criar modelos"

#: plugins/ollama/ollamaconfigurewidget.cpp:50
#, kde-format
msgid "Server Url:"
msgstr "URL do servidor:"

#: plugins/ollama/ollamaconfigurewidget.cpp:54
#, kde-format
msgid "Model:"
msgstr "Modelo:"

#: plugins/ollama/ollamaconfigurewidget.cpp:57
#: widgets/networkpluginconfigure/textautogeneratenetworkpluginconfigurewidget.cpp:50
#, kde-format
msgid "Temperature:"
msgstr "Temperatura:"

#: plugins/ollama/ollamaconfigurewidget.cpp:60
#, kde-format
msgctxt "@info:tooltip"
msgid ""
"The temperature of the model. Increasing the temperature will make the model "
"answer more creatively."
msgstr ""
"A temperatura do modelo. Aumentar a temperatura fará com que o modelo "
"responda de forma mais criativa."

#: plugins/ollama/ollamaconfigurewidget.cpp:63
#: widgets/networkpluginconfigure/textautogeneratenetworkpluginconfigurewidget.cpp:51
#, kde-format
msgid "Seed:"
msgstr "Semente:"

#: plugins/ollama/ollamaconfigurewidget.cpp:65
#, kde-format
msgctxt "@info:tooltip"
msgid ""
"Sets the random number seed to use for generation. Setting this to a "
"specific number will make the model generate the same text for the same "
"prompt. (Default: 0)"
msgstr ""
"Define a semente numérica aleatória a ser usada para geração. Definir um "
"número específico fará com que o modelo gere o mesmo texto para o mesmo "
"prompt. (Padrão: 0)"

#: widgets/common/textautogeneratemodelsearchlineedit.cpp:14
#, kde-format
msgctxt "@info:placeholder"
msgid "Search Model…"
msgstr "Pesquisar modelo..."

#: widgets/common/textautogeneratenotinstancefoundwidget.cpp:21
#, kde-format
msgid "No instance found. Please add one."
msgstr "Nenhuma instância encontrada. Adicione uma."

#: widgets/common/textautogeneratenotinstancefoundwidget.cpp:25
#, kde-format
msgctxt "@action:button"
msgid "Add instance…"
msgstr "Adicionar instância..."

#: widgets/common/textautogeneratenotworkingmessagewidget.cpp:43
#, kde-format
msgid ""
"Ollama not found on system. Ask to your administrator system to install it."
msgstr ""
"Ollama não encontrado no sistema. Peça ao administrador do sistema para "
"instalá-lo."

#: widgets/common/textautogeneratenotworkingmessagewidget.cpp:45
#, kde-format
msgid "Ollama not found on system. Please install it."
msgstr "Ollama não encontrado no sistema. Por favor, instale-o."

#: widgets/common/textautogeneratenotworkingmessagewidget.cpp:46
#, kde-format
msgctxt "@action"
msgid "Download Ollama"
msgstr "Baixar o Ollama"

#: widgets/common/textautogeneratenotworkingmessagewidget.cpp:54
#, kde-format
msgctxt "@action"
msgid "Start Ollama"
msgstr "Iniciar Ollama"

#: widgets/common/textautogeneratenotworkingwidget.cpp:32
#, kde-format
msgctxt "@action:button"
msgid "Configure…"
msgstr "Configurar..."

#: widgets/common/textautogeneratetextlineedit.cpp:16
#, kde-format
msgctxt "@info:placeholder"
msgid "Enter a message"
msgstr "Inserir uma mensagem"

#: widgets/common/textautogeneratetextlineeditwidget.cpp:29
#, kde-format
msgctxt "@info:tooltip"
msgid "Attach File"
msgstr "Anexar arquivo"

#: widgets/common/textautogeneratetextlineeditwidget.cpp:45
#, kde-format
msgctxt "@info:tooltip"
msgid "Send"
msgstr "Enviar"

#: widgets/configure/textautogeneratetextconfigurepluginswidget.cpp:26
#, kde-format
msgid "Restart is necessary for applying the changes."
msgstr "É necessário reiniciar para aplicar as alterações."

#: widgets/configure/textautogeneratetextconfigurepluginswidget.cpp:95
#, kde-format
msgid "Text Plugins"
msgstr "Plugins de texto"

#: widgets/configure/textautogeneratetextconfigurepluginswidget.cpp:158
#, kde-format
msgid "..."
msgstr "..."

#: widgets/configure/textautogeneratetextconfigurepluginswidget.cpp:160
#, kde-format
msgctxt "@info:tooltip"
msgid "Configure"
msgstr "Configurar"

#: widgets/configure/textautogeneratetextconfigurepromptwidget.cpp:24
#, kde-format
msgid "Prompt"
msgstr "Prompt"

#: widgets/instancesmanager/textautogenerateaddinstancedialog.cpp:19
#, kde-format
msgctxt "@title:window"
msgid "Add Instance"
msgstr "Adicionar instância"

#: widgets/instancesmanager/textautogenerateaddinstancewidget.cpp:28
#, kde-format
msgctxt "@label:textbox"
msgid "Name:"
msgstr "Nome:"

#: widgets/instancesmanager/textautogenerateaddinstancewidget.cpp:32
#, kde-format
msgctxt "@label:textbox"
msgid "Select a Type of Instance:"
msgstr "Selecione um tipo de instância:"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerdialog.cpp:27
#, kde-format
msgctxt "@title:window"
msgid "Configure Instances"
msgstr "Configurar instâncias"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerlistview.cpp:57
#, kde-format
msgctxt "@action"
msgid "Add instance…"
msgstr "Adicionar instância..."

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerlistview.cpp:67
#, kde-format
msgctxt "@action"
msgid "Mark As Default"
msgstr "Marcar como padrão"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerlistview.cpp:80
#, kde-format
msgctxt "@action"
msgid "Edit…"
msgstr "Editar…"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerlistview.cpp:86
#, kde-format
msgctxt "@action"
msgid "Remove Instance"
msgstr "Remover instância"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerlistview.cpp:94
#, kde-format
msgid "Do you want to remove this instance (%1)?"
msgstr "Você deseja remover esta instância (%1)?"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerlistview.cpp:95
#, kde-format
msgctxt "@title"
msgid "Remove Instance"
msgstr "Remover instância"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerwidget.cpp:45
#: widgets/textautogeneratehistorywidget.cpp:28
#: widgets/textautogeneratesearchwidget.cpp:30
#, kde-format
msgctxt "@info:placeholder"
msgid "Search…"
msgstr "Pesquisar…"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerwidget.cpp:52
#, kde-format
msgctxt "@info:tooltip"
msgid "Add Instance…"
msgstr "Adicionar instância..."

#: widgets/menu/textautogeneratemenuconfiguredialog.cpp:26
#, kde-format
msgctxt "@title:window"
msgid "Configure AI text plugins"
msgstr "Configurar plugins de texto de IA"

#: widgets/menu/textautogeneratemenulistview.cpp:42
#, kde-format
msgctxt "@action"
msgid "Add…"
msgstr "Adicionar…"

#: widgets/menu/textautogeneratemenulistview.cpp:45
#, kde-format
msgid "Ask to AI"
msgstr "Pergunte à IA"

#: widgets/menu/textautogeneratemenulistview.cpp:51
#: widgets/view/textautogeneratehistorylistview.cpp:131
#, kde-format
msgctxt "@action"
msgid "Modify…"
msgstr "Modificar…"

#: widgets/menu/textautogeneratemenulistview.cpp:58
#: widgets/view/textautogeneratehistorylistview.cpp:166
#, kde-format
msgctxt "@action"
msgid "Remove…"
msgstr "Remover…"

#: widgets/menu/textautogeneratemenulistview.cpp:61
#, kde-format
msgid "Do you want to remove it?"
msgstr "Deseja removê-lo?"

#: widgets/menu/textautogeneratemenulistview.cpp:62
#, kde-format
msgctxt "@title"
msgid "Remove"
msgstr "Remover"

#: widgets/menu/textautogeneratemenuwidget.cpp:34
#, kde-format
msgid "Ask AI…"
msgstr "Pergunte à IA..."

#: widgets/menu/textautogeneratemenuwidget.cpp:63
#, kde-format
msgctxt "@action"
msgid "Configure…"
msgstr "Configurar..."

#: widgets/networkpluginconfigure/textautogeneratenetworkpluginconfigurewidget.cpp:48
#, kde-format
msgid "Api Key:"
msgstr "Chave da API:"

#: widgets/networkpluginconfigure/textautogeneratenetworkpluginconfigurewidget.cpp:49
#, kde-format
msgid "Max Tokens:"
msgstr "Máximo de tokens:"

#: widgets/quickask/textautogeneratequickaskdialog.cpp:30
#, kde-format
msgctxt "@title:window"
msgid "Quick Ask"
msgstr "Pergunta rápida"

#: widgets/quickask/textautogeneratequickaskheaderwidget.cpp:38
#, kde-format
msgctxt "@info:tooltip"
msgid "Configure…"
msgstr "Configurar..."

#: widgets/quickask/textautogeneratequickaskheaderwidget.cpp:45
#, kde-format
msgctxt "@info:tooltip"
msgid "Clear"
msgstr "Limpar"

#: widgets/textautogeneratedialog.cpp:37
#, kde-format
msgctxt "@title:window"
msgid "Conversation"
msgstr "Conversa"

#: widgets/textautogenerateheaderwidget.cpp:39
#, kde-format
msgctxt "@info:tooltip"
msgid "Search…"
msgstr "Pesquisar…"

#: widgets/textautogenerateheaderwidget.cpp:46
#, kde-format
msgctxt "@info:tooltip"
msgid "New Chat"
msgstr "Novo bate-papo"

#: widgets/textautogenerateheaderwidget.cpp:53
#, kde-format
msgctxt "@info:tooltip"
msgid "Favorite"
msgstr "Favoritos"

#: widgets/textautogeneratesearchdialog.cpp:28
#, kde-format
msgctxt "@title:window"
msgid "Search"
msgstr "Pesquisar"

#: widgets/textautogeneratewidget.cpp:96
#, kde-format
msgid "No plugin found."
msgstr "Nenhum plugin encontrado."

#: widgets/view/textautogeneratebaselistview.cpp:69
#, kde-format
msgctxt "@action"
msgid "Copy Selection"
msgstr "Copiar seleção"

#: widgets/view/textautogeneratebaselistview.cpp:69
#, kde-format
msgctxt "@action"
msgid "Copy"
msgstr "Copiar"

#: widgets/view/textautogeneratebaselistview.cpp:83
#, kde-format
msgctxt "@action"
msgid "Copy URL"
msgstr "Copiar URL"

#: widgets/view/textautogeneratebaselistview.cpp:95
#, kde-format
msgctxt "@action"
msgid "Select All"
msgstr "Selecionar tudo"

#: widgets/view/textautogeneratehistorylistview.cpp:120
#, kde-format
msgctxt "@action"
msgid "New Chat"
msgstr "Novo bate-papo"

#: widgets/view/textautogeneratehistorylistview.cpp:144
#, kde-format
msgctxt "@action"
msgid "Remove as Favorite"
msgstr "Remover dos favoritos"

#: widgets/view/textautogeneratehistorylistview.cpp:144
#, kde-format
msgctxt "@action"
msgid "Set as Favorite"
msgstr "Definir como favorito"

#: widgets/view/textautogeneratehistorylistview.cpp:155
#, kde-format
msgctxt "@action"
msgid "Restore"
msgstr "Restaurar"

#: widgets/view/textautogeneratehistorylistview.cpp:155
#, kde-format
msgctxt "@action"
msgid "Archive"
msgstr "Arquivar"

#: widgets/view/textautogeneratehistorylistview.cpp:170
#, kde-format
msgid "Do you want to remove this discussion?"
msgstr "Deseja remover esta discussão?"

#: widgets/view/textautogeneratehistorylistview.cpp:171
#, kde-format
msgctxt "@title:window"
msgid "Remove Discussion"
msgstr "Remover discussão"

#: widgets/view/textautogeneratehistorylistview.cpp:196
#, kde-format
msgid "No Archive Found."
msgstr "Nenhum arquivo encontrado."

#: widgets/view/textautogeneratelistviewdelegate.cpp:377
#, kde-format
msgctxt "@info:tooltip"
msgid "Edit…"
msgstr "Editar…"

#: widgets/view/textautogeneratelistviewdelegate.cpp:381
#, kde-format
msgctxt "@info:tooltip"
msgid "Remove"
msgstr "Remover"

#: widgets/view/textautogeneratelistviewdelegate.cpp:385
#, kde-format
msgctxt "@info:tooltip"
msgid "Copy"
msgstr "Copiar"

#: widgets/view/textautogeneratelistviewdelegate.cpp:393
#, kde-format
msgctxt "@info:tooltip"
msgid "Refresh"
msgstr "Atualizar"

#: widgets/view/textautogeneratesearchlistview.cpp:50
#, kde-format
msgid "No Messages Found."
msgstr "Nenhuma mensagem encontrada."

#~ msgid "No system prompt"
#~ msgstr "Nenhum prompt de sistema"
