msgid ""
msgstr ""
"Project-Id-Version: kdeorg\n"
"Report-Msgid-Bugs-To: https://bugs.kde.org\n"
"POT-Creation-Date: 2025-04-02 00:40+0000\n"
"PO-Revision-Date: 2025-02-21 19:27\n"
"Last-Translator: \n"
"Language-Team: Chinese Simplified\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: kdeorg\n"
"X-Crowdin-Project-ID: 269464\n"
"X-Crowdin-Language: zh-CN\n"
"X-Crowdin-File: /kf6-trunk/messages/ktextaddons/libtextautogeneratetext.pot\n"
"X-Crowdin-File-ID: 57198\n"

#: core/textautogenerateengineutil.cpp:15 plugins/ollama/ollamaclient.cpp:27
#, kde-format
msgid "Ollama"
msgstr "Ollama"

#: core/textautogeneratetextclient.cpp:33
#, kde-format
msgid "Local"
msgstr "本地"

#: core/textautogeneratetextclient.cpp:35
#, kde-format
msgid "Network"
msgstr "网络"

#: plugins/mistral/mistralclient.cpp:27
#, kde-format
msgid "Mistral AI"
msgstr "Mistral AI"

#: plugins/mistral/mistralconfiguredialog.cpp:17
#, kde-format
msgctxt "@title:window"
msgid "Configure Mistral IA"
msgstr "配置 Mistral IA"

#: plugins/ollama/ollamacomboboxwidget.cpp:27
#, kde-format
msgctxt "@info:tooltip"
msgid "Reload Model"
msgstr "重新加载模型"

#: plugins/ollama/ollamaconfiguredialog.cpp:16
#, kde-format
msgctxt "@title:window"
msgid "Configure Ollama"
msgstr "配置 Ollama"

#: plugins/ollama/ollamaconfigurewidget.cpp:39
#, kde-format
msgid "Server Url:"
msgstr "服务器 URL："

#: plugins/ollama/ollamaconfigurewidget.cpp:43
#, kde-format
msgid "Model:"
msgstr "模型："

#: plugins/ollama/ollamaconfigurewidget.cpp:46
#, kde-format
msgid "Prompt:"
msgstr "提示词："

#: plugins/ollama/ollamaconfigurewidget.cpp:47
#, kde-format
msgid "No system prompt"
msgstr "没有系统提示词"

#: plugins/ollama/ollamamanager.cpp:46
#, kde-format
msgid "Failed to connect to interface at %1: %2"
msgstr "无法连接到位于 %1 的接口：%2"

#. i18n: ectx: label, entry (ServerUrl), group (Ollama)
#: plugins/ollama/ollamasettings.kcfg:14
#, kde-format
msgid "The URL to the Ollama instance"
msgstr "Ollama 实例的 URL"

#. i18n: ectx: label, entry (SystemPrompt), group (LLM)
#: plugins/ollama/ollamasettings.kcfg:20
#, kde-format
msgid "The system prompt for the LLM"
msgstr "该大语言模型的系统提示词"

#. i18n: ectx: label, entry (Model), group (LLM)
#: plugins/ollama/ollamasettings.kcfg:32
#, kde-format
msgid "The model used to generate responses"
msgstr "用于生成回复的模型"

#: widgets/textautogenerateconfiguredialog.cpp:19
#, kde-format
msgctxt "@title:window"
msgid "Configure IA"
msgstr "配置 IA"

#: widgets/textautogenerateconfigurewidget.cpp:27
#, kde-format
msgid "Engine:"
msgstr "引擎："

#: widgets/textautogeneratedialog.cpp:28
#, kde-format
msgctxt "@title:window"
msgid "Conversation"
msgstr "对话"

#: widgets/textautogeneratenotworkingwidget.cpp:29
#, kde-format
msgid "Configure..."
msgstr "配置..."

#: widgets/textautogeneratetextlineeditwidget.cpp:16
#, kde-format
msgid "Send"
msgstr "发送"
