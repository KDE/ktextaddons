# Spanish translations for libtextautogeneratetext.po package.
# Copyright (C) 2025 This file is copyright:
# This file is distributed under the same license as the ktextaddons package.
# Automatically generated, 2025.
#
# SPDX-FileCopyrightText: 2025 Eloy Cuadra <ecuadra@eloihr.net>
msgid ""
msgstr ""
"Project-Id-Version: libtextautogeneratetext\n"
"Report-Msgid-Bugs-To: https://bugs.kde.org\n"
"POT-Creation-Date: 2025-06-08 00:41+0000\n"
"PO-Revision-Date: 2025-06-06 19:52+0100\n"
"Last-Translator: Eloy Cuadra <ecuadra@eloihr.net>\n"
"Language-Team: Spanish <kde-l10n-es@kde.org>\n"
"Language: es\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=n != 1;\n"
"X-Generator: Lokalize 25.04.1\n"

#: core/textautogeneratechatsmodel.cpp:74
#, kde-format
msgid "New Chat..."
msgstr "Nueva charla…"

#: core/textautogeneratechatsmodel.cpp:146
#, kde-format
msgid "Favorite"
msgstr "Favorita"

#: core/textautogeneratechatsmodel.cpp:148
#, kde-format
msgid "Today"
msgstr "Hoy"

#: core/textautogeneratechatsmodel.cpp:150
#, kde-format
msgid "7 days previous"
msgstr "7 días anteriores"

#: core/textautogeneratechatsmodel.cpp:152
#, kde-format
msgid "30 days previous"
msgstr "30 días anteriores"

#: core/textautogeneratechatsmodel.cpp:154
#, kde-format
msgid "Later"
msgstr "Más tarde"

#: core/textautogeneratechatsmodel.cpp:156
#, kde-format
msgid "Unknown"
msgstr "Desconocido"

#: core/textautogenerateengineutil.cpp:15 plugins/ollama/ollamaclient.cpp:30
#, kde-format
msgid "Ollama"
msgstr "Ollama"

#: core/textautogeneratemessagesmodel.cpp:68
#, kde-format
msgid ""
"Engine: %1\n"
"Model: %2"
msgstr ""
"Motor: %1\n"
"Modelo: %2"

#: core/textautogeneratesearchmessageutils.cpp:34
#, kde-format
msgid "Go to message"
msgstr "Ir al mensaje"

#: core/textautogeneratetextclient.cpp:33
#, kde-format
msgid "Local"
msgstr "Local"

#: core/textautogeneratetextclient.cpp:35
#, kde-format
msgid "Network"
msgstr "Red"

#: plugins/mistral/mistralclient.cpp:30
#, kde-format
msgid "Mistral AI"
msgstr "IA Mistral"

#: plugins/mistral/mistralconfiguredialog.cpp:25
#, kde-format
msgctxt "@title:window"
msgid "Configure Mistral IA"
msgstr "Configurar IA Mistral"

#: plugins/mistral/mistralmanager.cpp:38 plugins/ollama/ollamamanager.cpp:165
#: plugins/openai/openaimanager.cpp:37
#, kde-format
msgid "Failed to connect to interface at %1: %2"
msgstr "No se ha podido conectar a la interfaz %1: %2"

#. i18n: ectx: label, entry (ServerUrl), group (Ollama)
#. i18n: ectx: label, entry (ServerUrl), group (Mistral)
#: plugins/mistral/mistralsettings.kcfg:14
#: plugins/ollama/ollamasettings.kcfg:14
#, kde-format
msgid "The URL to the Ollama instance"
msgstr "La URL de la instancia de Ollama"

#. i18n: ectx: label, entry (SystemPrompt), group (LLM)
#: plugins/mistral/mistralsettings.kcfg:20
#: plugins/ollama/ollamasettings.kcfg:20
#, kde-format
msgid "The system prompt for the LLM"
msgstr "Prompt del sistema para el LLM"

#. i18n: ectx: label, entry (Model), group (LLM)
#: plugins/mistral/mistralsettings.kcfg:32
#: plugins/ollama/ollamasettings.kcfg:32
#, kde-format
msgid "The model used to generate responses"
msgstr "Modelo que se usa para generar respuestas"

#: plugins/ollama/modelsmanager/ollamamodelavailabledialog.cpp:27
#, kde-format
msgctxt "@title:window"
msgid "Manage Ollama Models"
msgstr "Gestión de modelos de Ollama"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:83
#, kde-format
msgid "Tools"
msgstr "Herramientas"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:85
#, kde-format
msgid "Small"
msgstr "Pequeño"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:87
#, kde-format
msgid "Medium"
msgstr "Medio"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:89
#, kde-format
msgid "Big"
msgstr "Grande"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:91
#, kde-format
msgid "Huge"
msgstr "Enorme"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:93
#, kde-format
msgid "Multilingual"
msgstr "Multilingüe"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:95
#, kde-format
msgid "Code"
msgstr "Código"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:97
#, kde-format
msgid "Math"
msgstr "Matemáticas"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:99
#, kde-format
msgid "Vision"
msgstr "Visión"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:101
#, kde-format
msgid "Embedding"
msgstr "Para integrar"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:103
#, kde-format
msgid "Reasoning"
msgstr "Razonamiento"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfowidget.cpp:44
#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:102
#, kde-format
msgid "Languages Supported"
msgstr "Idiomas permitidos"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfowidget.cpp:54
#, kde-format
msgid "Models"
msgstr "Modelos"

#: plugins/ollama/modelsmanager/ollamamodelavailablesearchwidget.cpp:37
#, kde-format
msgctxt "@info:tooltip"
msgid "Add Model"
msgstr "Añadir modelo"

#: plugins/ollama/modelsmanager/ollamamodelcategoriesmodel.cpp:41
#, kde-format
msgid "Categories"
msgstr "Categorías"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:29
#, kde-format
msgid "Base:"
msgstr "Base:"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:32
#, kde-format
msgid "Name:"
msgstr "Nombre:"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:35
#, kde-format
msgid "Tag:"
msgstr "Etiqueta:"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:38
#: plugins/ollama/ollamaconfigurewidget.cpp:62
#, kde-format
msgid "Prompt:"
msgstr "Prompt:"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:43
#, kde-format
msgctxt "@action:button"
msgid "Create"
msgstr "Crear"

#: plugins/ollama/modelsmanager/ollamamodelcreatewidget.cpp:39
#, kde-format
msgctxt "@action:button"
msgid "Load GGUF File…"
msgstr "Cargar archivo GGUF…"

#: plugins/ollama/modelsmanager/ollamamodelcreatewidget.cpp:43
#, kde-format
msgctxt "@title:window"
msgid "Select GGUF File"
msgstr "Seleccionar archivo GGUF"

#: plugins/ollama/modelsmanager/ollamamodelcreatewidget.cpp:49
#, kde-format
msgctxt "@action:button"
msgid "Create Model"
msgstr "Crear modelo"

#: plugins/ollama/modelsmanager/ollamamodeldownloadfromnamedialog.cpp:17
#, kde-format
msgctxt "@title:window"
msgid "Download Model"
msgstr "Descargar modelo"

#: plugins/ollama/modelsmanager/ollamamodeldownloadfromnamewidget.cpp:21
#, kde-format
msgid "Please enter model name as \"name:tag\""
msgstr "Introduzca el nombre del modelo como «nombre:etiqueta»"

#: plugins/ollama/modelsmanager/ollamamodeldownloadprogresswidget.cpp:45
#: widgets/view/textautogeneratelistviewdelegate.cpp:377
#, kde-format
msgctxt "@info:tooltip"
msgid "Cancel"
msgstr "Cancelar"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:24
#, kde-format
msgid "Family:"
msgstr "Familia:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:33
#, kde-format
msgid "Parameter Size:"
msgstr "Tamaño de parámetros:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:42
#, kde-format
msgid "Quantization Level:"
msgstr "Nivel de cuantización:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:51
#, kde-format
msgid "Modified At:"
msgstr "Modificado:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:86
#, kde-format
msgid "Parent Model:"
msgstr "Modelo padre:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:120
#, kde-format
msgid "Features Supported"
msgstr "Funciones permitidas"

#: plugins/ollama/modelsmanager/ollamamodelinstalledwidget.cpp:102
#, kde-format
msgid "Do you want to remove this model (%1)?"
msgstr "¿Desea eliminar este modelo (%1)?"

#: plugins/ollama/modelsmanager/ollamamodelinstalledwidget.cpp:103
#, kde-format
msgctxt "@title"
msgid "Remove Model"
msgstr "Eliminar modelo"

#: plugins/ollama/modelsmanager/ollamamodelsearchlineedit.cpp:14
#, kde-format
msgctxt "@info:placeholder"
msgid "Search Model…"
msgstr "Modelo de búsqueda…"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:15
#, kde-format
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to the Llama 3.1 405B model."
msgstr ""
"Nuevo modelo 70B de última generación. Llama 3.3 70B ofrece un rendimiento "
"similar al modelo Llama 3.1 405B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:16
#, kde-format
msgid "QwQ is the reasoning model of the Qwen series."
msgstr "QwQ es el modelo de razonamiento de la serie Qwen."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:18
#, kde-format
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""
"Llama 3.2 Vision es una colección de modelos generativos de razonamiento de "
"imágenes ajustados por instrucciones en tamaños 11B y 90B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:19
#, kde-format
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr "Llama 3.2 de Meta se reduce con los modelos 1B y 3B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:20
#, kde-format
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr ""
"Llama 3.1 es un nuevo modelo de última generación de Meta, disponible con "
"tamaños de parámetros 8B, 70B y 405B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:21
#, kde-format
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3: el LLM disponible abiertamente más capaz hasta la fecha."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:22
#, kde-format
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr "El modelo 7B publicado por Mistral AI, actualizado a la versión 0.3."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:23
#, kde-format
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr ""
"Un modelo abierto de alto rendimiento para integrar, con una gran ventana de "
"contextos de tókenes."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:24
#, kde-format
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr ""
"Gemma es una familia de modelos abiertos ligeros y de última generación "
"creada por Google DeepMind. Actualizada a la versión 1.1."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:25
#, kde-format
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr ""
"Qwen 1.5 es una serie de modelos extensos de lenguaje de Alibaba Cloud, que "
"abarca parámetros desde 0.5B hasta 110B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:26
#, kde-format
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr ""
"Qwen2 es una nueva serie de modelos extensos de lenguaje del grupo Alibaba."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:27
#, kde-format
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 es una familia de modelos abiertos 3B ligeros (Mini) y 14B (Medium) de "
"última generación de Microsoft."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:28
#, kde-format
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr ""
"Llama 2 es una colección de modelos de lenguaje fundacionales que abarcan "
"parámetros desde 7B hasta 70B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:30
#, kde-format
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""
"Los modelos Qwen2.5 están preentrenados con el más reciente conjunto de "
"datos a gran escala de Alibaba, que abarca hasta 18 billones de tókenes. El "
"modelo admite hasta 128 000 tókenes y es multilingüe."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:32
#, kde-format
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr ""
"Google Gemma 2es un modelo eficiente y de alto rendimiento disponible en "
"tres tamaños: 2B, 9B y 27B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:34
#, kde-format
msgid ""
"LLaVA is a novel end-to-end trained large multimodal model that combines a "
"vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"LLaVA es un es un novedoso modelo extenso multimodal, entrenado de extremo a "
"extremo, que combina un codificador de visión y Vicuna para la comprensión "
"visual y del lenguaje de propósito general."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:36
#, kde-format
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr ""
"Un modelo extenso de lenguaje que puede usar indicaciones de texto para "
"generar y discutir código."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:38
#, kde-format
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""
"La última serie de modelos Qwen específicos de código, con mejoras "
"significativas en la generación de código, el razonamiento de código y la "
"corrección de código."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:39
#, kde-format
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr ""
"Un modelo 12B de última generación con una longitud de contexto de 128k, "
"creado por Mistral AI en colaboración con NVIDIA."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:40
#, kde-format
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"El proyecto TinyLlama es un esfuerzo abierto para entrenar un modelo "
"compacto de Llama de 1.1B en 3 billones de tókenes."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:41
#, kde-format
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr ""
"Modelo para incrustar de gran tamaño de última generación de mixedbread.ai."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:43
#, kde-format
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 es la próxima generación de LLM de código abierto entrenados de "
"forma transparente que viene en tres tamaños: parámetros 3B, 7B y 15B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:44
#, kde-format
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"Un conjunto de modelos de mezcla de expertos (MoE) con pesos abiertos de "
"Mistral AI en tamaños de parámetros de 8x7b y 8x22b."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:46
#, kde-format
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"Modelos 8x7b y 8x22b optimizados, sin censura, basados ​​en los modelos de "
"mezcla de modelos de expertos de Mixtral, que destaca en tareas de "
"programación. Creado por Eric Hartford."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:49
#, kde-format
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma es una colección de modelos livianos y potentes que pueden "
"realizar una variedad de tareas de programación, como completar código "
"intermedio, generación de código, comprensión del lenguaje natural, "
"razonamiento matemático y seguimiento de instrucciones."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:52
#, kde-format
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"Un modelo de lenguaje de código de mezcla de expertos de código abierto que "
"logra un rendimiento comparable a GPT4-Turbo en tareas específicas de código."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:54
#, kde-format
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr ""
"Phi-2: un modelo de lenguaje 2.7B de Microsoft Research que demuestra "
"capacidades excepcionales de razonamiento y comprensión del lenguaje."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:55
#, kde-format
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "Modelo de Llama 2 sin censura de George Sung y Jarrad Hope."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:56
#, kde-format
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder es un modelo capaz de programar entrenado con dos billones de "
"códigos y tókenes de lenguaje natural."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:57
#, kde-format
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr ""
"Un conjunto de modelos de integración de texto de Snowflake, optimizado de "
"cara al rendimiento."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:59
#, kde-format
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"Modelo de lenguaje extenso de última generación de Microsoft AI con "
"rendimiento mejorado para casos de usos complejos de chat, multilingües, "
"razonamiento y agentes."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:61
#, kde-format
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr ""
"Modelo Dolphin sin censura, basado en Mistral, que destaca en tareas de "
"programación. Actualizado a la versión 2.8."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:63
#, kde-format
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9 es un nuevo modelo con tamaños 8B y 70B de Eric Hartford, basado "
"en Llama 3, que tiene una variedad de habilidades de instrucción, "
"conversación y programación."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:65
#, kde-format
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 es un modelo de lenguaje bilingüe de alto rendimiento."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:66
#, kde-format
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr ""
"Command R es un modelo de lenguaje extenso optimizado para la interacción "
"conversacional y grandes tareas de contexto."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:67
#, kde-format
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr ""
"Un modelo de propósito general que va desde tres mil millones de parámetros "
"hasta setenta mil millones, adecuado para hardware de nivel básico."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:68
#, kde-format
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr ""
"Un modelo LLaVA perfeccionado a partir de Llama 3 Instruct con mejores "
"puntuaciones en varias pruebas de referencia."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:70
#, kde-format
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr es una serie de versiones perfeccionadas de los modelos Mistral y "
"Mixtral, que están entrenados para actuar como asistentes de utilidad."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:71
#, kde-format
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr ""
"Un modelo de IA liviano con 3,8 mil millones de parámetros, con un "
"rendimiento que supera a modelos similares y de mayor tamaño."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:72
#, kde-format
msgid "Embedding models on very large sentence level datasets."
msgstr ""
"Integración de modelos sobre conjuntos de datos de nivel de frases muy "
"grandes."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:73
#, kde-format
msgid ""
"Codestral is Mistral AI’s first-ever code model designed for code generation "
"tasks."
msgstr ""
"Codestral es el primer modelo de código de Mistral AI diseñado para tareas "
"de generación de código."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:74
#, kde-format
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr ""
"StarCoder es un modelo de generación de código entrenado en más de 80 "
"lenguajes de programación."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:75
#, kde-format
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr ""
"Modelo de chat de uso general basado en Llama y Llama 2, con tamaños de "
"contexto de 2K a 16K."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:76
#, kde-format
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr "Una familia de modelos de base abierta de IBM para Code Intelligence."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:78
#, kde-format
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca es un modelo de siete mil millones de parámetros, ajustado "
"sobre el modelo Mistral 7B, que usa el conjunto de datos OpenOrca."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:79
#, kde-format
msgid ""
"A family of small models with 135M, 360M, and 1.7B parameters, trained on a "
"new high-quality dataset."
msgstr ""
"Una familia de modelos pequeños con parámetros 135M, 360M y 1.7B, entrenados "
"con un nuevo conjunto de datos de alta calidad."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:81
#, kde-format
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored es un modelo de parámetros 7B, 13B y 30B basado en "
"Llama 2 sin censura, de Eric Hartford."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:82
#, kde-format
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr ""
"Modelo basado en Llama 2, optimizado para mejorar la capacidad de diálogo en "
"chino."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:84
#, kde-format
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr ""
"BGE-M3 es un nuevo modelo de BAAI que se distingue por su versatilidad en "
"multifuncionalidad, multilingüismo y multigranularidad."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:85
#, kde-format
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr ""
"Un modelo versátil para escenarios de desarrollo de software de IA, que "
"incluye terminación de código."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:87
#, kde-format
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"Una familia de modelos de código abierto entrenados con una amplia variedad "
"de datos, que supera a ChatGPT en diversas pruebas de referencia. "
"Actualizado a la versión 3.5-0106."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:88
#, kde-format
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr ""
"Aya 23, lanzado por Cohere, es una nueva familia de modelos multilingües de "
"última generación que admiten 23 idiomas."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:89
#, kde-format
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr ""
"CodeQwen1.5 es un modelo de lenguaje extenso preentrenado con una gran "
"cantidad de datos de código fuente."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:90
#, kde-format
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr ""
"La poderosa familia de modelos de Nous Research que destaca en tareas de "
"programación y discusión científica."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:92
#, kde-format
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+ es un modelo de lenguaje extenso, potente y escalable, diseñado "
"específicamente para destacar en casos de uso empresariales del mundo real."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:93
#, kde-format
msgid "State-of-the-art code generation model"
msgstr "Modelo de generación de código de última generación."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:95
#, kde-format
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"Stable Code 3B es un modelo de programación con variantes de instrucciones y "
"terminación de código a la par de modelos como Code Llama 7B que son 2,5 "
"veces más grandes."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:97
#, kde-format
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"Un modelo experimental de 1.1B parámetros entrenado en el nuevo conjunto de "
"datos Dolphin 2.8 de Eric Hartford y basado en TinyLlama."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:98
#, kde-format
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5 es un modelo 7B perfeccionado por Teknium en Mistral con "
"conjuntos de datos completamente abiertos."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:100
#, kde-format
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""
"Mistral Large 2 es el nuevo modelo insignia de Mistral que es "
"significativamente mejor en generación de código, matemáticas y razonamiento "
"con una ventana de contexto de 128K y compatible con docenas de idiomas."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:103
#, kde-format
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""
"Qwen2 Math es una serie de modelos de lenguajes matemáticos especializados "
"creados sobre la base de los LLM de Qwen2, que superan significativamente "
"las capacidades matemáticas de los modelos de código abierto e incluso de "
"los modelos de código cerrado (por ejemplo, GPT4o)."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:105
#, kde-format
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr ""
"Un modelo de lenguaje general multilingüe sólido con un rendimiento "
"competitivo frente a Llama 3."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:107
#, kde-format
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"Stable LM 2 es un modelo de lenguaje de parámetros 1.6B y 12B de última "
"generación entrenado con datos multilingües en inglés, español, alemán, "
"italiano, francés, portugués y holandés."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:109
#, kde-format
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr ""
"BakLLaVA es un modelo multimodal que consta del modelo base Mistral 7B "
"aumentado con la arquitectura LLaVA."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:111
#, kde-format
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""
"Un modelo de alto rendimiento entrenado con una nueva técnica llamada "
"«ajuste de reflexión» que enseña a un LLM a detectar errores en su "
"razonamiento y a corregir el rumbo."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:113
#, kde-format
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr ""
"Un modelo de lenguaje avanzado creado con 2 billones de tókenes bilingües."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:114
#, kde-format
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr ""
"Este modelo extiende la longitud del contexto de LLama-3 8B de 8k a más de "
"un millón de tókenes."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:115
#, kde-format
msgid "Model focused on math and logic problems"
msgstr "Modelo enfocado a problemas matemáticos y lógicos."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:116
#, kde-format
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr ""
"moondream2 es un modelo de lenguaje de visión pequeño, diseñado para "
"ejecutarse de manera eficiente en dispositivos de borde."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:117
#, kde-format
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr ""
"Un modelo optimizado basado en Mistral con buena cobertura de dominio y "
"lenguaje."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:119
#, kde-format
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"Un modelo de NVIDIA basado en Llama 3 que destaca en la respuesta a "
"preguntas conversacionales (QA) y en la generación aumentada por "
"recuperación (RAG)."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:120
#, kde-format
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr ""
"Modelo conversacional basado en Llama 2 que tiene un rendimiento competitivo "
"en varias pruebas de referencia."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:121
#, kde-format
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr ""
"SQLCoder es un modelo de terminación de código optimizado en StarCoder para "
"tareas de generación de SQL."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:122
#, kde-format
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr "Modelos de uso generala basados en Llama y Llama 2 de Nous Research."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:123
#, kde-format
msgid "Code generation model based on Code Llama."
msgstr "Modelo de generación de código basado en Code Llama."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:124
#, kde-format
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr ""
"Una extensión de Llama 2 que admite un contexto de hasta 128 000 tókenes."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:125
#, kde-format
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr ""
"Una variante sin censura 7B y 15B de la familia de modelos Dolphin que "
"destaca en la programación, basada en StarCoder2."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:126
#, kde-format
msgid "General use model based on Llama 2."
msgstr "Modelo de uso general basado en Llama 2."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:127
#, kde-format
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr ""
"Un modelo de lenguaje de mezcla de expertos sólido, económico y eficiente."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:129
#, kde-format
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling es un modelo extenso de lenguaje entrenado mediante aprendizaje de "
"refuerzo a partir de retroalimentación de IA, enfocado a mejorar la utilidad "
"del chatbot."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:130
#, kde-format
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr ""
"Asistente de compañía entrenado en filosofía, psicología y relaciones "
"personales. Basado en Mistral."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:131
#, kde-format
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr ""
"Hermes 3 es la última versión de la serie insignia Hermes de LLM, de Nous "
"Research."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:133
#, kde-format
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""
"Yi-Coder es una serie de modelos de lenguajes de programación de código "
"abierto que ofrece un rendimiento de programación de última generación con "
"menos de 10 mil millones de parámetros."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:136
#, kde-format
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""
"Un modelo de lenguaje extenso creado por el Instituto de Innovación "
"Tecnológica (TII) para usar en resúmenes, generación de texto y bots de chat."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:137
#, kde-format
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr ""
"InternLM2.5 es un modelo de parámetros de 7B diseñado para escenarios "
"prácticos con una capacidad de razonamiento excepcional."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:138
#, kde-format
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr ""
"Un modelo de lenguaje extenso de 10.7B, compacto pero potente, diseñado para "
"conversaciones de un solo turno."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:139
#, kde-format
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""
"Athene-V2 es un modelo de parámetros de 72B que destaca en tareas de "
"terminación de código, matemáticas y extracción de registros."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:140
#, kde-format
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr "Un nuevo modelo pequeño de LLaVA afinado a partir del Phi 3 Mini."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:142
#, kde-format
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"Orca 2 fue desarrollado por Microsoft Research y es una versión optimizada "
"de los modelos Llama 2 de Meta. El modelo está diseñado para destacar "
"especialmente en razonamiento."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:144
#, kde-format
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr ""
"Una serie de LLM multimodales (MLLM) diseñados para la comprensión visual y "
"lingüística."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:145
#, kde-format
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"Modelo basado en Llama 2, optimizado con un conjunto de datos similar al de "
"Orca. Originalmente llamado «Liberad a Willy»."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:146
#, kde-format
msgid ""
"Mistral Small 3 sets a new benchmark in the “small” Large Language Models "
"category below 70B."
msgstr ""
"Mistral Small 3 establece un nuevo punto de referencia en la categoría de "
"modelos de lenguaje extensos «pequeños» por debajo de 70B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:147
#, kde-format
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"Modelo Dolphin 2.7B sin censura de Eric Hartford, basado en el modelo de "
"lenguaje Phi de Microsoft Research."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:148
#, kde-format
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""
"SmolLM2 es una familia de modelos de lenguaje compactos disponibles en tres "
"tamaños: 135M, 360M y 1.7B parámetros."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:149
#, kde-format
msgid "Uncensored version of Wizard LM model"
msgstr "Versión sin censura del modelo Wizard LM."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:150
#, kde-format
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""
"Un modelo de lenguaje pequeño, comercialmente amigable, de NVIDIA y "
"optimizado para juegos de rol, control de calidad de RAG y llamada de "
"funciones."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:151
#, kde-format
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr ""
"Una extensión de Mistral que admite ventanas de contexto de 64K o 128K."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:153
#, kde-format
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"Una expansión de Llama 2 que se especializa en integrar tanto la comprensión "
"general del lenguaje como el conocimiento específico del dominio, "
"particularmente en programación y matemáticas."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:155
#, kde-format
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr ""
"Modelo Llama 2 optimizado para responder preguntas médicas basadas en un "
"conjunto de datos médicos de código abierto."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:156
#, kde-format
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr ""
"Modelo de lenguaje extenso médico de código abierto adaptado de Llama 2 al "
"ámbito médico."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:158
#, kde-format
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""
"Una serie de modelos de Groq que representan un avance significativo en las "
"capacidades de IA de código abierto para el uso de herramientas y llamada de "
"funciones."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:160
#, kde-format
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""
"Llama-3.1-Nemotron-70B-Instruct es un modelo de lenguaje extenso "
"personalizado por NVIDIA para mejorar la utilidad de las respuestas "
"generadas por LLM a las consultas de los usuarios."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:162
#, kde-format
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr ""
"Nexus Raven es un modelo 13B optimizado con instrucciones para tareas de "
"llamada de funciones."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:163
#, kde-format
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr ""
"El modelo Nous Hermes 2 de Nous Research, entrenado ahora sobre Mixtral."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:164
#, kde-format
msgid "Great code generation model based on Llama2."
msgstr "Excelente modelo de generación de código basado en Llama2."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:165
#, kde-format
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr ""
"Modelo basado en Llama2 sin censura con soporte para una ventana de contexto "
"de 16K."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:167
#, kde-format
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""
"Los modelos IBM Granite 2B y 8B están diseñados para admitir casos de uso "
"basados ​​en herramientas y compatibilidad con generación de recuperación "
"aumentada (RAG), que agiliza la generación de código, la traducción y la "
"corrección de errores."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:170
#, kde-format
msgid ""
"Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"Magicoder es una familia de modelos de parámetros 7B entrenados en 75K de "
"datos de instrucciones sintéticas usando OSS-Instruct, un enfoque novedoso "
"para iluminar los LLM con fragmentos de código de fuente abierta."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:172
#, kde-format
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr ""
"Un modelo de chat liviano que permite resultados precisos y receptivos sin "
"necesidad de hardware de alta gama."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:173
#, kde-format
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr ""
"Un modelo de instrucción de código de alto rendimiento creado mediante la "
"fusión de dos modelos de código existentes."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:174
#, kde-format
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2 es un modelo descodificador causal únicamente con 11B parámetros "
"creado por TII y entrenado con 5T tokens."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:175
#, kde-format
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr ""
"Wizard Vicuna es un modelo de 13B parámetros basado en Llama 2 y entrenado "
"por MelodysDreamj."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:176
#, kde-format
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr ""
"MistralLite es un modelo optimizado basado en Mistral con capacidades "
"mejoradas para procesar contextos grandes."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:177
#, kde-format
msgid ""
"MathΣtral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr ""
"MathΣtral: un modelo 7B diseñado para el razonamiento matemático y el "
"descubrimiento científico, creado por Mistral AI."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:178
#, kde-format
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr ""
"Modelo de texto a SQL de 7B parámetros creado por MotherDuck y Numbers "
"Station."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:179
#, kde-format
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b es una transformación de Dolphin-2.2-70b creada "
"intercalando el modelo consigo mismo."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:181
#, kde-format
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""
"Vista previa de Solar Pro: un modelo de lenguaje extenso (LLM) avanzado con "
"22 mil millones de parámetros, diseñado para encajar en una sola GPU."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:182
#, kde-format
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""
"Una serie de modelos que convierten contenido HTML en contenido Markdown, lo "
"que resulta útil para tareas de conversión de contenido."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:183
#, kde-format
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr ""
"Un modelo combinado de expertos de alto rendimiento, optimizado con datos de "
"alta calidad."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:184
#, kde-format
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr ""
"Un modelo de chat 7B ajustado con datos de alta calidad y basado en Zephyr."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:186
#, kde-format
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"Fusión del modelo Open Orca OpenChat y el modelo Garage-bAInd Platypus 2. "
"Diseñado para chat y generación de código."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:187
#, kde-format
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr ""
"Un modelo de lenguaje creado mediante la combinación de dos modelos Llama 2 "
"70B perfeccionados en uno."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:189
#, kde-format
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"Los modelos IBM Granite 1B y 3B son los primeros modelos Granite de mezcla "
"de expertos (MoE) de IBM diseñados para un uso de baja latencia."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:190
#, kde-format
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""
"Un modelo 3.8B optimizado con un conjunto de datos sintéticos privados de "
"alta calidad para la extracción de información, basado en Phi-3."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:191
#, kde-format
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr ""
"Cohere para modelos de lenguaje de IA entrenados para funcionar bien en 23 "
"idiomas diferentes."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:192
#, kde-format
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr "DBRX es un LLM abierto y de propósito general creado por Databricks."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:194
#, kde-format
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""
"Un modelo de razonamiento abierto a gran escala para soluciones del mundo "
"real del Alibaba International Digital Commerce Group (AIDC-AI)."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:195
#, kde-format
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr "Modelo para integrar de BAAI que mapea textos con vectores."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:197
#, kde-format
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr ""
"Un modelo abierto de llamada a función de pesos basado en Llama 3, "
"competitivo con las capacidades de llamada de función de GPT-4o."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:198
#, kde-format
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr ""
"Un modelo conversacional sólido diseñado para usar en chats y en "
"instrucciones."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:200
#, kde-format
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""
"Una versión mejorada de DeekSeek-V2 que integra las capacidades generales y "
"de programación de DeepSeek-V2-Chat y de DeepSeek-Coder-V2-Instruct."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:202
#, kde-format
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""
"ShieldGemma es un conjunto de modelos de instrucciones optimizados para "
"evaluar la seguridad de las respuestas de entrada y salida de texto frente a "
"un conjunto de políticas de seguridad definidas."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:204
#, kde-format
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr ""
"Un modelo de verificación de datos de última generación desarrollado por "
"Bespoke Labs."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:205
#, kde-format
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""
"Llama Guard 3 es una serie de modelos optimizados para la clasificación de "
"seguridad de contenido de entradas y respuestas de LLM."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:206
#, kde-format
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr ""
"Modelo de transformadores de frases que se puede usar para tareas como "
"agrupamiento o búsqueda semántica."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:208
#, kde-format
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""
"OpenCoder es una familia de LLM de código abierto y reproducible que incluye "
"modelos 1.5B y 8B y admite chat en los idiomas inglés y chino."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:210
#, kde-format
msgid ""
"Tülu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""
"Tülu 3 es una familia líder de modelos de seguimiento de instrucciones que "
"ofrece datos, códigos y recetas totalmente de código abierto, del Instituto "
"Allen para IA."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:212
#, kde-format
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""
"Modelo de integración fronterizo de Snowflake. Arctic Embed 2.0 añade "
"compatibilidad multilingüe sin sacrificar el rendimiento ni la escalabilidad "
"en inglés."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:213
#, kde-format
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr ""
"Los modelos IBM Granite Guardian 3.0 2B y 8B están diseñados para detectar "
"riesgos en indicaciones y/o respuestas."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:215
#, kde-format
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""
"EXAONE 3.5 es una colección de modelos generativos bilingües (inglés y "
"coreano) afinados con instrucciones que van de 2.4B a 32B parámetros, "
"desarrollado y publicado por LG AI Research."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:217
#, kde-format
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr ""
"Sailor2 son modelos lingüísticos multilingües diseñados para el sudeste "
"asiático. Disponibles en tamaños de parámetros 1B, 8B y 20B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:219
#, kde-format
msgid ""
"A family of efficient AI models under 10B parameters performant in science, "
"math, and coding through innovative training techniques."
msgstr ""
"Una familia de modelos de IA eficientes con 10B parámetros y buen "
"rendimiento en ciencias, matemáticas y programación a través de técnicas de "
"entrenamiento innovadoras."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:221
#, kde-format
msgid ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."
msgstr ""
"Los modelos IBM Granite 2B y 8B son LLM densos de solo texto entrenados con "
"más de 12 billones de tokens de datos, que han demostrado mejoras "
"significativas sobre sus predecesores en rendimiento y velocidad en las "
"pruebas iniciales de IBM."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:224
#, kde-format
msgid ""
"The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"Los modelos IBM Granite 1B y 3B son modelos Granite de mezcla de expertos "
"(MoE) de grandes contextos, de IBM, diseñados para un uso de baja latencia."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:226
#, kde-format
msgid ""
"The IBM Granite Embedding 30M and 278M models models are text-only dense "
"biencoder embedding models, with 30M available in English only and 278M "
"serving multilingual use cases."
msgstr ""
"Los modelos IBM Granite Embedding 30M y 278M son modelos de solo texto de "
"doble codificación densa para integrar; el modelo 30M está disponible solo "
"en inglés y el modelo 278M sirve para casos de uso multilingües."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:228
#, kde-format
msgid "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft."
msgstr ""
"Phi-4 es un modelo abierto de última generación con 14B parámetros, de "
"Microsoft."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:229
#, kde-format
msgid ""
"A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model."
msgstr ""
"Un nuevo modelo de razonamiento pequeño, optimizado a partir del modelo "
"Instruct de 3B de Qwen 2.5."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:231
#, kde-format
msgid ""
"Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of "
"instruct-tuned models designed to be the ultimate general purpose local "
"model, enabling coding, math, agentic, function calling, and general use "
"cases."
msgstr ""
"Dolphin 3.0 Llama 3.1 8B 🐬 es la próxima generación de la serie Dolphin de "
"modelos optimizados por instrucciones, diseñados para ser el mejor modelo "
"local de propósito general, que permite codificación, matemáticas, agentes, "
"llamadas de funciones y casos de uso general."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:234
#, kde-format
msgid ""
"DeepSeek's first-generation of reasoning models with comparable performance "
"to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on "
"Llama and Qwen."
msgstr ""
"La primera generación de modelos de razonamiento de DeepSeek con un "
"rendimiento comparable a OpenAI-o1, incluidos seis modelos densos extraídos "
"de DeepSeek-R1, basados ​​en Llama y Qwen."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:236
#, kde-format
msgid ""
"A strong Mixture-of-Experts (MoE) language model with 671B total parameters "
"with 37B activated for each token."
msgstr ""
"Un modelo de lenguaje sólido de mezcla de expertos (MoE) con 671 mil "
"millones de parámetros en total, con 37 mil millones activados para cada "
"token."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:238
#, kde-format
msgid ""
"OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. "
"These models are on par with or better than equivalently sized fully open "
"models, and competitive with open-weight models such as Llama 3.1 on English "
"academic benchmarks."
msgstr ""
"OLMo 2 es una nueva familia de modelos 7B y 13B entrenados con tókenes de "
"hasta 5T. Estos modelos son iguales o mejores que los modelos completamente "
"abiertos de tamaño equivalente y compiten con modelos de peso abierto, como "
"Llama 3.1, en los estándares académicos en inglés."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:241
#, kde-format
msgid ""
"The smallest model in Cohere's R series delivers top-tier speed, efficiency, "
"and quality to build powerful AI applications on commodity GPUs and edge "
"devices."
msgstr ""
"El modelo más pequeño de la serie R de Cohere ofrece velocidad, eficiencia y "
"calidad de primer nivel para crear potentes aplicaciones de IA en GPU "
"comerciales y dispositivos de borde."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:243
#, kde-format
msgid ""
"A fully open-source family of reasoning models built using a dataset derived "
"by distilling DeepSeek-R1."
msgstr ""
"Una familia de modelos de razonamiento de código completamente abierto "
"creada usando un conjunto de datos derivado de la destilación de DeepSeek-R1."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:245
#, kde-format
msgid ""
"A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the "
"performance of OpenAI’s o1-preview with just 1.5B parameters on popular math "
"evaluations."
msgstr ""
"Una versión optimizada de Deepseek-R1-Distilled-Qwen-1.5B que supera el "
"rendimiento de OpenAI o1-preview con solo 1.5B parámetros en evaluaciones "
"matemáticas populares."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:248
#, kde-format
msgid ""
"A version of the DeepSeek-R1 model that has been post trained to provide "
"unbiased, accurate, and factual information by Perplexity."
msgstr ""
"Una versión del modelo DeepSeek-R1 que ha sido entrenado posteriormente para "
"proporcionar información imparcial, precisa y objetiva mediante Perplexity."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:249
#, kde-format
msgid "The current, most capable model that runs on a single GPU."
msgstr "El modelo actual más capaz que funciona con una sola GPU."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:251
#, kde-format
msgid ""
"Phi-4-mini brings significant enhancements in multilingual support, "
"reasoning, and mathematics, and now, the long-awaited function calling "
"feature is finally supported."
msgstr ""
"Phi-4-mini aporta mejoras significativas con compatibilidad multilingüe, "
"razonamiento y matemáticas, y ahora ya admite la tan esperada funcionalidad "
"de llamada de funciones."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:254
#, kde-format
msgid ""
"A compact and efficient vision-language model, specifically designed for "
"visual document understanding, enabling automated content extraction from "
"tables, charts, infographics, plots, diagrams, and more."
msgstr ""
"Un modelo de lenguaje de visión compacto y eficiente, diseñado "
"específicamente para la comprensión visual de documentos, que permite la "
"extracción automatizada de contenido de tablas, gráficos, infografías, "
"gráficos y diagramas, entre otros."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:256
#, kde-format
msgid ""
"Granite-3.2 is a family of long-context AI models from IBM Granite fine-"
"tuned for thinking capabilities."
msgstr ""
"Granite-3.2 es una familia de modelos de IA de contexto largo de IBM Granite "
"optimizados para capacidades de pensamiento."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:258
#, kde-format
msgid ""
"A new state-of-the-art version of the lightweight Command R7B model that "
"excels in advanced Arabic language capabilities for enterprises in the "
"Middle East and Northern Africa."
msgstr ""
"Una nueva versión de última generación del modelo liviano Command R7B que "
"destaca por sus capacidades avanzadas en el idioma árabe para empresas de "
"Medio Oriente y del norte de África."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:260
#, kde-format
msgid ""
"111 billion parameter model optimized for demanding enterprises that require "
"fast, secure, and high-quality AI"
msgstr ""
"Modelo de 111 mil millones de parámetros optimizado para empresas exigentes "
"que requieren IA rápida, segura y de alta calidad."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:262
#, kde-format
msgid ""
"EXAONE Deep exhibits superior capabilities in various reasoning tasks "
"including math and coding benchmarks, ranging from 2.4B to 32B parameters "
"developed and released by LG AI Research."
msgstr ""
"EXAONE Deep exhibe capacidades superiores en varias tareas de razonamiento, "
"incluidas pruebas de referencia de matemáticas y programación, que van desde "
"2.4B a 32B de parámetros, desarrollado y publicado por LG AI Research."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:265
#, kde-format
msgid ""
"Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-"
"art vision understanding and enhances long context capabilities up to 128k "
"tokens without compromising text performance."
msgstr ""
"Basado en Mistral Small 3, Mistral Small 3.1 (2503) añade comprensión de "
"visión de última generación y mejora las capacidades de grandes contextos de "
"hasta 128 000 tókenes sin comprometer el rendimiento del texto."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:268
#, kde-format
msgid ""
"Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that "
"outperform the best available open models of the same size, including "
"counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks."
msgstr ""
"Cogito v1 Preview es una familia de modelos de razonamiento híbrido de Deep "
"Cogito que superan a los mejores modelos abiertos disponibles del mismo "
"tamaño, incluidos sus homólogos de LLaMA, DeepSeek y Qwen en la mayoría de "
"los referentes estándares."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:270
#, kde-format
msgid ""
"DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a "
"1.5B version also available."
msgstr ""
"DeepCoder es un modelo codificador de 14B totalmente de código abierto al "
"nivel de O3-mini, que también dispone de una versión de 1.5B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:272
#, kde-format
msgid ""
"Qwen3 is the latest generation of large language models in Qwen series, "
"offering a comprehensive suite of dense and mixture-of-experts (MoE) models."
msgstr ""
"Qwen3 es la última generación de modelos extensos de lenguaje de la serie "
"Qwen y ofrece un conjunto integral de modelos densos y de mezcla de expertos "
"(MoE)."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:274
#, kde-format
msgid "Meta's latest collection of multimodal models."
msgstr "La colección más reciente de modelos multimodales de Meta."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:276
#, kde-format
msgid ""
"IBM Granite 2B and 8B models are 128K context length language models that "
"have been fine-tuned for improved reasoning and instruction-following "
"capabilities."
msgstr ""
"Los modelos IBM Granite 2B y 8B son modelos de lenguaje de contextos de 128K "
"que han sido afinados para capacidades de razonamiento mejorado y "
"seguimiento de instrucciones."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:279
#, kde-format
msgid ""
"Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight "
"reasoning models that rival much larger models on complex reasoning tasks."
msgstr ""
"Phi 4 reasoning y reasoning plus son modelos de razonamiento de peso abierto "
"de 14 mil millones de parámetros que rivalizan con modelos mucho más grandes "
"en tareas de razonamiento complejas."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:282
#, kde-format
msgid ""
"Phi 4 mini reasoning is a lightweight open model that balances efficiency "
"with advanced reasoning ability."
msgstr ""
"Phi 4 mini reasoning es un modelo ligero abierto que compensa la eficiencia "
"con la capacidad de razonamiento avanzada."

#: plugins/ollama/ollamacomboboxwidget.cpp:28
#, kde-format
msgctxt "@info:tooltip"
msgid "Reload Model"
msgstr "Volver a cargar el modelo"

#: plugins/ollama/ollamaconfiguredialog.cpp:32
#, kde-format
msgctxt "@title:window"
msgid "Configure Ollama"
msgstr "Configurar Ollama"

#: plugins/ollama/ollamaconfiguredialog.cpp:41
#, kde-format
msgctxt "@title Preferences page name"
msgid "General"
msgstr "General"

#: plugins/ollama/ollamaconfiguredialog.cpp:47
#, kde-format
msgctxt "@title Preferences page name"
msgid "Available Models"
msgstr "Modelos disponibles"

#: plugins/ollama/ollamaconfiguredialog.cpp:53
#, kde-format
msgctxt "@title Preferences page name"
msgid "Installed Models"
msgstr "Modelos instalados"

#: plugins/ollama/ollamaconfiguredialog.cpp:59
#, kde-format
msgctxt "@title Preferences page name"
msgid "Create Models"
msgstr "Crear modelos"

#: plugins/ollama/ollamaconfigurewidget.cpp:41
#, kde-format
msgid "Server Url:"
msgstr "URL del servidor:"

#: plugins/ollama/ollamaconfigurewidget.cpp:45
#, kde-format
msgid "Model:"
msgstr "Modelo:"

#: plugins/ollama/ollamaconfigurewidget.cpp:48
#, kde-format
msgid "Temperature:"
msgstr "Temperatura:"

#: plugins/ollama/ollamaconfigurewidget.cpp:51
#, kde-format
msgctxt "@info:tooltip"
msgid ""
"The temperature of the model. Increasing the temperature will make the model "
"answer more creatively."
msgstr ""
"La temperatura del modelo. Un aumento de la temperatura hará que el modelo "
"responda con más creatividad."

#: plugins/ollama/ollamaconfigurewidget.cpp:54
#, kde-format
msgid "Seed:"
msgstr "Semilla:"

#: plugins/ollama/ollamaconfigurewidget.cpp:56
#, kde-format
msgctxt "@info:tooltip"
msgid ""
"Sets the random number seed to use for generation. Setting this to a "
"specific number will make the model generate the same text for the same "
"prompt. (Default: 0)"
msgstr ""
"Define el número de semilla aleatorio que debe usar la generación. Si se usa "
"un número específico, el modelo generará el mismo texto para la misma "
"pregunta (el valor predeterminado es 0)."

#: plugins/ollama/ollamaconfigurewidget.cpp:63
#, kde-format
msgid "No system prompt"
msgstr "Sin prompt del sistema"

#. i18n: ectx: label, entry (Temperature), group (LLM)
#: plugins/ollama/ollamasettings.kcfg:35
#, kde-format
msgid ""
"The temperature of the model. Increasing the temperature will make the model "
"answer more creatively."
msgstr ""
"La temperatura del modelo. Un aumento de la temperatura hará que el modelo "
"responda con más creatividad."

#. i18n: ectx: label, entry (Seed), group (LLM)
#: plugins/ollama/ollamasettings.kcfg:39
#, kde-format
msgid ""
"Sets the random number seed to use for generation. Setting this to a "
"specific number will make the model generate the same text for the same "
"prompt. (Default: 0)"
msgstr ""
"Define el número de semilla aleatorio que debe usar la generación. Si se usa "
"un número específico, el modelo generará el mismo texto para la misma "
"pregunta (el valor predeterminado es 0)."

#: plugins/openai/openaiclient.cpp:27
#, kde-format
msgid "OpenAI"
msgstr "OpenAI"

#: plugins/openai/openaiconfiguredialog.cpp:25
#, kde-format
msgctxt "@title:window"
msgid "Configure Openai IA"
msgstr "Configurar la IA OpenAI"

#: widgets/common/textautogeneratenotworkingwidget.cpp:30
#, kde-format
msgid "Configure…"
msgstr "Configurar…"

#: widgets/common/textautogeneratetextlineedit.cpp:16
#, kde-format
msgctxt "@info:placeholder"
msgid "Enter a message"
msgstr "Introduzca un mensaje"

#: widgets/menu/textautogeneratemenuconfiguredialog.cpp:24
#, kde-format
msgctxt "@title:window"
msgid "Configure AI text plugins"
msgstr "Configurar complementos de texto de IA"

#: widgets/menu/textautogeneratemenulistview.cpp:41
#, kde-format
msgctxt "@action"
msgid "Add…"
msgstr "Añadir…"

#: widgets/menu/textautogeneratemenulistview.cpp:44
#, kde-format
msgid "Ask to AI"
msgstr "Preguntar a la IA"

#: widgets/menu/textautogeneratemenulistview.cpp:50
#: widgets/view/textautogeneratehistorylistview.cpp:114
#, kde-format
msgctxt "@action"
msgid "Modify…"
msgstr "Modificar…"

#: widgets/menu/textautogeneratemenulistview.cpp:57
#: widgets/view/textautogeneratehistorylistview.cpp:151
#, kde-format
msgctxt "@action"
msgid "Remove…"
msgstr "Eliminar…"

#: widgets/menu/textautogeneratemenulistview.cpp:60
#, kde-format
msgid "Do you want to remove it?"
msgstr "¿Desea eliminarlo?"

#: widgets/menu/textautogeneratemenulistview.cpp:61
#, kde-format
msgctxt "@title"
msgid "Remove"
msgstr "Eliminar"

#: widgets/menu/textautogeneratemenuwidget.cpp:32
#, kde-format
msgid "Ask AI…"
msgstr "Preguntar a la IA…"

#: widgets/menu/textautogeneratemenuwidget.cpp:61
#, kde-format
msgctxt "@action"
msgid "Configure…"
msgstr "Configurar…"

#: widgets/networkpluginconfigure/networkpluginconfigurewidget.cpp:29
#, kde-format
msgid "Api Key:"
msgstr "Clave de la API:"

#: widgets/quickask/textautogeneratequickaskdialog.cpp:27
#, kde-format
msgctxt "@title:window"
msgid "Quick Ask"
msgstr ""

#: widgets/textautogenerateconfiguredialog.cpp:19
#, kde-format
msgctxt "@title:window"
msgid "Configure IA"
msgstr "Configurar IA"

#: widgets/textautogenerateconfigurewidget.cpp:27
#, kde-format
msgid "Engine:"
msgstr "Motor:"

#: widgets/textautogeneratedialog.cpp:30
#, kde-format
msgctxt "@title:window"
msgid "Conversation"
msgstr "Conversación"

#: widgets/textautogenerateheaderwidget.cpp:37
#, kde-format
msgctxt "@info:tooltip"
msgid "Configure…"
msgstr "Configurar…"

#: widgets/textautogenerateheaderwidget.cpp:45
#, kde-format
msgctxt "@info:tooltip"
msgid "Search…"
msgstr "Buscar…"

#: widgets/textautogenerateheaderwidget.cpp:52
#, kde-format
msgctxt "@info:tooltip"
msgid "New Chat"
msgstr "Nueva charla"

#: widgets/textautogenerateheaderwidget.cpp:59
#, kde-format
msgctxt "@info:tooltip"
msgid "Favorite"
msgstr "Favorita"

#: widgets/textautogeneratehistorywidget.cpp:27
#: widgets/textautogeneratesearchwidget.cpp:30
#, kde-format
msgctxt "@info:placeholder"
msgid "Search…"
msgstr "Buscar…"

#: widgets/textautogeneratesearchdialog.cpp:26
#, kde-format
msgctxt "@title:window"
msgid "Search"
msgstr "Buscar"

#: widgets/textautogeneratetextlineeditwidget.cpp:17
#, kde-format
msgid "Send"
msgstr "Enviar"

#: widgets/textautogeneratewidget.cpp:94
#, kde-format
msgid "No plugin found."
msgstr "No se ha encontrado ningún complemento."

#: widgets/view/textautogeneratebaselistview.cpp:40
#, kde-format
msgctxt "@action"
msgid "Copy Selection"
msgstr "Copiar selección"

#: widgets/view/textautogeneratebaselistview.cpp:40
#, kde-format
msgctxt "@action"
msgid "Copy"
msgstr "Copiar"

#: widgets/view/textautogeneratebaselistview.cpp:48
#, kde-format
msgctxt "@action"
msgid "Select All"
msgstr "Seleccionar todo"

#: widgets/view/textautogeneratehistorylistview.cpp:103
#, kde-format
msgctxt "@action"
msgid "New Chat"
msgstr "Nueva charla"

#: widgets/view/textautogeneratehistorylistview.cpp:127
#, kde-format
msgctxt "@action"
msgid "Remove as Favorite"
msgstr "Eliminar de favoritas"

#: widgets/view/textautogeneratehistorylistview.cpp:127
#, kde-format
msgctxt "@action"
msgid "Set as Favorite"
msgstr "Marcar como favorita"

#: widgets/view/textautogeneratehistorylistview.cpp:140
#, kde-format
msgctxt "@action"
msgid "Restore"
msgstr "Restaurar"

#: widgets/view/textautogeneratehistorylistview.cpp:140
#, kde-format
msgctxt "@action"
msgid "Archive"
msgstr "Archivar"

#: widgets/view/textautogeneratehistorylistview.cpp:155
#, kde-format
msgid "Do you want to remove this discussion?"
msgstr "¿Desea eliminar esta discusión?"

#: widgets/view/textautogeneratehistorylistview.cpp:156
#, kde-format
msgctxt "@title:window"
msgid "Remove Discussion"
msgstr "Eliminar discusión"

#: widgets/view/textautogeneratelistviewdelegate.cpp:369
#, kde-format
msgctxt "@info:tooltip"
msgid "Edit..."
msgstr "Editar…"

#: widgets/view/textautogeneratelistviewdelegate.cpp:373
#, kde-format
msgctxt "@info:tooltip"
msgid "Copy"
msgstr "Copiar"

#: widgets/view/textautogeneratelistviewdelegate.cpp:381
#, kde-format
msgctxt "@info:tooltip"
msgid "Refresh"
msgstr "Actualizar"

#: widgets/view/textautogeneratesearchlistview.cpp:48
#, kde-format
msgid "No Messages Found."
msgstr "No se han encontrado mensajes."

#~ msgctxt "@action:button"
#~ msgid "Cancel"
#~ msgstr "Cancelar"
