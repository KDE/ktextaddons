# Copyright (C) 2025 This file is copyright:
# This file is distributed under the same license as the ktextaddons package.
#
# SPDX-FileCopyrightText: 2025 Emir SARI <emir_sari@icloud.com>
msgid ""
msgstr ""
"Project-Id-Version: ktextaddons\n"
"Report-Msgid-Bugs-To: https://bugs.kde.org\n"
"POT-Creation-Date: 2025-08-07 18:28+0000\n"
"PO-Revision-Date: 2025-08-06 22:44+0300\n"
"Last-Translator: Emir SARI <emir_sari@îcloud.com>\n"
"Language-Team: Turkish <kde-l10n-tr@kde.org>\n"
"Language: tr\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
"X-Generator: Lokalize 25.04.2\n"

#: core/models/textautogeneratechatsmodel.cpp:78
#, kde-format
msgid "New Chat..."
msgstr "Yeni Sohbet…"

#: core/models/textautogeneratechatsmodel.cpp:150
#, kde-format
msgid "Favorite"
msgstr "Sık Kullanılanlara Ekle"

#: core/models/textautogeneratechatsmodel.cpp:152
#, kde-format
msgid "Today"
msgstr "Bugün"

#: core/models/textautogeneratechatsmodel.cpp:154
#, kde-format
msgid "7 days previous"
msgstr "7 gün öncesi"

#: core/models/textautogeneratechatsmodel.cpp:156
#, kde-format
msgid "30 days previous"
msgstr "30 gün öncesi"

#: core/models/textautogeneratechatsmodel.cpp:158
#, kde-format
msgid "Later"
msgstr "Sonrası"

#: core/models/textautogeneratechatsmodel.cpp:160
#, kde-format
msgid "Unknown"
msgstr "Bilinmeyen"

#: core/models/textautogeneratemessagesmodel.cpp:70
#, kde-format
msgid ""
"Engine: %1\n"
"Model: %2\n"
"Instance Name: %3"
msgstr ""
"İşletke: %1\n"
"Model: %2\n"
"Örnek adı: %3"

#: core/textautogeneratesearchmessageutils.cpp:35
#, kde-format
msgid "Go to message"
msgstr "İletiye git"

#: core/textautogeneratesettings.cpp:44
#, kde-format
msgid ""
"You are an AI assistant. You are speaking to a person named %1. Be helpful, "
"professional, and courteous. Do not give inaccurate information."
msgstr ""
"Sen bir yapay zekâ asistanısın. %1 adlı bir kişiyle konuşuyorsun. Nâzik, "
"profesyonel ve yardımcı ol. Doğru olmayan bilgiler verme."

#: core/textautogeneratetextplugin.cpp:241
#, kde-format
msgid "Local"
msgstr "Yerel"

#: core/textautogeneratetextplugin.cpp:243
#, kde-format
msgid "Network"
msgstr "Ağ"

#: plugins/genericnetworkplugin/genericnetworkclient.cpp:29
#, kde-format
msgid "Generic"
msgstr "Genel"

#: plugins/genericnetworkplugin/genericnetworkconfiguredialog.cpp:28
#, kde-format
msgctxt "@title:window"
msgid "Configure %1"
msgstr "Yapılandır: %1"

#: plugins/genericnetworkplugin/genericnetworkconfiguredialog.cpp:31
#: plugins/ollama/ollamaconfiguredialog.cpp:49
#, kde-format
msgctxt "@title Preferences page name"
msgid "General"
msgstr "Genel"

#: plugins/genericnetworkplugin/genericnetworkconfiguredialog.cpp:36
#: plugins/ollama/ollamaconfiguredialog.cpp:54
#, kde-format
msgctxt "@title Preferences page name"
msgid "Available Models"
msgstr "Kullanılabilir Modeller"

#: plugins/genericnetworkplugin/genericnetworkmanager.cpp:48
#: plugins/ollama/ollamamanager.cpp:166
#, kde-format
msgid "Failed to connect to interface at %1: %2"
msgstr "%1 konumunda arayüze bağlanılamadı: %2"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:24
#, kde-format
msgid "Mistral AI"
msgstr "Mistral AI"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:26
#, kde-format
msgid "OpenAI"
msgstr "OpenAI"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:28
#, kde-format
msgid "Kluster AI"
msgstr "Kluster AI"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:30
#, kde-format
msgid "Groq Cloud"
msgstr "Groq Cloud"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:32
#, kde-format
msgid "Cerebras AI"
msgstr "Cerebras AI"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:34
#, kde-format
msgid "Venice"
msgstr "Venice"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:36
#, kde-format
msgid "Llama Api"
msgstr "Llama API’si"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:38
#, kde-format
msgid "Anthropic"
msgstr "Anthropic"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:129
#, kde-format
msgid "Mistral AI large language models"
msgstr "Mistral AI büyük dil modelleri"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:136
#, kde-format
msgid "Kluster AI cloud inference API"
msgstr "Kluster yapay zekâ bulut öngörü API’si"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:138
#, kde-format
msgid "Cerebras AI cloud inference API"
msgstr "Cerebras yapay zekâ bulut öngörü API’si"

#: plugins/genericnetworkplugin/genericnetworkserverinfo.cpp:140
#, kde-format
msgid "Meta AI Llama API"
msgstr "Meta AI Llama API’si"

#: plugins/ollama/modelsmanager/ollamamodelavailabledialog.cpp:28
#, kde-format
msgctxt "@title:window"
msgid "Manage Ollama Models"
msgstr "Ollama Modellerini Yönet"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:83
#, kde-format
msgid "Tools"
msgstr "Araçlar"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:85
#, kde-format
msgid "Small"
msgstr "Küçük"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:87
#, kde-format
msgid "Medium"
msgstr "Orta"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:89
#, kde-format
msgid "Big"
msgstr "Büyük"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:91
#, kde-format
msgid "Huge"
msgstr "Devasa"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:93
#, kde-format
msgid "Multilingual"
msgstr "Çok Dilli"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:95
#, kde-format
msgid "Code"
msgstr "Kod"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:97
#, kde-format
msgid "Math"
msgstr "Matematik"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:99
#, kde-format
msgid "Vision"
msgstr "Görsel"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:101
#, kde-format
msgid "Embedding"
msgstr "Gömülü"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfo.cpp:103
#, kde-format
msgid "Reasoning"
msgstr "Akıl Yürütme"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfowidget.cpp:47
#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:104
#, kde-format
msgid "Languages Supported"
msgstr "Desteklenen Diller"

#: plugins/ollama/modelsmanager/ollamamodelavailableinfowidget.cpp:61
#, kde-format
msgid "Models"
msgstr "Modeller"

#: plugins/ollama/modelsmanager/ollamamodelavailablesearchwidget.cpp:39
#, kde-format
msgctxt "@info:tooltip"
msgid "Add Model"
msgstr "Model ekle"

#: plugins/ollama/modelsmanager/ollamamodelcategoriesmodel.cpp:41
#, kde-format
msgid "Categories"
msgstr "Kategoriler"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:31
#, kde-format
msgid "Base:"
msgstr "Temel:"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:34
#: plugins/ollama/ollamaconfigurewidget.cpp:46
#: widgets/networkpluginconfigure/textautogeneratenetworkpluginconfigurewidget.cpp:47
#, kde-format
msgid "Name:"
msgstr "Ad:"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:37
#, kde-format
msgid "Tag:"
msgstr "Künye:"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:40
#, kde-format
msgid "Prompt:"
msgstr "İstem:"

#: plugins/ollama/modelsmanager/ollamamodelcreatefromexistingmodelwidget.cpp:45
#, kde-format
msgctxt "@action:button"
msgid "Create"
msgstr "Oluştur"

#: plugins/ollama/modelsmanager/ollamamodelcreatewidget.cpp:41
#, kde-format
msgctxt "@action:button"
msgid "Load GGUF File…"
msgstr "GGUF Dosyası Yükle…"

#: plugins/ollama/modelsmanager/ollamamodelcreatewidget.cpp:45
#, kde-format
msgctxt "@title:window"
msgid "Select GGUF File"
msgstr "GGUF Dosyası Seç"

#: plugins/ollama/modelsmanager/ollamamodelcreatewidget.cpp:51
#, kde-format
msgctxt "@action:button"
msgid "Create Model"
msgstr "Model Oluştur"

#: plugins/ollama/modelsmanager/ollamamodeldownloadfromnamedialog.cpp:19
#, kde-format
msgctxt "@title:window"
msgid "Download Model"
msgstr "Model İndir"

#: plugins/ollama/modelsmanager/ollamamodeldownloadfromnamewidget.cpp:23
#, kde-format
msgid "Please enter model name as \"name:tag\""
msgstr "Model adını “ad:künye” biçiminde girin"

#: plugins/ollama/modelsmanager/ollamamodeldownloadprogresswidget.cpp:47
#: widgets/view/textautogeneratelistviewdelegate.cpp:390
#, kde-format
msgctxt "@info:tooltip"
msgid "Cancel"
msgstr "İptal"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:26
#, kde-format
msgid "Family:"
msgstr "Aile:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:35
#, kde-format
msgid "Parameter Size:"
msgstr "Parametre boyutu:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:44
#, kde-format
msgid "Quantization Level:"
msgstr "Nicemleme düzeyi:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:53
#, kde-format
msgid "Modified At:"
msgstr "Değiştirilme:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:88
#, kde-format
msgid "Parent Model:"
msgstr "Üst model:"

#: plugins/ollama/modelsmanager/ollamamodelinstalledinfowidget.cpp:126
#, kde-format
msgid "Features Supported"
msgstr "Desteklenen Özellikler"

#: plugins/ollama/modelsmanager/ollamamodelinstalledwidget.cpp:108
#, kde-format
msgid "Do you want to remove this model (%1)?"
msgstr "Bu modeli kaldırmak istiyor musunuz (%1)?"

#: plugins/ollama/modelsmanager/ollamamodelinstalledwidget.cpp:109
#, kde-format
msgctxt "@title"
msgid "Remove Model"
msgstr "Modeli Kaldır"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:17
#, kde-format
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to the Llama 3.1 405B model."
msgstr ""
"Yeni son teknoloji 70 milyar parametreli modeli. Llama 3.3 70B, Llama 3.1 "
"405B modeliyle karşılaştırıldığında benzer başarım sunar."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:18
#, kde-format
msgid "QwQ is the reasoning model of the Qwen series."
msgstr "QwQ, Qwen serisinin akıl yürütme modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:19
#, kde-format
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""
"Llama 3.2 Vision, 11 ve 90 milyar boyutlu yönergelerle ayarlanmış görsel "
"akıl yürütme üretme modellerinin bir koleksiyonudur."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:20
#, kde-format
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr "Meta’nın Llama 3.2’si 1 ve 3 milyarlık modelleriyle küçülüyor."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:21
#, kde-format
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr ""
"Llama 3.1, Meta’nın 8, 70 ve 405 milyarlık parametre boyutlarında var olan "
"yeni ve son teknoloji bir modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:22
#, kde-format
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3: Bugüne kadarki en yetenekli açık erişimli LLM."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:23
#, kde-format
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr "Mistral AI tarafından yayınlanan 7B modeli 0.3 sürümüne güncellendi."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:24
#, kde-format
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr ""
"Büyük bir jeton bağlam penceresine sahip, yüksek başarımlı, açık bir "
"yerleştirme modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:25
#, kde-format
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr ""
"Gemma, Google DeepMind tarafından oluşturulmuş hafif, son teknoloji açık "
"modellerden oluşan bir ailedir. 1.1 sürümüne güncellendi."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:26
#, kde-format
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr ""
"Qwen 1.5, Alibaba Cloud tarafından geliştirilen 0,5 milyardan 110 milyara "
"kadar parametreye sahip büyük dil modelleri serisidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:27
#, kde-format
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr "Qwen 2, Alibaba grubunun yeni büyük dil modelleri serisidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:28
#, kde-format
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3, Microsoft’un hafif 3 (Mini) ve 14 (Orta) milyarlık son teknoloji açık "
"model ailesidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:29
#, kde-format
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr ""
"Llama 2, 7B’den 70B’ye kadar parametreye sahip temel dil modelleri "
"koleksiyonudur."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:31
#, kde-format
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""
"Qwen 2.5 modelleri, 18 trilyon jetona kadar kapsayan Alibaba’nın en son "
"büyük ölçekli veri kümesinde önceden eğitilmiştir. Model, 128K jetona kadar "
"destekler ve çok dilli desteğe sahiptir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:33
#, kde-format
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr ""
"Google Gemma 2; 2, 9 ve 27 milyarlık olmak üzere üç boyutta sunulan yüksek "
"başarımlı ve verimli bir modeldir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:35
#, kde-format
msgid ""
"LLaVA is a novel end-to-end trained large multimodal model that combines a "
"vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"LLaVA, genel amaçlı görsel ve dil anlayışı için bir vizyon kodlayıcısı ve "
"Vicuna’yı birleştiren yeni bir uçtan uca eğitilmiş büyük çok kipli modeldir. "
"1.6 sürümüne güncellendi."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:37
#, kde-format
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr ""
"Kod üretmek ve tartışmak için metin istemlerini kullanabilen büyük bir dil "
"modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:39
#, kde-format
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""
"Kod üretimi, kod akıl yürütmesi ve kod düzeltmede önemli iyileştirmeler "
"içeren, kodlamaya özel Qwen modellerinin en son serisi."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:40
#, kde-format
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr ""
"Mistral AI ve NVIDIA işbirliğiyle geliştirilen, 128 k bağlam uzunluğuna "
"sahip son teknoloji 12 milyarlık model."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:41
#, kde-format
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"TinyLlama projesi, 3 trilyon jeton üzerinde kompakt bir 1,1 milyarlık Lama "
"modeli eğitmek için açık bir çabadır."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:42
#, kde-format
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "mixedbread.ai’dan son teknoloji büyük gömülü model."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:44
#, kde-format
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2; 3, 7 ve 15 milyar parametreli olmak üzere üç boyutta sunulan, "
"saydam bir şekilde eğitilmiş, açık kodlu LLM’lerin yeni neslidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:45
#, kde-format
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"Mistral AI tarafından 8 × 7 ve 8 × 22 milyar parametre boyutlarında açık "
"ağırlıklara sahip bir Uzmanlar Karışımı (MoE) modeli kümesi."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:47
#, kde-format
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"Kodlama görevlerinde üstünlük sağlayan Mixtral uzman model karışımına dayalı "
"sansürsüz, 8 × 7 ve 8 × 22 milyar ince ayarlı modeller. Eric Hartford "
"tarafından yaratıldı."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:50
#, kde-format
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma; ortadaki kodu doldurma, kod oluşturma, doğal dil anlama, "
"matematiksel akıl yürütme ve yönerge takibi gibi çeşitli kodlama görevlerini "
"gerçekleştirebilen güçlü ve hafif modellerden oluşan bir koleksiyondur."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:53
#, kde-format
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"Kod odaklı görevlerde GPT4-Turbo ile karşılaştırılabilir başarım sağlayan, "
"açık kaynaklı bir Uzmanlar Karışımı kod dili modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:54
#, kde-format
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr ""
"Phi-2: Microsoft Research tarafından geliştirilen, olağanüstü akıl yürütme "
"ve dil anlama yetenekleri gösteren 2,7 milyarlık dil modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:55
#, kde-format
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr ""
"George Sung ve Jarrad Hope tarafından geliştirilen sansürsüz Llama 2 modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:56
#, kde-format
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder, iki trilyon kod ve doğal dil jetonları üzerinde eğitilmiş "
"yetenekli bir kodlama modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:57
#, kde-format
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr ""
"Snowflake tarafından başarım için eniyilenmiş bir dizi metin gömme modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:59
#, kde-format
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"Microsoft AI’ın karmaşık sohbet, çok dilli, akıl yürütme ve aracı kullanım "
"durumlarında geliştirilmiş başarıma sahip son teknoloji büyük dil modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:61
#, kde-format
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr ""
"Kodlama görevlerinde üstünlük sağlayan Mistral tabanlı sansürsüz Dolphin "
"modeli. 2.8 sürümüne güncellendi."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:63
#, kde-format
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9, Eric Hartford tarafından Llama 3 temel alınarak geliştirilen, "
"çeşitli yönerge, konuşma ve kodlama becerileri içeren 8 ve 70 milyar "
"boyutlarındaki yeni bir modeldir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:65
#, kde-format
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5; yüksek başarımlı, iki dilli bir dil modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:66
#, kde-format
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr ""
"Command R, konuşma etkileşimi ve uzun bağlam görevleri için eniyilenmiş bir "
"Büyük Dil Modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:67
#, kde-format
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr ""
"Giriş düzeyi donanımlar için uygun, 3 milyardan 70 milyara kadar parametreye "
"sahip genel amaçlı bir model."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:68
#, kde-format
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr ""
"Llama 3 Instruct’tan uyarlanan ve birçok kıyaslamada daha iyi puanlar alan "
"bir LLaVA modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:69
#, kde-format
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr, Mistral ve Mixtral modellerinin yardımcı asistanlar olarak hareket "
"edecek şekilde eğitilmiş, ince ayarlı sürümlerinden oluşan bir seridir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:70
#, kde-format
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr ""
"Benzer ve daha büyük boyutlu modellere göre başarımı geride bırakan, 3,8 "
"milyar parametreli hafif bir yapay zekâ modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:71
#, kde-format
msgid "Embedding models on very large sentence level datasets."
msgstr "Çok büyük tümce düzeyindeki veri kümelerine modelleri gömme."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:72
#, kde-format
msgid ""
"Codestral is Mistral AI’s first-ever code model designed for code generation "
"tasks."
msgstr ""
"Codestral, Mistral AI’ın kod oluşturma görevleri için tasarlanmış ilk kod "
"modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:73
#, kde-format
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr ""
"StarCoder, 80’den fazla programlama dili üzerinde eğitilmiş bir kod üretme "
"modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:74
#, kde-format
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr ""
"2 ile 16 bin arasında içerik boyutlarına sahip Llama ve Llama 2 tabanlı "
"genel kullanım sohbet modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:75
#, kde-format
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr "IBM’in Code Intelligence için açık temelli model ailesi."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:76
#, kde-format
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca, OpenOrca veri kümesini kullanarak Mistral 7B modelinin "
"üzerine ince ayar yapılmış 7 milyar parametreli bir modeldir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:77
#, kde-format
msgid ""
"A family of small models with 135M, 360M, and 1.7B parameters, trained on a "
"new high-quality dataset."
msgstr ""
"Yeni, yüksek kaliteli bir veri kümesi üzerinde eğitilen, 135, 360 ve 1,7 "
"milyar parametreli küçük modellerden oluşan bir aile."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:78
#, kde-format
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored, Eric Hartford’ın Llama 2 Uncensored temelli; 7, 13 "
"ve 30 milyar parametreli bir modeldir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:79
#, kde-format
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr ""
"Çince diyalog yeteneğini geliştirmek için Llama 2 tabanlı model ince "
"ayarlandı."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:81
#, kde-format
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr ""
"BGE-M3; çok işlevlilik, dillilik ve granülaritelik açısından çok "
"yönlülüğüyle öne çıkan BAAI’nin yeni bir modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:82
#, kde-format
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr ""
"Kod tamamlamayı da içeren yapay zekâ yazılım geliştirme senaryoları için çok "
"yönlü bir model."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:84
#, kde-format
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"Çeşitli ölçütlerde ChatGPT’yi geride bırakan, çok çeşitli veriler üzerinde "
"eğitilmiş bir açık kaynaklı model ailesi. 3.5-0106 sürümüne güncellendi."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:85
#, kde-format
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr ""
"Cohere tarafından piyasaya sürülen Aya 23, 23 dili destekleyen, son "
"teknoloji ürünü, çok dilli modellerden oluşan yeni bir ailedir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:86
#, kde-format
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr ""
"CodeQwen 1.5, büyük miktarda kod verisi üzerinde önceden eğitilmiş büyük bir "
"dil modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:87
#, kde-format
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr ""
"Nous Research’ün bilimsel tartışma ve kodlama görevlerinde üstünlük sağlayan "
"güçlü model ailesi."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:88
#, kde-format
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+, gerçek dünyadaki kurumsal kullanım durumlarında mükemmellik "
"sağlamak için özel olarak tasarlanmış, güçlü, ölçeklenebilir ve büyük bir "
"dil modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:89
#, kde-format
msgid "State-of-the-art code generation model"
msgstr "Son teknoloji kod üretme modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:91
#, kde-format
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"Stable Code 3B, Code Llama 7B gibi 2,5 kat daha büyük modellerle aynı "
"düzeyde yönerge ve kod tamamlama varyantlarına sahip bir kodlama modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:92
#, kde-format
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"Eric Hartford tarafından yeni Dolphin 2.8 veri kümesi üzerinde eğitilen ve "
"TinyLlama temelli deneysel bir 1,1 milyar parametreli model."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:93
#, kde-format
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5, Teknium tarafından Mistral üzerinde tamamen açık veri "
"kümeleriyle ince ayar yapılan bir 7 milyarlık modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:95
#, kde-format
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""
"Mistral Large 2, 128 bin bağlam penceresi ve düzinelerce dili "
"desteklemesiyle kod üretimi, matematik ve akıl yürütme konusunda önemli "
"ölçüde daha yetenekli olan Mistral’in yeni amiral gemisi modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:98
#, kde-format
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""
"Qwen2 Math, Qwen2 LLM’leri üzerine yapılmış, açık kaynaklı modellerin ve "
"hatta kapalı kaynaklı modellerin (örneğin GPT4o) matematiksel yeteneklerini "
"önemli ölçüde geride bırakan bir dizi uzmanlaşmış matematik dili modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:100
#, kde-format
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr ""
"Llama 3 ile rekabet edebilecek başarıma sahip, güçlü çok dilli genel dil "
"modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:102
#, kde-format
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"Stable LM 2; İngilizce, İspanyolca, Almanca, İtalyanca, Fransızca, "
"Portekizce ve Hollandaca dillerindeki çok dilli veriler üzerinde eğitilmiş, "
"son teknoloji ürünü 1,6 ve 12 milyar parametreli bir dil modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:104
#, kde-format
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr ""
"BakLLaVA, Mistral 7B temel modelinin LLaVA mimarisiyle zenginleştirilmesiyle "
"oluşan çok kipli bir modeldir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:106
#, kde-format
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""
"LLM öğrencilerine akıl yürütmelerindeki hataları tespit etmeyi ve doğru yolu "
"bulmayı öğreten Reflection-Tuning adı verilen yeni bir teknikle eğitilmiş "
"yüksek başarımlı bir model."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:108
#, kde-format
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr "2 trilyon çift dilli jeton ile hazırlanmış gelişmiş bir dil modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:109
#, kde-format
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr ""
"Bu model, LLama-3 8B’nin bağlam uzunluğunu 8 binden 1 milyar jetona "
"çıkarıyor."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:110
#, kde-format
msgid "Model focused on math and logic problems"
msgstr "Matematik ve mantık problemlerine odaklanan model."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:111
#, kde-format
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr ""
"moondream2, uç aygıtlarda verimli bir şekilde çalışmak üzere tasarlanmış "
"küçük bir görsel dil modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:112
#, kde-format
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr ""
"Alan ve dil açısından iyi bir kapsama sahip, Mistral tabanlı ince ayarlı bir "
"model."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:114
#, kde-format
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"NVIDIA’nın Llama 3 tabanlı, konuşma tarzında soru–yanıt (QA) ve geri çağırma "
"destekli üretim (RAG) konusunda üstünlük sağlayan bir modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:115
#, kde-format
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr ""
"Çeşitli ölçütlerde rekabetçi başarım gösteren, Llama 2 tabanlı konuşma "
"modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:116
#, kde-format
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr ""
"SQLCoder, SQL üretimi görevleri için StarCoder üzerinde ince ayar yapılmış "
"bir kod tamamlama modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:117
#, kde-format
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr ""
"Nous Research’ün Llama’sı ve Llama 2’si temelli genel kullanım modelleri."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:118
#, kde-format
msgid "Code generation model based on Code Llama."
msgstr "Code Llama tabanlı kod üretim modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:119
#, kde-format
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr "Llama 2’nin 128 bin jetona kadar bağlamı destekleyen bir uzantısı."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:120
#, kde-format
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr ""
"StarCoder2 tabanlı, kodlamada üstünlük sağlayan Dolphin model ailesinin 7 ve "
"15 milyarlık, sansürsüz bir çeşidi."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:121
#, kde-format
msgid "General use model based on Llama 2."
msgstr "Llama 2 tabanlı genel kullanım modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:122
#, kde-format
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr "Güçlü, ekonomik ve etkili bir Uzmanlar Karışımı dil modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:124
#, kde-format
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling, sohbet robotlarının yardımseverliğini artırmaya odaklanan, yapay "
"zekâ geri bildirimlerinden gelen takviyeli öğrenme ile eğitilen büyük bir "
"dil modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:125
#, kde-format
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr ""
"Felsefe, psikoloji ve kişisel ilişkiler konusunda eğitimli bir refakatçi "
"yardımcı. Mistral tabanlıdır."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:126
#, kde-format
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr ""
"Hermes 3, Nous Research’ün Hermes LLM serisinin amiral gemisi serisinin son "
"sürümüdür."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:128
#, kde-format
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""
"Yi-Coder, 10 milyardan az parametreyle en son teknoloji kodlama başarımını "
"sunan, bir dizi açık kaynaklı kod dili modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:131
#, kde-format
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""
"Özetleme, metin üretimi ve sohbet robotlarında kullanılmak üzere Teknoloji "
"İnovasyon Enstitüsü (TII) tarafından oluşturulmuş büyük bir dil modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:132
#, kde-format
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr ""
"InternLM2.5, olağanüstü akıl yürütme yeteneğine sahip, pratik senaryolara "
"yönelik tasarlanmış bir 7 milyar parametreli modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:133
#, kde-format
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr ""
"Tek turlu konuşmalar için tasarlanmış, kompakt ama güçlü 10,7 milyarlık "
"büyük dil modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:134
#, kde-format
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""
"Athene-V2, kod tamamlama, matematik ve günlük çıkarma görevlerinde üstünlük "
"sağlayan 72 milyar parametreli bir modeldir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:135
#, kde-format
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr "Phi 3 Mini’den ince ayar yapılmış yeni bir küçük LLaVA modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:137
#, kde-format
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"Orca 2, Microsoft Research tarafından yapılmıştır ve Meta’nın Llama 2 "
"modellerinin ince ayarlı bir sürümüdür. Model, özellikle akıl yürütmede "
"mükemmelleşmek üzere tasarlanmıştır."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:139
#, kde-format
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr ""
"Görsel dil anlayışına yönelik tasarlanmış bir dizi çok kipli LLM (MLLM)."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:140
#, kde-format
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"Orca tarzı bir veri kümesinde ince ayar yapılmış Llama 2 tabanlı model. "
"Başlangıçta Free Willy olarak adlandırıldı."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:141
#, kde-format
msgid ""
"Mistral Small 3 sets a new benchmark in the “small” Large Language Models "
"category below 70B."
msgstr ""
"Mistral Small 3, 70 milyarın altındaki “küçük” Büyük Dil Modelleri "
"kategorisinde yeni bir ölçüt belirliyor."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:142
#, kde-format
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"Microsoft Research’ün Phi dil modeline dayanan, Eric Hartford’un 2,7 "
"milyarlık sansürsüz Dolphin modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:143
#, kde-format
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""
"SmolLM2; 135 milyon, 360 milyon ve 1,7 milyar parametreli olmak üzere üç "
"boyutta var olan kompakt dil modelleri ailesidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:144
#, kde-format
msgid "Uncensored version of Wizard LM model"
msgstr "Wizard LM modelinin sansürsüz sürümü."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:145
#, kde-format
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""
"NVIDIA tarafından rol yapma, RAG QA ve işlev çağırma için eniyilenmiş, "
"ticari kullanıma uygun küçük bir dil modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:146
#, kde-format
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr ""
"64 veya 128 bin bağlam penceresini desteklemek için Mistral’in bir uzantısı."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:148
#, kde-format
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"Llama 2’nin, özellikle programlama ve matematikte genel dil anlayışını ve "
"alana özel bilgiyi birleştirmeye odaklanan bir uzantısıdır."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:150
#, kde-format
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr ""
"Açık kaynaklı tıbbi veri kümesine dayalı tıbbi soruları yanıtlamak için ince "
"ayarlı Llama 2 modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:151
#, kde-format
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr ""
"Llama 2’den tıbbi alana uyarlanmış açık kaynaklı tıbbi büyük dil modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:153
#, kde-format
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""
"Groq’un, araç kullanımı/işlev çağırma için açık kaynaklı yapay zekâ "
"yeteneklerinde önemli bir ilerlemeyi temsil eden bir dizi modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:155
#, kde-format
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""
"Llama-3.1-Nemotron-70B-Instruct, NVIDIA tarafından LLM tarafından üretilen "
"kullanıcı sorgularına verilen yanıtların yararlılığını artırmak için "
"özelleştirilmiş büyük bir dil modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:157
#, kde-format
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr ""
"Nexus Raven, işlev çağırma görevleri için 13 milyar yönerge ayarlı bir "
"modeldir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:158
#, kde-format
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr ""
"Nous Research’ün Nous Hermes 2 modeli, artık Mixtral üzerinden eğitiliyor."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:159
#, kde-format
msgid "Great code generation model based on Llama2."
msgstr "Llama2 tabanlı harika bir kod üretme modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:160
#, kde-format
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr "16 bin bağlam penceresini destekleyen sansürsüz Llama2 tabanlı model."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:162
#, kde-format
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""
"IBM Granite 2B ve 8B modelleri, araç tabanlı kullanım durumlarını "
"desteklemek ve kod üretimi, çeviri ve hata düzeltmeyi kolaylaştıran "
"artırılmış üretim (RAG) desteği sağlamak üzere tasarlanmıştır."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:165
#, kde-format
msgid ""
"Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"Magicoder, açık kaynaklı kod parçacıklarıyla LLM’leri aydınlatmak için yeni "
"bir yaklaşım olan OSS-Instruct kullanılarak 75 bin sentetik yönerge verisi "
"üzerinde eğitilen 7 milyar parametreli modellerden oluşan bir ailedir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:167
#, kde-format
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr ""
"Üst düzey donanım gerektirmeden doğru ve hızlı yanıt veren çıktılara olanak "
"tanıyan hafif bir sohbet modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:168
#, kde-format
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr ""
"Var olan iki kod modelinin birleştirilmesiyle oluşturulan yüksek başarımlı "
"bir kod yönerge modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:169
#, kde-format
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2, TII tarafından geliştirilen ve 5 trilyon jeton ile eğitilen 11 "
"milyar parametreli nedensel kod çözücüye dayalı bir modeldir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:170
#, kde-format
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr ""
"Wizard Vicuna, MelodysDreamj tarafından eğitilen, Llama 2 tabanlı 13 milyar "
"parametreli bir modeldir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:171
#, kde-format
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr ""
"MistralLite, uzun bağlamları işleme konusunda gelişmiş yeteneklere sahip, "
"Mistral temelli, ince ayarlı bir modeldir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:172
#, kde-format
msgid ""
"MathΣtral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr ""
"MathΣtral: Mistral AI tarafından matematiksel akıl yürütme ve bilimsel "
"keşifler için tasarlanmış bir 7 milyarlık modeldir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:173
#, kde-format
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr ""
"MotherDuck ve Numbers Station tarafından yapılmış 7 milyar parametreli, "
"metinden SQL’e dönüştürme modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:174
#, kde-format
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b, Dolphin-2.2-70b modelinin kendisiyle iç içe "
"geçirilmesiyle oluşturulan bir dönüşümdür."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:175
#, kde-format
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""
"Solar Pro Preview: Tek bir GPU’ya sığacak şekilde tasarlanmış 22 milyar "
"parametreli gelişmiş bir büyük dil modeli (LLM)."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:176
#, kde-format
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""
"İçerik dönüştürme görevleri için yararlı olan, HTML içeriğini Markdown "
"içeriğine dönüştüren bir dizi model."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:177
#, kde-format
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr ""
"Yüksek kaliteli verilerle ince ayarlanmış, en iyi başarımı gösteren Uzmanlar "
"Karışımı modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:178
#, kde-format
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr ""
"Yüksek kaliteli verilerle ince ayarlanmış ve Zephyr tabanlı 7 milyarlık "
"sohbet modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:179
#, kde-format
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"Open Orca OpenChat modeli ve Garage-bAInd Platypus 2 modelinin "
"birleştirilmesi. Sohbet ve kod üretimi için tasarlanmıştır."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:180
#, kde-format
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr ""
"İki adet ince ayarlı Llama 2 70B modelinin bir araya getirilmesiyle "
"oluşturulmuş bir dil modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:182
#, kde-format
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"IBM Granite 1B ve 3B modelleri, IBM’in düşük gecikmeli kullanım için "
"tasarlanmış ilk Uzmanlar Karışımı (MoE) Granite modelleridir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:183
#, kde-format
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""
"Phi-3 temelli, bilgi çıkarımı için özel, yüksek kaliteli sentetik veri "
"kümesi üzerinde ince ayar yapılmış 3,8 milyarlık modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:184
#, kde-format
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr ""
"Cohere For AI’ın dil modelleri, 23 farklı dilde iyi başarım gösterecek "
"şekilde eğitildi."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:185
#, kde-format
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr ""
"DBRX, Databricks tarafından oluşturulan açık ve genel amaçlı bir LLM "
"programıdır."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:186
#, kde-format
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""
"Alibaba Uluslararası Dijital Ticaret Grubu’nun (AIDC-AI) gerçek dünya "
"çözümleri için açık bir büyük akıl yürütme modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:187
#, kde-format
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr "BAAI’den metinleri vektörlere eşleyen gömme modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:188
#, kde-format
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr ""
"GPT-4o’nun işlev çağırma yetenekleriyle rekabet edebilecek, Llama 3 tabanlı "
"açık ağırlıklı işlev çağırma modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:189
#, kde-format
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr ""
"Hem sohbet hem de yönerge kullanım durumlarında kullanılmak üzere "
"tasarlanmış sağlam bir konuşma modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:191
#, kde-format
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""
"Hem DeepSeek-V2-Chat’in hem de DeepSeek-Coder-V2-Instruct’un genel ve "
"kodlama yeteneklerini birleştiren DeekSeek-V2’nin yükseltilmiş sürümü."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:193
#, kde-format
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""
"ShieldGemma, metin istemi girişinin ve metin çıktısı yanıtlarının "
"tanımlanmış güvenlik politikalarına göre güvenliğini değerlendirmek için bir "
"dizi yönerge ayarlı modeldir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:195
#, kde-format
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr ""
"Bespoke Labs tarafından geliştirilen son teknoloji bir hakikat denetim "
"modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:196
#, kde-format
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""
"Llama Guard 3, LLM girdilerinin ve yanıtlarının içerik güvenliği "
"sınıflandırması için ince ayar yapılmış bir dizi modeldir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:197
#, kde-format
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr ""
"Kümeleme veya anlamsal arama gibi görevler için kullanılabilen tümce "
"dönüştürücüleri modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:199
#, kde-format
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""
"OpenCoder, İngilizce ve Çince sohbet desteği sağlayan 1,5 ve 8 milyarlık "
"modellerini içeren açık ve yeniden üretilebilir kod LLM ailesidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:201
#, kde-format
msgid ""
"Tülu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""
"Tülu 3, The Allen Institute for AI tarafından sağlanan tamamen açık kaynaklı "
"veriler, kodlar ve tarifler sunan, önde gelen bir yönerge izleme modeli "
"ailesidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:203
#, kde-format
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""
"Snowflake’in sınır yerleştirme modeli. Arctic Embed 2.0, İngilizce "
"başarımından veya ölçeklenebilirliğinden ödün vermeden çok dilli destek "
"ekler."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:204
#, kde-format
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr ""
"IBM Granite Guardian 3.0 2B ve 8B modelleri, uyarılarda ve/veya yanıtlarda "
"riskleri tespit etmek için tasarlanmıştır."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:206
#, kde-format
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""
"EXAONE 3.5, LG AI Research tarafından geliştirilen ve yayınlanan, 2,4 "
"milyardan 32 milyara kadar parametre eriminde, yönerge ayarlı iki dilli "
"(İngilizce ve Korece) üretken modellerden oluşan bir koleksiyondur."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:208
#, kde-format
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr ""
"Sailor2, Güneydoğu Asya için yapılmış çok dilli dil modelleridir. 1, 8 ve 20 "
"milyar parametre boyutlarında kullanılabilir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:210
#, kde-format
msgid ""
"A family of efficient AI models under 10B parameters performant in science, "
"math, and coding through innovative training techniques."
msgstr ""
"Bilim, matematik ve kodlama alanlarında yenilikçi eğitim teknikleriyle "
"performans gösteren, 10 milyar parametre altında verimli yapay zekâ "
"modelleri ailesi."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:212
#, kde-format
msgid ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."
msgstr ""
"IBM Granite 2B ve 8B modelleri, 12 trilyondan fazla veri jetonu üzerinde "
"eğitilen, yalnızca metin içeren yoğun LLM’lerdir ve IBM’in ilk sınamalarında "
"başarım ve hız açısından seleflerine göre önemli iyileştirmeler göstermiştir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:215
#, kde-format
msgid ""
"The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"IBM Granite 1B ve 3B modelleri, düşük gecikmeli kullanım için tasarlanmış "
"IBM’in uzun bağlamlı Uzmanlar Karışımı (MoE) Granite modelleridir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:217
#, kde-format
msgid ""
"The IBM Granite Embedding 30M and 278M models models are text-only dense "
"biencoder embedding models, with 30M available in English only and 278M "
"serving multilingual use cases."
msgstr ""
"IBM Granite Embedding 30M ve 278M modelleri yalnızca metin içeren yoğun çift "
"kodlayıcılı gömme modelleridir; 30M yalnızca İngilizce olarak vardır ve 278M "
"ise çok dilli kullanım durumlarına hizmet eder."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:219
#, kde-format
msgid "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft."
msgstr ""
"Phi-4, Microsoft’un 14 milyar parametreli, son teknoloji ürünü açık "
"modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:220
#, kde-format
msgid ""
"A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model."
msgstr ""
"Qwen 2.5 3B Instruct modelinden ince ayar yapılmış yeni bir küçük akıl "
"yürütme modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:222
#, kde-format
msgid ""
"Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of "
"instruct-tuned models designed to be the ultimate general purpose local "
"model, enabling coding, math, agentic, function calling, and general use "
"cases."
msgstr ""
"Dolphin 3.0 Llama 3.1 8B 🐬, kodlama, matematik, aracı, işlev çağırma ve "
"genel kullanım durumlarını etkinleştiren, nihai genel amaçlı yerel model "
"olacak şekilde tasarlanmış, Dolphin serisi yönerge ayarlı modellerin yeni "
"neslidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:225
#, kde-format
msgid ""
"DeepSeek's first-generation of reasoning models with comparable performance "
"to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on "
"Llama and Qwen."
msgstr ""
"DeepSeek’in OpenAI-o1 ile karşılaştırılabilir başarıma sahip birinci nesil "
"akıl yürütme modelleri, Llama’ya ve Qwen’e dayalı DeepSeek-R1’den damıtılan "
"altı yoğun model de dahil."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:227
#, kde-format
msgid ""
"A strong Mixture-of-Experts (MoE) language model with 671B total parameters "
"with 37B activated for each token."
msgstr ""
"Her jeton için 37 milyar etkinleştirilmiş toplam 671 milyar parametreye "
"sahip güçlü bir Uzmanlar Karışımı (MoE) dil modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:229
#, kde-format
msgid ""
"OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. "
"These models are on par with or better than equivalently sized fully open "
"models, and competitive with open-weight models such as Llama 3.1 on English "
"academic benchmarks."
msgstr ""
"OLMo 2, 5 trilyon jetona kadar eğitilmiş yeni bir 7 ve 13 milyarlık model "
"ailesidir. Bu modeller, eşdeğer büyüklükteki tümüyle açık modellerle aynı "
"düzeyde veya daha iyidir ve İngilizce akademik kıyaslamalarında Llama 3.1 "
"gibi açık ağırlıklı modellerle rekabet edebilir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:232
#, kde-format
msgid ""
"The smallest model in Cohere's R series delivers top-tier speed, efficiency, "
"and quality to build powerful AI applications on commodity GPUs and edge "
"devices."
msgstr ""
"Cohere’nin R serisindeki en küçük model, standart GPU’lar ve uç aygıtlar "
"üzerinde güçlü yapay zekâ uygulamaları yapmak için üst düzey hız, verimlilik "
"ve kalite sunuyor."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:234
#, kde-format
msgid ""
"A fully open-source family of reasoning models built using a dataset derived "
"by distilling DeepSeek-R1."
msgstr ""
"DeepSeek-R1’in damıtılmasıyla elde edilen bir veri kümesi kullanılarak "
"oluşturulmuş tamamen açık kaynaklı bir akıl yürütme modelleri ailesi."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:236
#, kde-format
msgid ""
"A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the "
"performance of OpenAI’s o1-preview with just 1.5B parameters on popular math "
"evaluations."
msgstr ""
"OpenAI’nin o1-preview’inin popüler matematik değerlendirmelerinde sadece 1,5 "
"milyar parametresiyle başarımını aşan Deepseek-R1-Distilled-Qwen-1.5B’nin "
"ince ayarlanmış bir sürümü."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:239
#, kde-format
msgid ""
"A version of the DeepSeek-R1 model that has been post trained to provide "
"unbiased, accurate, and factual information by Perplexity."
msgstr ""
"Perplexity tarafından tarafsız, doğru ve gerçekçi bilgi sağlamak üzere "
"sonradan eğitilmiş DeepSeek-R1 modelinin bir sürümü."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:240
#, kde-format
msgid "The current, most capable model that runs on a single GPU."
msgstr "Tek GPU üzerinde çalışan, şu anda en yetenekli model."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:242
#, kde-format
msgid ""
"Phi-4-mini brings significant enhancements in multilingual support, "
"reasoning, and mathematics, and now, the long-awaited function calling "
"feature is finally supported."
msgstr ""
"Phi-4-mini, çok dilli destek, akıl yürütme ve matematik alanlarında önemli "
"geliştirmeler getiriyor ve artık uzun zamandır beklenen işlev çağırma "
"özelliği de nihayet destekleniyor."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:245
#, kde-format
msgid ""
"A compact and efficient vision-language model, specifically designed for "
"visual document understanding, enabling automated content extraction from "
"tables, charts, infographics, plots, diagrams, and more."
msgstr ""
"Görsel belge anlaşılması için özel olarak tasarlanmış, tablolardan, "
"çizelgelerden, infografiklerden, çizimlerden, diyagramlardan ve daha "
"fazlasından kendiliğinden içerik çıkarmayı sağlayan kompakt ve etkili bir "
"görsel dil modeli."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:247
#, kde-format
msgid ""
"Granite-3.2 is a family of long-context AI models from IBM Granite fine-"
"tuned for thinking capabilities."
msgstr ""
"Granite-3.2, IBM Granite’in düşünme yetenekleri için ince ayarlanmış, uzun "
"bağlamlı yapay zekâ modelleri ailesidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:249
#, kde-format
msgid ""
"A new state-of-the-art version of the lightweight Command R7B model that "
"excels in advanced Arabic language capabilities for enterprises in the "
"Middle East and Northern Africa."
msgstr ""
"Orta Doğu ve Kuzey Afrika’daki işletmeler için gelişmiş Arapça dil "
"yetenekleriyle öne çıkan hafif Command R7B modelinin yeni, son teknoloji "
"sürümü."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:251
#, kde-format
msgid ""
"111 billion parameter model optimized for demanding enterprises that require "
"fast, secure, and high-quality AI"
msgstr ""
"Hızlı, güvenli ve yüksek kaliteli yapay zekâ gerektiren zorlu işletmeler "
"için eniyilenmiş, 111 milyar parametreli model."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:253
#, kde-format
msgid ""
"EXAONE Deep exhibits superior capabilities in various reasoning tasks "
"including math and coding benchmarks, ranging from 2.4B to 32B parameters "
"developed and released by LG AI Research."
msgstr ""
"EXAONE Deep, LG AI Research tarafından geliştirilen ve yayınlanan 2,4 "
"milyardan 32 milyara kadar parametreye sahip matematik ve kodlama "
"kıyaslamaları da dahil olmak üzere çeşitli akıl yürütme görevlerinde üstün "
"yetenekler sergiliyor."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:256
#, kde-format
msgid ""
"Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-"
"art vision understanding and enhances long context capabilities up to 128k "
"tokens without compromising text performance."
msgstr ""
"Mistral Small 3’ü temel alan Mistral Small 3.1 (2503), metin başarımından "
"ödün vermeden en son teknoloji görsel anlayışı ekler ve 128 bağlama kadar "
"uzun bağlam yeteneklerini geliştirir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:259
#, kde-format
msgid ""
"Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that "
"outperform the best available open models of the same size, including "
"counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks."
msgstr ""
"Cogito v1 Preview; Deep Cogito’nun aynı boyuttaki en iyi var olan açık "
"modellerden, LLaMA’dan, DeepSeek’ten ve Qwen’den gelen benzerleri de "
"içerilmek üzere, çoğu standart kıyaslamada daha iyi başarım gösteren bir "
"hibrit akıl yürütme modelleri ailesidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:261
#, kde-format
msgid ""
"DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a "
"1.5B version also available."
msgstr ""
"DeepCoder, O3-mini düzeyinde tamamen açık kaynaklı 14 milyarlık kodlayıcı "
"modelidir, ayrıca 1,5 milyarlık bir sürümü de bulunur."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:263
#, kde-format
msgid ""
"Qwen3 is the latest generation of large language models in Qwen series, "
"offering a comprehensive suite of dense and mixture-of-experts (MoE) models."
msgstr ""
"Qwen 3, Qwen serisindeki büyük dil modellerinin son nesli olup yoğun ve "
"Uzmanlar Karışımı (MoE) modellerden oluşan kapsamlı bir paket sunmaktadır."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:265
#, kde-format
msgid "Meta's latest collection of multimodal models."
msgstr "Meta’nın en son çok kipli model koleksiyonu."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:267
#, kde-format
msgid ""
"IBM Granite 2B and 8B models are 128K context length language models that "
"have been fine-tuned for improved reasoning and instruction-following "
"capabilities."
msgstr ""
"IBM Granite 2B ve 8B modelleri, geliştirilmiş akıl yürütme ve yönerge izleme "
"yetenekleri için ince ayar yapılmış 128 bin bağlam uzunluğundaki dil "
"modelleridir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:270
#, kde-format
msgid ""
"Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight "
"reasoning models that rival much larger models on complex reasoning tasks."
msgstr ""
"Phi 4 Reasoning ve Reasoning Plus, karmaşık akıl yürütme görevlerinde çok "
"daha büyük modellerle rekabet edebilen 14 milyar parametreli açık ağırlıklı "
"akıl yürütme modelleridir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:272
#, kde-format
msgid ""
"Phi 4 mini reasoning is a lightweight open model that balances efficiency "
"with advanced reasoning ability."
msgstr ""
"Phi 4 Mini Reasoning, verimliliği gelişmiş akıl yürütme yeteneğiyle "
"dengeleyen hafif ve açık bir modeldir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:273
#, kde-format
msgid ""
"Gemma 3n models are designed for efficient execution on everyday devices "
"such as laptops, tablets or phones."
msgstr ""
"Genma 3n modelleri; dizüstleri, tabletler veya telefonlar gibi günlük "
"kullanım aygıtları üzerinde efektif yürütme için tasarlanmıştır."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:274
#, kde-format
msgid "Magistral is a small, efficient reasoning model with 24B parameters."
msgstr ""
"Magistral; 24 milyar parametreli, küçük ve kaynakları verimli kullanan bir "
"akıl yürütme modelidir."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:275
#, kde-format
msgid ""
"An update to Mistral Small that improves on function calling, instruction "
"following, and less repetition errors."
msgstr ""
"Mistral Small üzerine işlev çağırmayı, yönerge takibini ve yineleme "
"hatalarını azaltan bir güncelleme."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:276
#, kde-format
msgid ""
"Flagship vision-language model of Qwen and also a significant leap from the "
"previous Qwen2-VL."
msgstr ""
"Qwen’in amiral gemisi öngörü dil modeli ve bir önceki Qwen2-VL üzerine kayda "
"değer bir güncelleme."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:277
#, kde-format
msgid "Devstral: the best open source model for coding agents."
msgstr "Devstral: Kodlama aracıları için en iyi açık kaynaklı model."

#: plugins/ollama/ollamaclient.cpp:27 plugins/ollama/ollamaplugin.cpp:76
#, kde-format
msgid "Ollama"
msgstr "Ollama"

#: plugins/ollama/ollamacomboboxwidget.cpp:30
#, kde-format
msgctxt "@info:tooltip"
msgid "Reload Model"
msgstr "Modeli yeniden yükle"

#: plugins/ollama/ollamaconfiguredialog.cpp:34
#, kde-format
msgctxt "@title:window"
msgid "Configure Ollama"
msgstr "Ollama’yı Yapılandır"

#: plugins/ollama/ollamaconfiguredialog.cpp:59
#, kde-format
msgctxt "@title Preferences page name"
msgid "Installed Models"
msgstr "Kurulu Modeller"

#: plugins/ollama/ollamaconfiguredialog.cpp:64
#, kde-format
msgctxt "@title Preferences page name"
msgid "Create Models"
msgstr "Modeller Oluştur"

#: plugins/ollama/ollamaconfigurewidget.cpp:50
#, kde-format
msgid "Server Url:"
msgstr "Sunucu URL’si:"

#: plugins/ollama/ollamaconfigurewidget.cpp:54
#, kde-format
msgid "Model:"
msgstr "Model:"

#: plugins/ollama/ollamaconfigurewidget.cpp:57
#: widgets/networkpluginconfigure/textautogeneratenetworkpluginconfigurewidget.cpp:50
#, kde-format
msgid "Temperature:"
msgstr "Sıcaklık:"

#: plugins/ollama/ollamaconfigurewidget.cpp:60
#, kde-format
msgctxt "@info:tooltip"
msgid ""
"The temperature of the model. Increasing the temperature will make the model "
"answer more creatively."
msgstr ""
"Modelin sıcaklığı. Sıcaklığı artırmak modelin daha yaratıcı bir biçimde "
"yanıtlar vermesini sağlar."

#: plugins/ollama/ollamaconfigurewidget.cpp:63
#: widgets/networkpluginconfigure/textautogeneratenetworkpluginconfigurewidget.cpp:51
#, kde-format
msgid "Seed:"
msgstr "Tohum:"

#: plugins/ollama/ollamaconfigurewidget.cpp:65
#, kde-format
msgctxt "@info:tooltip"
msgid ""
"Sets the random number seed to use for generation. Setting this to a "
"specific number will make the model generate the same text for the same "
"prompt. (Default: 0)"
msgstr ""
"Üretme için kullanılacak rastgele tohum numarasını ayarlar. Bunu belirli bir "
"sayıya ayarlamak modelin aynı istem için aynı metni üretmesini sağlar "
"(Öntanımlı: 0)."

#: widgets/common/textautogeneratemodelsearchlineedit.cpp:14
#, kde-format
msgctxt "@info:placeholder"
msgid "Search Model…"
msgstr "Model ara…"

#: widgets/common/textautogeneratenotinstancefoundwidget.cpp:21
#, kde-format
msgid "No instance found. Please add one."
msgstr "Bulunan örnek yok. Lütfen bir tane ekleyin."

#: widgets/common/textautogeneratenotinstancefoundwidget.cpp:25
#, kde-format
msgctxt "@action:button"
msgid "Add instance…"
msgstr "Örnek Ekle…"

#: widgets/common/textautogeneratenotworkingmessagewidget.cpp:39
#, kde-format
msgid ""
"Ollama not found on system. Ask to your administrator system to install it."
msgstr ""
"Ollama sistemde bulunamadı. Sistem yöneticinize onu kurmasını söyleyin."

#: widgets/common/textautogeneratenotworkingmessagewidget.cpp:41
#, kde-format
msgid "Ollama not found on system. Please install it."
msgstr "Ollama sistemde bulunamadı. Lütfen onu kurun."

#: widgets/common/textautogeneratenotworkingmessagewidget.cpp:42
#, kde-format
msgctxt "@action"
msgid "Download Ollama"
msgstr "Ollama’yı İndir"

#: widgets/common/textautogeneratenotworkingmessagewidget.cpp:49
#, kde-format
msgctxt "@action"
msgid "Start Ollama"
msgstr "Ollama’yı Başlat"

#: widgets/common/textautogeneratenotworkingwidget.cpp:32
#, kde-format
msgctxt "@action:button"
msgid "Configure…"
msgstr "Yapılandır…"

#: widgets/common/textautogeneratetextlineedit.cpp:16
#, kde-format
msgctxt "@info:placeholder"
msgid "Enter a message"
msgstr "İleti gir…"

#: widgets/common/textautogeneratetextlineeditwidget.cpp:29
#, kde-format
msgctxt "@info:tooltip"
msgid "Attach File"
msgstr "Dosya İliştir"

#: widgets/common/textautogeneratetextlineeditwidget.cpp:45
#, kde-format
msgctxt "@info:tooltip"
msgid "Send"
msgstr "Gönder"

#: widgets/configure/textautogeneratetextconfigurepluginswidget.cpp:26
#, kde-format
msgid "Restart is necessary for applying the changes."
msgstr ""

#: widgets/configure/textautogeneratetextconfigurepluginswidget.cpp:95
#, kde-format
msgid "Text Plugins"
msgstr ""

#: widgets/configure/textautogeneratetextconfigurepluginswidget.cpp:158
#, kde-format
msgid "..."
msgstr ""

#: widgets/configure/textautogeneratetextconfigurepluginswidget.cpp:160
#, fuzzy, kde-format
#| msgctxt "@info:tooltip"
#| msgid "Configure…"
msgctxt "@info:tooltip"
msgid "Configure"
msgstr "Yapılandır…"

#: widgets/configure/textautogeneratetextconfigurepromptwidget.cpp:24
#, fuzzy, kde-format
#| msgid "Prompt:"
msgid "Prompt"
msgstr "İstem:"

#: widgets/instancesmanager/textautogenerateaddinstancedialog.cpp:19
#, kde-format
msgctxt "@title:window"
msgid "Add Instance"
msgstr "Örnek Ekle"

#: widgets/instancesmanager/textautogenerateaddinstancewidget.cpp:28
#, kde-format
msgctxt "@label:textbox"
msgid "Name:"
msgstr "Ad:"

#: widgets/instancesmanager/textautogenerateaddinstancewidget.cpp:32
#, kde-format
msgctxt "@label:textbox"
msgid "Select a Type of Instance:"
msgstr "Bir örnek türü seç:"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerdialog.cpp:27
#, kde-format
msgctxt "@title:window"
msgid "Configure Instances"
msgstr "Örnekleri Yapılandır"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerlistview.cpp:57
#, kde-format
msgctxt "@action"
msgid "Add instance…"
msgstr "Örnek Ekle…"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerlistview.cpp:67
#, kde-format
msgctxt "@action"
msgid "Mark As Default"
msgstr "Öntanımlı Olarak İmle"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerlistview.cpp:80
#, kde-format
msgctxt "@action"
msgid "Edit…"
msgstr "Düzenle…"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerlistview.cpp:86
#, kde-format
msgctxt "@action"
msgid "Remove Instance"
msgstr "Örneği Kaldır"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerlistview.cpp:94
#, kde-format
msgid "Do you want to remove this instance (%1)?"
msgstr "Bu örneği kaldırmak istiyor musunuz (%1)?"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerlistview.cpp:95
#, kde-format
msgctxt "@title"
msgid "Remove Instance"
msgstr "Örneği Kaldır"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerwidget.cpp:45
#: widgets/textautogeneratehistorywidget.cpp:28
#: widgets/textautogeneratesearchwidget.cpp:30
#, kde-format
msgctxt "@info:placeholder"
msgid "Search…"
msgstr "Ara…"

#: widgets/instancesmanager/textautogeneratetextinstancesmanagerwidget.cpp:52
#, kde-format
msgctxt "@info:tooltip"
msgid "Add Instance…"
msgstr "Örnek ekle…"

#: widgets/menu/textautogeneratemenuconfiguredialog.cpp:26
#, kde-format
msgctxt "@title:window"
msgid "Configure AI text plugins"
msgstr "Yapay Zekâ Metin Eklentilerini Yapılandır"

#: widgets/menu/textautogeneratemenulistview.cpp:42
#, kde-format
msgctxt "@action"
msgid "Add…"
msgstr "Ekle…"

#: widgets/menu/textautogeneratemenulistview.cpp:45
#, kde-format
msgid "Ask to AI"
msgstr "Yapay Zekâya Sor"

#: widgets/menu/textautogeneratemenulistview.cpp:51
#: widgets/view/textautogeneratehistorylistview.cpp:116
#, kde-format
msgctxt "@action"
msgid "Modify…"
msgstr "Değişiklik Yap…"

#: widgets/menu/textautogeneratemenulistview.cpp:58
#: widgets/view/textautogeneratehistorylistview.cpp:152
#, kde-format
msgctxt "@action"
msgid "Remove…"
msgstr "Kaldır…"

#: widgets/menu/textautogeneratemenulistview.cpp:61
#, kde-format
msgid "Do you want to remove it?"
msgstr "Kaldırmak istiyor musunuz?"

#: widgets/menu/textautogeneratemenulistview.cpp:62
#, kde-format
msgctxt "@title"
msgid "Remove"
msgstr "Kaldır"

#: widgets/menu/textautogeneratemenuwidget.cpp:34
#, kde-format
msgid "Ask AI…"
msgstr "Yapay Zekâya Sor…"

#: widgets/menu/textautogeneratemenuwidget.cpp:63
#, kde-format
msgctxt "@action"
msgid "Configure…"
msgstr "Yapılandır…"

#: widgets/networkpluginconfigure/textautogeneratenetworkpluginconfigurewidget.cpp:48
#, kde-format
msgid "Api Key:"
msgstr "API anahtarı:"

#: widgets/networkpluginconfigure/textautogeneratenetworkpluginconfigurewidget.cpp:49
#, kde-format
msgid "Max Tokens:"
msgstr "En çok jeton sayısı:"

#: widgets/quickask/textautogeneratequickaskdialog.cpp:30
#, kde-format
msgctxt "@title:window"
msgid "Quick Ask"
msgstr "Tez Sor"

#: widgets/quickask/textautogeneratequickaskheaderwidget.cpp:38
#, kde-format
msgctxt "@info:tooltip"
msgid "Configure…"
msgstr "Yapılandır…"

#: widgets/quickask/textautogeneratequickaskheaderwidget.cpp:45
#, kde-format
msgctxt "@info:tooltip"
msgid "Clear"
msgstr "Temizle"

#: widgets/textautogeneratedialog.cpp:37
#, kde-format
msgctxt "@title:window"
msgid "Conversation"
msgstr "Konuşma"

#: widgets/textautogenerateheaderwidget.cpp:39
#, kde-format
msgctxt "@info:tooltip"
msgid "Search…"
msgstr "Ara…"

#: widgets/textautogenerateheaderwidget.cpp:46
#, kde-format
msgctxt "@info:tooltip"
msgid "New Chat"
msgstr "Yeni sohbet"

#: widgets/textautogenerateheaderwidget.cpp:53
#, kde-format
msgctxt "@info:tooltip"
msgid "Favorite"
msgstr "Sık kullanılanlara ekle"

#: widgets/textautogeneratesearchdialog.cpp:28
#, kde-format
msgctxt "@title:window"
msgid "Search"
msgstr "Ara"

#: widgets/textautogeneratewidget.cpp:96
#, kde-format
msgid "No plugin found."
msgstr "Bulunan eklenti yok."

#: widgets/view/textautogeneratebaselistview.cpp:64
#, kde-format
msgctxt "@action"
msgid "Copy Selection"
msgstr "Seçimi Kopyala"

#: widgets/view/textautogeneratebaselistview.cpp:64
#, kde-format
msgctxt "@action"
msgid "Copy"
msgstr "Kopyala"

#: widgets/view/textautogeneratebaselistview.cpp:77
#, kde-format
msgctxt "@action"
msgid "Copy URL"
msgstr "URL’yi Kopyala"

#: widgets/view/textautogeneratebaselistview.cpp:89
#, kde-format
msgctxt "@action"
msgid "Select All"
msgstr "Tümünü Seç"

#: widgets/view/textautogeneratehistorylistview.cpp:105
#, kde-format
msgctxt "@action"
msgid "New Chat"
msgstr "Yeni Sohbet"

#: widgets/view/textautogeneratehistorylistview.cpp:129
#, kde-format
msgctxt "@action"
msgid "Remove as Favorite"
msgstr "Sık Kullanılanlardan Kaldır"

#: widgets/view/textautogeneratehistorylistview.cpp:129
#, kde-format
msgctxt "@action"
msgid "Set as Favorite"
msgstr "Sık Kullanılan Yap"

#: widgets/view/textautogeneratehistorylistview.cpp:141
#, kde-format
msgctxt "@action"
msgid "Restore"
msgstr "Geri Yükle"

#: widgets/view/textautogeneratehistorylistview.cpp:141
#, kde-format
msgctxt "@action"
msgid "Archive"
msgstr "Arşivle"

#: widgets/view/textautogeneratehistorylistview.cpp:156
#, kde-format
msgid "Do you want to remove this discussion?"
msgstr "Bu tartışmayı kaldırmak istiyor musunuz?"

#: widgets/view/textautogeneratehistorylistview.cpp:157
#, kde-format
msgctxt "@title:window"
msgid "Remove Discussion"
msgstr "Tartışmayı Kaldır"

#: widgets/view/textautogeneratehistorylistview.cpp:182
#, kde-format
msgid "No Archive Found."
msgstr "Bulunan arşiv yok."

#: widgets/view/textautogeneratelistviewdelegate.cpp:378
#, kde-format
msgctxt "@info:tooltip"
msgid "Edit…"
msgstr "Düzenle…"

#: widgets/view/textautogeneratelistviewdelegate.cpp:382
#, kde-format
msgctxt "@info:tooltip"
msgid "Remove"
msgstr "Kaldır"

#: widgets/view/textautogeneratelistviewdelegate.cpp:386
#, kde-format
msgctxt "@info:tooltip"
msgid "Copy"
msgstr "Kopyala"

#: widgets/view/textautogeneratelistviewdelegate.cpp:394
#, kde-format
msgctxt "@info:tooltip"
msgid "Refresh"
msgstr "Yenile"

#: widgets/view/textautogeneratesearchlistview.cpp:50
#, kde-format
msgid "No Messages Found."
msgstr "Bulunan ileti yok."

#~ msgid "No system prompt"
#~ msgstr "Sistem istemi yok"

#~ msgctxt "@info:tooltip"
#~ msgid "Edit..."
#~ msgstr "Düzenle…"

#~ msgid "The URL to the Ollama instance"
#~ msgstr "Ollama örneği URL’si"

#~ msgid "The system prompt for the LLM"
#~ msgstr "LLM için olan sistem istemi"

#~ msgid "The model used to generate responses"
#~ msgstr "Yanıtlar üretmek için kullanılan model"

#~ msgid ""
#~ "The temperature of the model. Increasing the temperature will make the "
#~ "model answer more creatively."
#~ msgstr ""
#~ "Modelin sıcaklığı. Sıcaklığı artırmak modelin daha yaratıcı bir biçimde "
#~ "yanıtlar vermesini sağlar."

#~ msgid ""
#~ "Sets the random number seed to use for generation. Setting this to a "
#~ "specific number will make the model generate the same text for the same "
#~ "prompt. (Default: 0)"
#~ msgstr ""
#~ "Üretme için kullanılacak rastgele tohum numarasını ayarlar. Bunu belirli "
#~ "bir sayıya ayarlamak modelin aynı istem için aynı metni üretmesini sağlar "
#~ "(Öntanımlı: 0)."

#~ msgid "Engine:"
#~ msgstr "İşletke:"

#~ msgctxt "@title:window"
#~ msgid "Configure Mistral IA"
#~ msgstr "Mistral AI’ı Yapılandır"

#~ msgctxt "@title:window"
#~ msgid "Configure Openai IA"
#~ msgstr "OpenAI Zekâsını Yapılandır"

#~ msgctxt "@action:button"
#~ msgid "Cancel"
#~ msgstr "İptal"

#, fuzzy
#~| msgid "Favorite"
#~ msgctxt "@action"
#~ msgid "Favorite…"
#~ msgstr "Sık Kullanılanlara Ekle"
