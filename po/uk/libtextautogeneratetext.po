# Copyright (C) YEAR This file is copyright:
# This file is distributed under the same license as the ktextaddons package.
#
# Yuri Chornoivan <yurchor@ukr.net>, 2025.
msgid ""
msgstr ""
"Project-Id-Version: ktextaddons\n"
"Report-Msgid-Bugs-To: https://bugs.kde.org\n"
"POT-Creation-Date: 2025-05-25 00:41+0000\n"
"PO-Revision-Date: 2025-05-24 21:45+0300\n"
"Last-Translator: Yuri Chornoivan <yurchor@ukr.net>\n"
"Language-Team: Ukrainian <trans-uk@lists.fedoraproject.org>\n"
"Language: uk\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=4; plural=n==1 ? 3 : n%10==1 && n%100!=11 ? 0 : n"
"%10>=2 && n%10<=4 && (n%100<10 || n%100>=20) ? 1 : 2;\n"
"X-Generator: Lokalize 23.04.3\n"

#: core/textautogeneratechatsmodel.cpp:74
#, kde-format
msgid "New Chat..."
msgstr "–ù–æ–≤–µ —Å–ø—ñ–ª–∫—É–≤–∞–Ω–Ω—è‚Ä¶"

#: core/textautogeneratechatsmodel.cpp:146
#, kde-format
msgid "Favorite"
msgstr "–£–ª—é–±–ª–µ–Ω–µ"

#: core/textautogeneratechatsmodel.cpp:148
#, kde-format
msgid "Today"
msgstr "–°—å–æ–≥–æ–¥–Ω—ñ"

#: core/textautogeneratechatsmodel.cpp:150
#, kde-format
msgid "7 days previous"
msgstr "7 –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ—Ö –¥–Ω—ñ–≤"

#: core/textautogeneratechatsmodel.cpp:152
#, kde-format
msgid "30 days previous"
msgstr "30 –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ—Ö –¥–Ω—ñ–≤"

#: core/textautogeneratechatsmodel.cpp:154
#, kde-format
msgid "Later"
msgstr "–ü—ñ–∑–Ω—ñ—à–µ"

#: core/textautogeneratechatsmodel.cpp:156
#, kde-format
msgid "Unknown"
msgstr "–ù–µ–≤—ñ–¥–æ–º–æ"

#: core/textautogenerateengineutil.cpp:15 plugins/ollama/ollamaclient.cpp:30
#, kde-format
msgid "Ollama"
msgstr "Ollama"

#: core/textautogeneratemessagesmodel.cpp:68
#, kde-format
msgid ""
"Engine: %1\n"
"Model: %2"
msgstr ""
"–†—É—à—ñ–π: %1\n"
"–ú–æ–¥–µ–ª—å: %2"

#: core/textautogeneratesearchmessageutils.cpp:34
#, kde-format
msgid "Go to message"
msgstr "–ü–µ—Ä–µ–π—Ç–∏ –¥–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è"

#: core/textautogeneratetextclient.cpp:33
#, kde-format
msgid "Local"
msgstr "–õ–æ–∫–∞–ª—å–Ω–∏–π"

#: core/textautogeneratetextclient.cpp:35
#, kde-format
msgid "Network"
msgstr "–ú–µ—Ä–µ–∂–µ–≤–∏–π"

#: plugins/mistral/mistralclient.cpp:30
#, kde-format
msgid "Mistral AI"
msgstr "–®–Ü Mistral"

#: plugins/mistral/mistralconfiguredialog.cpp:25
#, kde-format
msgctxt "@title:window"
msgid "Configure Mistral IA"
msgstr "–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –®–Ü Mistral"

#: plugins/mistral/mistralconfigurewidget.cpp:27
#: plugins/openai/openaiconfigurewidget.cpp:27
#, kde-format
msgid "Api Key:"
msgstr "–ö–ª—é—á API:"

#: plugins/mistral/mistralmanager.cpp:37 plugins/ollama/ollamamanager.cpp:103
#, kde-format
msgid "Failed to connect to interface at %1: %2"
msgstr "–ù–µ –≤–¥–∞–ª–æ—Å—è –≤—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –∑'—î–¥–Ω–∞–Ω–Ω—è –∑ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º –Ω–∞ %1: %2"

#. i18n: ectx: label, entry (ServerUrl), group (Ollama)
#. i18n: ectx: label, entry (ServerUrl), group (Mistral)
#: plugins/mistral/mistralsettings.kcfg:14
#: plugins/ollama/ollamasettings.kcfg:14
#, kde-format
msgid "The URL to the Ollama instance"
msgstr "–ê–¥—Ä–µ—Å–∞ –µ–∫–∑–µ–º–ø–ª—è—Ä–∞ Ollama"

#. i18n: ectx: label, entry (SystemPrompt), group (LLM)
#: plugins/mistral/mistralsettings.kcfg:20
#: plugins/ollama/ollamasettings.kcfg:20
#, kde-format
msgid "The system prompt for the LLM"
msgstr "–°–∏—Å—Ç–µ–º–Ω–∏–π –∑–∞–ø–∏—Ç –¥–æ –≤–µ–ª–∏–∫–æ—ó –º–æ–≤–Ω–æ—ó –º–æ–¥–µ–ª—ñ"

#. i18n: ectx: label, entry (Model), group (LLM)
#: plugins/mistral/mistralsettings.kcfg:32
#: plugins/ollama/ollamasettings.kcfg:32
#, kde-format
msgid "The model used to generate responses"
msgstr "–ú–æ–¥–µ–ª—å, —è–∫—É –±—É–¥–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π"

#: plugins/ollama/modelsmanager/ollamamodeldialog.cpp:24
#, kde-format
msgctxt "@title:window"
msgid "Manage Ollama Models"
msgstr "–ö–µ—Ä—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—è–º–∏ Ollama"

#: plugins/ollama/modelsmanager/ollamamodelinfo.cpp:81
#, kde-format
msgid "Tools"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelinfo.cpp:83
#, kde-format
msgid "Small"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelinfo.cpp:85
#, kde-format
msgid "Medium"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelinfo.cpp:87
#, kde-format
msgid "Big"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelinfo.cpp:89
#, kde-format
msgid "Huge"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelinfo.cpp:91
#, kde-format
msgid "Multilingual"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelinfo.cpp:93
#, kde-format
msgid "Code"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelinfo.cpp:95
#, kde-format
msgid "Math"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelinfo.cpp:97
#, kde-format
msgid "Vision"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelinfo.cpp:99
#, kde-format
msgid "Embedding"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelinfo.cpp:101
#, kde-format
msgid "Reasoning"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelsearchwidget.cpp:24
#, kde-format
msgctxt "@info:placeholder"
msgid "Search Model‚Ä¶"
msgstr "–®—É–∫–∞—Ç–∏ –º–æ–¥–µ–ª—å‚Ä¶"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:15
#, kde-format
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to the Llama 3.1 405B model."
msgstr ""
"–ù–æ–≤–∞ —Å—É—á–∞—Å–Ω–∞ –º–æ–¥–µ–ª—å 70B. Llama 3.3 70B –ø—Ä–æ–ø–æ–Ω—É—î –∞–Ω–∞–ª–æ–≥—ñ—á–Ω—É –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å "
"–ø–æ—Ä—ñ–≤–Ω—è–Ω–æ –∑ –º–æ–¥–µ–ª–ª—é Llama 3.1 405B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:16
#, kde-format
msgid "QwQ is the reasoning model of the Qwen series."
msgstr "QwQ ‚Äì —Ü–µ –º–æ–¥–µ–ª—å –ø—Ä–∏–π–Ω—è—Ç—Ç—è —Ä—ñ—à–µ–Ω—å —Å–µ—Ä—ñ—ó Qwen."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:18
#, kde-format
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""
"Llama 3.2 Vision ‚Äî —Ü–µ –∑–±—ñ—Ä–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –æ–±—Ä–∞–∑–Ω–æ–≥–æ –º–∏—Å–ª–µ–Ω–Ω—è –∑ "
"–Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è–º–∏ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ–π —Ä–æ–∑–º—ñ—Ä—ñ–≤ 11B —Ç–∞ 90B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:19
#, kde-format
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr "Meta Llama 3.2 –ø–æ—Å—Ç–∞—á–∞—î—Ç—å—Å—è —É —Ñ–æ—Ä–º—ñ –∫–æ–º–ø–∞–∫—Ç–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π 1B —Ç–∞ 3B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:20
#, kde-format
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr ""
"Llama 3.1 ‚Äî —Ü–µ –Ω–æ–≤–∞ —Å—É—á–∞—Å–Ω–∞ –º–æ–¥–µ–ª—å –≤—ñ–¥ Meta, –¥–æ—Å—Ç—É–ø–Ω–∞ —É —Ä–æ–∑–º—ñ—Ä–∞—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ "
"8B, 70B —Ç–∞ 405B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:21
#, kde-format
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3: –Ω–∞–π–ø–æ—Ç—É–∂–Ω—ñ—à–∞ –≤—ñ–¥–∫—Ä–∏—Ç–æ –¥–æ—Å—Ç—É–ø–Ω–∞ LLM –Ω–∞ —Ü–µ–π –º–æ–º–µ–Ω—Ç —á–∞—Å—É"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:22
#, kde-format
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr "–ú–æ–¥–µ–ª—å 7B, —è–∫—É –≤–∏–ø—É—â–µ–Ω–æ Mistral AI, –æ–Ω–æ–≤–ª–µ–Ω–∞ –¥–æ –≤–µ—Ä—Å—ñ—ó 0.3."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:23
#, kde-format
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr ""
"–í–∏—Å–æ–∫–æ–ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–∞ –º–æ–¥–µ–ª—å –∑ –≤—ñ–¥–∫—Ä–∏—Ç–∏–º –≤–±—É–¥–æ–≤—É–≤–∞–Ω–Ω—è–º –∑ –≤–µ–ª–∏–∫–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∏–º "
"–≤—ñ–∫–Ω–æ–º —Ç–æ–∫–µ–Ω—ñ–≤."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:24
#, kde-format
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr ""
"Gemma ‚Äî —Ü–µ —Å—ñ–º–µ–π—Å—Ç–≤–æ –Ω–µ–≤–∏–±–∞–≥–ª–∏–≤–∏—Ö, —Å—É—á–∞—Å–Ω–∏—Ö –≤—ñ–¥–∫—Ä–∏—Ç–∏—Ö –º–æ–¥–µ–ª–µ–π, —Å—Ç–≤–æ—Ä–µ–Ω–∏—Ö "
"Google DeepMind. –û–Ω–æ–≤–ª–µ–Ω–æ –¥–æ –≤–µ—Ä—Å—ñ—ó 1.1."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:25
#, kde-format
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr ""
"Qwen 1.5 ‚Äî —Ü–µ —Å–µ—Ä—ñ—è –≤–µ–ª–∏–∫–∏—Ö –º–æ–≤–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –≤—ñ–¥ Alibaba Cloud, —â–æ –æ—Ö–æ–ø–ª—é—é—Ç—å "
"–≤—ñ–¥ 0,5 –¥–æ 110 –º—ñ–ª—å—è—Ä–¥—ñ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:26
#, kde-format
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr "Qwen2 ‚Äî —Ü–µ –Ω–æ–≤–∞ —Å–µ—Ä—ñ—è –≤–µ–ª–∏–∫–∏—Ö –º–æ–≤–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –≤—ñ–¥ –≥—Ä—É–ø–∏ Alibaba"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:27
#, kde-format
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 ‚Äî —Ü–µ —Å—ñ–º–µ–π—Å—Ç–≤–æ –Ω–µ–≤–∏–±–∞–≥–ª–∏–≤–∏—Ö –≤—ñ–¥–∫—Ä–∏—Ç–∏—Ö –º–æ–¥–µ–ª–µ–π 3B (Mini) —Ç–∞ 14B "
"(Medium) —Å—ñ–º–µ–π—Å—Ç–≤–∞ –Ω–∞–π—Å—É—á–∞—Å–Ω—ñ—à–∏—Ö –º–æ–¥–µ–ª–µ–π –≤—ñ–¥ Microsoft."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:28
#, kde-format
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr ""
"Llama 2 ‚Äî —Ü–µ –∑–±—ñ—Ä–∫–∞ –±–∞–∑–æ–≤–∏—Ö –º–æ–≤–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –∑ –∫—ñ–ª—å–∫—ñ—Å—Ç—é –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –≤—ñ–¥ 7B –¥–æ "
"70B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:30
#, kde-format
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""
"–ú–æ–¥–µ–ª—ñ Qwen2.5 –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω—ñ –Ω–∞ –Ω–æ–≤—ñ—Ç–Ω—å–æ–º—É –≤–µ–ª–∏–∫–æ–º–∞—Å—à—Ç–∞–±–Ω–æ–º—É –Ω–∞–±–æ—Ä—ñ "
"–¥–∞–Ω–∏—Ö –≤—ñ–¥ Alibaba, —â–æ –æ—Ö–æ–ø–ª—é—î –¥–æ 18 —Ç—Ä–∏–ª—å–π–æ–Ω—ñ–≤ —Ç–æ–∫–µ–Ω—ñ–≤. –£ –º–æ–¥–µ–ª—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–æ "
"–ø—ñ–¥—Ç—Ä–∏–º–∫—É –¥–æ 128 —Ç–∏—Å—è—á —Ç–æ–∫–µ–Ω—ñ–≤ —Ç–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫—É –±–∞–≥–∞—Ç—å–æ—Ö –º–æ–≤."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:32
#, kde-format
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr ""
"Google Gemma 2 ‚Äî —Ü–µ –≤–∏—Å–æ–∫–æ–ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–∞ —Ç–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∞ –º–æ–¥–µ–ª—å, –¥–æ—Å—Ç—É–ø–Ω–∞ —É —Ç—Ä—å–æ—Ö "
"—Ä–æ–∑–º—ñ—Ä–∞—Ö: 2B, 9B —Ç–∞ 27B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:34
#, kde-format
msgid ""
"LLaVA is a novel end-to-end trained large multimodal model that combines a "
"vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"LLaVA ‚Äî —Ü–µ –Ω–æ–≤–∞ –ø—Ä–∏–¥–∞—Ç–Ω–∞ –¥–æ –Ω–∞–≤—á–∞–Ω–Ω—è –≤–µ–ª–∏–∫–∞ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞ –º–æ–¥–µ–ª—å, —è–∫–∞ "
"–ø–æ—î–¥–Ω—É—î –≤—ñ–∑—É–∞–ª—å–Ω–∏–π –∫–æ–¥–µ—Ä —Ç–∞ Vicuna –¥–ª—è –∑–∞–≥–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É –∑–æ–±—Ä–∞–∂–µ–Ω—å —Ç–∞ –º–æ–≤. "
"–û–Ω–æ–≤–ª–µ–Ω–æ –¥–æ –≤–µ—Ä—Å—ñ—ó 1.6."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:36
#, kde-format
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr ""
"–í–µ–ª–∏–∫–∞ –º–æ–≤–Ω–∞ –º–æ–¥–µ–ª—å, —è–∫–∞ –º–æ–∂–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤—ñ –ø—ñ–¥–∫–∞–∑–∫–∏ –¥–ª—è "
"–ø–æ—Ä–æ–¥–∂–µ–Ω–Ω—è —Ç–∞ –∫–æ–º–µ–Ω—Ç—É–≤–∞–Ω–Ω—è –∫–æ–¥—É."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:38
#, kde-format
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""
"–ù–∞–π–Ω–æ–≤—ñ—à–∞ —Å–µ—Ä—ñ—è –º–æ–¥–µ–ª–µ–π Qwen, –æ—Ä—ñ—î–Ω—Ç–æ–≤–∞–Ω–∏—Ö –Ω–∞ –∫–æ–¥, –∑—ñ –∑–Ω–∞—á–Ω–∏–º–∏ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è–º–∏ "
"—É –ø–æ—Ä–æ–¥–∂–µ–Ω–Ω—ñ –∫–æ–¥—É, –æ–±“ë—Ä—É–Ω—Ç—É–≤–∞–Ω–Ω—ñ –∫–æ–¥—É —Ç–∞ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—ñ –∫–æ–¥—É."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:39
#, kde-format
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr ""
"–ù–∞–π—Å—É—á–∞—Å–Ω—ñ—à–∞ –º–æ–¥–µ–ª—å 12B –∑ –¥–æ–≤–∂–∏–Ω–æ—é –∫–æ–Ω—Ç–µ–∫—Å—Ç—É 128k, —Å—Ç–≤–æ—Ä–µ–Ω–∞ Mistral AI —É "
"—Å–ø—ñ–≤–ø—Ä–∞—Ü—ñ –∑ NVIDIA."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:40
#, kde-format
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"–ü—Ä–æ—î–∫—Ç TinyLlama ‚Äî —Ü–µ –≤—ñ–¥–∫—Ä–∏—Ç–∞ —ñ–Ω—ñ—Ü—ñ–∞—Ç–∏–≤–∞ –∑ –Ω–∞–≤—á–∞–Ω–Ω—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—ó –º–æ–¥–µ–ª—ñ Llama "
"–æ–±—Å—è–≥–æ–º 1,1 –º–ª—Ä–¥ –Ω–∞ 3 —Ç—Ä–∏–ª—å–π–æ–Ω–∞—Ö —Ç–æ–∫–µ–Ω—ñ–≤."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:41
#, kde-format
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "–ù–∞–π—Å—É—á–∞—Å–Ω—ñ—à–∞ –≤–µ–ª–∏–∫–∞ –º–æ–¥–µ–ª—å –∑ –≤–±—É–¥–æ–≤—É–≤–∞–Ω–Ω—è–º –≤—ñ–¥ mixedbread.ai"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:43
#, kde-format
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 ‚Äî —Ü–µ –Ω–∞—Å—Ç—É–ø–Ω–µ –ø–æ–∫–æ–ª—ñ–Ω–Ω—è –ø—Ä–æ–∑–æ—Ä–æ –Ω–∞–≤—á–µ–Ω–∏—Ö –í–ú–ú –∑ –≤—ñ–¥–∫—Ä–∏—Ç–∏–º –∫–æ–¥–æ–º, "
"—è–∫–µ –¥–æ—Å—Ç—É–ø–Ω–µ —É —Ç—Ä—å–æ—Ö —Ä–æ–∑–º—ñ—Ä–∞—Ö: –∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ 3B, 7B —Ç–∞ 15B."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:44
#, kde-format
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"–ù–∞–±—ñ—Ä Mixture of Experts (MoE) –º–æ–¥–µ–ª—ñ –∑ –≤—ñ–¥–∫—Ä–∏—Ç–∏–º–∏ –≤–∞–≥–∞–º–∏ –≤—ñ–¥ Mistral AI –∑ "
"—Ä–æ–∑–º—ñ—Ä–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ 8x7b —Ç–∞ 8x22b."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:46
#, kde-format
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"–ù–µ—Ü–µ–Ω–∑—É—Ä–æ–≤–∞–Ω—ñ, —Ç–æ—á–Ω–æ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω—ñ –º–æ–¥–µ–ª—ñ 8x7b —Ç–∞ 8x22b, –∑–∞—Å–Ω–æ–≤–∞–Ω—ñ –Ω–∞ —Å—É–º—ñ—à—ñ "
"–µ–∫—Å–ø–µ—Ä—Ç–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π Mixtral, —è–∫–∞ —á—É–¥–æ–≤–æ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å –¥–ª—è –∑–∞–≤–¥–∞–Ω—å –∫–æ–¥—É–≤–∞–Ω–Ω—è. "
"–†–æ–∑—Ä–æ–±–Ω–∏–∫: –ï—Ä—ñ–∫ –•–∞—Ä—Ç—Ñ–æ—Ä–¥."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:49
#, kde-format
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma ‚Äî —Ü–µ –∑–±—ñ—Ä–∫–∞ –ø–æ—Ç—É–∂–Ω–∏—Ö, –Ω–µ–≤–∏–±–∞–≥–ª–∏–≤–∏—Ö –º–æ–¥–µ–ª–µ–π, —è–∫—ñ –º–æ–∂—É—Ç—å –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏ "
"—Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è –∑ –Ω–∞–ø–∏—Å–∞–Ω–Ω—è –∫–æ–¥—É, —Ç–∞–∫—ñ —è–∫ –∞–≤—Ç–æ–¥–æ–ø–æ–≤–Ω–µ–Ω–Ω—è –∫–æ–¥—É –º–µ—Ç–æ–¥–æ–º "
"–∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –ø–æ—Å–µ—Ä–µ–¥–∏–Ω—ñ, –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –∫–æ–¥—É, —Ä–æ–∑—É–º—ñ–Ω–Ω—è –ø—Ä–∏—Ä–æ–¥–Ω–æ—ó –º–æ–≤–∏, –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω—ñ "
"–º—ñ—Ä–∫—É–≤–∞–Ω–Ω—è —Ç–∞ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ–π."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:52
#, kde-format
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"–ú–æ–¥–µ–ª—å –º–æ–≤ –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è Mixture-of-Experts –∑ –≤—ñ–¥–∫—Ä–∏—Ç–∏–º –≤–∏—Ö—ñ–¥–Ω–∏–º –∫–æ–¥–æ–º, —è–∫–∞ "
"–ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—à–∞, —è–∫—â–æ –ø–æ—Ä—ñ–≤–Ω—é–≤–∞—Ç–∏ –∑ GPT4-Turbo, —É –∑–∞–≤–¥–∞–Ω–Ω—è—Ö, —â–æ —Å—Ç–æ—Å—É—é—Ç—å—Å—è "
"–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–æ–¥—É."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:54
#, kde-format
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr ""
"Phi-2: –º–æ–≤–Ω–∞ –º–æ–¥–µ–ª—å –æ–±—Å—è–≥–æ–º 2,7 –º–ª—Ä–¥, —Ä–æ–∑—Ä–æ–±–ª–µ–Ω–∞ Microsoft Research, —è–∫–∞ "
"–¥–µ–º–æ–Ω—Å—Ç—Ä—É—î –≤–∏–¥–∞—Ç–Ω—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ –∞–Ω–∞–ª—ñ–∑—É —Ç–∞ —Ä–æ–∑—É–º—ñ–Ω–Ω—è –º–æ–≤–∏."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:55
#, kde-format
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "–ù–µ—Ü–µ–Ω–∑—É—Ä–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å Llama 2 –≤—ñ–¥ –î–∂–æ—Ä–¥–∂–∞ –°–∞–Ω–≥–∞ —Ç–∞ –î–∂–∞—Ä—Ä–∞–¥–∞ –•–æ—É–ø–∞."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:56
#, kde-format
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder ‚Äî —Ü–µ –ø–æ—Ç—É–∂–Ω–∞ –º–æ–¥–µ–ª—å –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è, –Ω–∞–≤—á–µ–Ω–∞ –Ω–∞ –¥–≤–æ—Ö —Ç—Ä–∏–ª—å–π–æ–Ω–∞—Ö "
"–∑—Ä–∞–∑–∫—ñ–≤ –∫–æ–¥—É —Ç–∞ —Ç–æ–∫–µ–Ω—ñ–≤ –ø—Ä–∏—Ä–æ–¥–Ω–æ—ó –º–æ–≤–∏."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:57
#, kde-format
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr ""
"–ù–∞–±—ñ—Ä –º–æ–¥–µ–ª–µ–π –≤–±—É–¥–æ–≤—É–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É –≤—ñ–¥ Snowflake, –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏—Ö –¥–ª—è "
"–ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:59
#, kde-format
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"–ù–∞–π—Å—É—á–∞—Å–Ω—ñ—à–∞ –≤–µ–ª–∏–∫–æ–º–æ–≤–Ω–∞ –º–æ–¥–µ–ª—å –≤—ñ–¥ Microsoft AI –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–æ—é –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—é "
"—É —Å–∫–ª–∞–¥–Ω–∏—Ö —á–∞—Ç–∞—Ö, –±–∞–≥–∞—Ç–æ–º–æ–≤–Ω–∏—Ö –≤–∏–ø–∞–¥–∫–∞—Ö, –º—ñ—Ä–∫—É–≤–∞–Ω–Ω—è—Ö —Ç–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—ñ –∞–≥–µ–Ω—Ç—ñ–≤."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:61
#, kde-format
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr ""
"–ù–µ—Ü–µ–Ω–∑—É—Ä–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å Dolphin –Ω–∞ –±–∞–∑—ñ Mistral, —è–∫–∞ —á—É–¥–æ–≤–æ —Å–ø—Ä–∞–≤–ª—è—î—Ç—å—Å—è –∑ "
"–∑–∞–≤–¥–∞–Ω–Ω—è–º–∏ –∫–æ–¥—É–≤–∞–Ω–Ω—è. –û–Ω–æ–≤–ª–µ–Ω–æ –¥–æ –≤–µ—Ä—Å—ñ—ó 2.8."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:63
#, kde-format
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9 ‚Äî —Ü–µ –Ω–æ–≤–∞ –º–æ–¥–µ–ª—å —Ä–æ–∑–º—ñ—Ä—ñ–≤ 8B —Ç–∞ 70B –≤—ñ–¥ –ï—Ä—ñ–∫–∞ –•–∞—Ä—Ç—Ñ–æ—Ä–¥–∞, "
"–∑–∞—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ Llama 3, —è–∫–∞ –º–∞—î —Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω—ñ –Ω–∞–≤–∏—á–∫–∏ –Ω–∞–≤—á–∞–Ω–Ω—è, —Ä–æ–∑–º–æ–≤–Ω–æ—ó "
"–¥—ñ—è–ª—å–Ω–æ—Å—Ç—ñ —Ç–∞ –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:65
#, kde-format
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 ‚Äî —Ü–µ –≤–∏—Å–æ–∫–æ–ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–∞ –¥–≤–æ–º–æ–≤–Ω–∞ –º–æ–≤–Ω–∞ –º–æ–¥–µ–ª—å."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:66
#, kde-format
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr ""
"Command R ‚Äî —Ü–µ –≤–µ–ª–∏–∫–∞ –º–æ–≤–Ω–∞ –º–æ–¥–µ–ª—å, –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –¥–ª—è —Ä–æ–∑–º–æ–≤–Ω–æ—ó –≤–∑–∞—î–º–æ–¥—ñ—ó —Ç–∞ "
"–¥–æ–≤–≥–∏—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∏—Ö –∑–∞–≤–¥–∞–Ω—å."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:67
#, kde-format
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr ""
"–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∞ –º–æ–¥–µ–ª—å –∑ –¥—ñ–∞–ø–∞–∑–æ–Ω–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –≤—ñ–¥ 3 –¥–æ 70 –º—ñ–ª—å—è—Ä–¥—ñ–≤, —â–æ "
"–ø—ñ–¥—Ö–æ–¥–∏—Ç—å –¥–ª—è –æ–±–ª–∞–¥–Ω–∞–Ω–Ω—è –ø–æ—á–∞—Ç–∫–æ–≤–æ–≥–æ —Ä—ñ–≤–Ω—è."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:68
#, kde-format
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr ""
"–ú–æ–¥–µ–ª—å LLaVA, –¥–æ–æ–ø—Ä–∞—Ü—å–æ–≤–∞–Ω–∞ –∑ Llama 3 Instruct, –∑ –∫—Ä–∞—â–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤ "
"–∫—ñ–ª—å–∫–æ—Ö —Ä–µ–π—Ç–∏–Ω–≥–∞—Ö —à–≤–∏–¥–∫–æ–¥—ñ—ó."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:70
#, kde-format
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr ‚Äî —Ü–µ —Å–µ—Ä—ñ—è –≤–¥–æ—Å–∫–æ–Ω–∞–ª–µ–Ω–∏—Ö –≤–µ—Ä—Å—ñ–π –º–æ–¥–µ–ª–µ–π Mistral —Ç–∞ Mixtral, —è–∫—ñ "
"–Ω–∞–≤—á–µ–Ω—ñ –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏ —Ä–æ–ª—å –∫–æ—Ä–∏—Å–Ω–∏—Ö –ø–æ–º—ñ—á–Ω–∏–∫—ñ–≤."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:71
#, kde-format
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr ""
"–ù–µ–≤–∏–±–∞–≥–ª–∏–≤–∞ –º–æ–¥–µ–ª—å —à—Ç—É—á–Ω–æ–≥–æ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É –∑ 3,8 –º—ñ–ª—å—è—Ä–¥–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤, —è–∫–∞ –∑–∞ "
"–ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—é –ø–µ—Ä–µ–≤–µ—Ä—à—É—î –∞–Ω–∞–ª–æ–≥—ñ—á–Ω—ñ —Ç–∞ –±—ñ–ª—å—à—ñ –º–æ–¥–µ–ª—ñ."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:72
#, kde-format
msgid "Embedding models on very large sentence level datasets."
msgstr "–ú–æ–¥–µ–ª—ñ –∑ –≤–∫–ª–∞–¥–∞–Ω–Ω—è–º –¥–ª—è –¥—É–∂–µ –≤–µ–ª–∏–∫–∏—Ö –Ω–∞–±–æ—Ä—ñ–≤ –¥–∞–Ω–∏—Ö –Ω–∞ —Ä—ñ–≤–Ω—ñ —Ä–µ—á–µ–Ω—å."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:73
#, kde-format
msgid ""
"Codestral is Mistral AI‚Äôs first-ever code model designed for code generation "
"tasks."
msgstr ""
"Codestral ‚Äî —Ü–µ –ø–µ—Ä—à–∞ –≤ —ñ—Å—Ç–æ—Ä—ñ—ó –º–æ–¥–µ–ª—å –∫–æ–¥—É –®–Ü Mistral, —Ä–æ–∑—Ä–æ–±–ª–µ–Ω–∞ –¥–ª—è "
"–∑–∞–≤–¥–∞–Ω—å –ø–æ—Ä–æ–¥–∂–µ–Ω–Ω—è –ø—Ä–æ–≥—Ä–∞–º–Ω–æ–≥–æ –∫–æ–¥—É."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:74
#, kde-format
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr ""
"StarCoder ‚Äî —Ü–µ –º–æ–¥–µ–ª—å –ø–æ—Ä–æ–¥–∂–µ–Ω–Ω—è –ø—Ä–æ–≥—Ä–∞–º–Ω–æ–≥–æ –∫–æ–¥—É, –Ω–∞–≤—á–µ–Ω–∞ –Ω–∞ –ø–æ–Ω–∞–¥ 80 –º–æ–≤–∞—Ö "
"–ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:75
#, kde-format
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr ""
"–ú–æ–¥–µ–ª—å —á–∞—Ç—É –∑–∞–≥–∞–ª—å–Ω–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ Llama —Ç–∞ Llama 2 –∑ —Ä–æ–∑–º—ñ—Ä–∞–º–∏ "
"–∫–æ–Ω—Ç–µ–∫—Å—Ç—É –≤—ñ–¥ 2K –¥–æ 16K."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:76
#, kde-format
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr "–°—ñ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –≤—ñ–¥–∫—Ä–∏—Ç–æ—ó –æ—Å–Ω–æ–≤–∏ –≤—ñ–¥ IBM –¥–ª—è Code Intelligence"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:78
#, kde-format
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca ‚Äî —Ü–µ –º–æ–¥–µ–ª—å —ñ–∑ 7 –º—ñ–ª—å—è—Ä–¥–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤, –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–∞ –Ω–∞ "
"–æ—Å–Ω–æ–≤—ñ –º–æ–¥–µ–ª—ñ Mistral 7B –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –Ω–∞–±–æ—Ä—É –¥–∞–Ω–∏—Ö OpenOrca."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:79
#, kde-format
msgid ""
"A family of small models with 135M, 360M, and 1.7B parameters, trained on a "
"new high-quality dataset."
msgstr ""
"–°—ñ–º–µ–π—Å—Ç–≤–æ –Ω–µ–≤–µ–ª–∏–∫–∏—Ö –º–æ–¥–µ–ª–µ–π —ñ–∑ 135 –º—ñ–ª—å–π–æ–Ω–∞–º–∏, 360 –º—ñ–ª—å–π–æ–Ω–∞–º–∏ —Ç–∞ 1,7 "
"–º—ñ–ª—å—è—Ä–¥–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –Ω–∞–≤—á–µ–Ω–∏—Ö –Ω–∞ –Ω–æ–≤–æ–º—É –≤–∏—Å–æ–∫–æ—è–∫—ñ—Å–Ω–æ–º—É –Ω–∞–±–æ—Ä—ñ –¥–∞–Ω–∏—Ö."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:81
#, kde-format
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored ‚Äî —Ü–µ –º–æ–¥–µ–ª—å —ñ–∑ 7B, 13B —Ç–∞ 30B –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, "
"–∑–∞—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ –Ω–µ—Ü–µ–Ω–∑—É—Ä–æ–≤–∞–Ω—ñ–π Llama 2 –≤—ñ–¥ –ï—Ä—ñ–∫–∞ –ì–∞—Ä—Ç—Ñ–æ—Ä–¥–∞."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:82
#, kde-format
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr ""
"–ú–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤—ñ Llama 2, –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–∞ –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è —Å–ø—ñ–ª–∫—É–≤–∞–Ω–Ω—è –∫–∏—Ç–∞–π—Å—å–∫–æ—é "
"–º–æ–≤–æ—é."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:84
#, kde-format
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr ""
"BGE-M3 ‚Äì —Ü–µ –Ω–æ–≤–∞ –º–æ–¥–µ–ª—å –≤—ñ–¥ BAAI, —è–∫–∞ –≤–∏—Ä—ñ–∑–Ω—è—î—Ç—å—Å—è —Å–≤–æ—î—é —É–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω—ñ—Å—Ç—é, "
"–±–∞–≥–∞—Ç–æ—Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—é, –±–∞–≥–∞—Ç–æ–º–æ–≤–Ω—ñ—Å—Ç—é —Ç–∞ –±–∞–≥–∞—Ç–æ–≥—Ä–∞–Ω–Ω—ñ—Å—Ç—é."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:85
#, kde-format
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr ""
"–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è —Å—Ü–µ–Ω–∞—Ä—ñ—ó–≤ —Ä–æ–∑—Ä–æ–±–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–Ω–æ–≥–æ –∑–∞–±–µ–∑–ø–µ—á–µ–Ω–Ω—è –Ω–∞ "
"–æ—Å–Ω–æ–≤—ñ —à—Ç—É—á–Ω–æ–≥–æ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É, –≤–∫–ª—é—á–Ω–æ —ñ–∑ –∞–≤—Ç–æ–¥–æ–ø–æ–≤–Ω–µ–Ω–Ω—è–º –∫–æ–¥—É."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:87
#, kde-format
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"–°—ñ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –∑ –≤—ñ–¥–∫—Ä–∏—Ç–∏–º –∫–æ–¥–æ–º, —â–æ –Ω–∞–≤—á–∞–ª–∏—Å—è –Ω–∞ —à–∏—Ä–æ–∫–æ–º—É —Å–ø–µ–∫—Ç—Ä—ñ –¥–∞–Ω–∏—Ö, "
"–ø–µ—Ä–µ–≤–µ—Ä—à—É—é—á–∏ ChatGPT –∑–∞ —Ä—ñ–∑–Ω–∏–º–∏ —Ç–µ—Å—Ç–∞–º–∏. –û–Ω–æ–≤–ª–µ–Ω–æ –¥–æ –≤–µ—Ä—Å—ñ—ó 3.5-0106."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:88
#, kde-format
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr ""
"Aya 23, –≤–∏–ø—É—â–µ–Ω–∞ –∫–æ–º–ø–∞–Ω—ñ—î—é Cohere, ‚Äî —Ü–µ –Ω–æ–≤–µ —Å—ñ–º–µ–π—Å—Ç–≤–æ —Å—É—á–∞—Å–Ω–∏—Ö –±–∞–≥–∞—Ç–æ–º–æ–≤–Ω–∏—Ö "
"–º–æ–¥–µ–ª–µ–π, —É —è–∫–∏—Ö –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–æ –ø—ñ–¥—Ç—Ä–∏–º–∫—É 23 –º–æ–≤."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:89
#, kde-format
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr ""
"CodeQwen1.5 ‚Äî —Ü–µ –≤–µ–ª–∏–∫–∞ –º–æ–≤–Ω–∞ –º–æ–¥–µ–ª—å, –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω–∞ –Ω–∞ –≤–µ–ª–∏–∫—ñ–π "
"–∫—ñ–ª—å–∫–æ—Å—Ç—ñ –¥–∞–Ω–∏—Ö –ø—Ä–æ–≥—Ä–∞–º–Ω–æ–≥–æ –∫–æ–¥—É."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:90
#, kde-format
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr ""
"–ü–æ—Ç—É–∂–Ω–µ —Å—ñ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –≤—ñ–¥ Nous Research, —è–∫–µ —á—É–¥–æ–≤–æ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å –¥–ª—è "
"–Ω–∞—É–∫–æ–≤–∏—Ö –æ–±–≥–æ–≤–æ—Ä–µ–Ω—å —Ç–∞ –∑–∞–≤–¥–∞–Ω—å –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:92
#, kde-format
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+ ‚Äî —Ü–µ –ø–æ—Ç—É–∂–Ω–∞, –º–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω–∞ –≤–µ–ª–∏–∫–∞ –º–æ–≤–Ω–∞ –º–æ–¥–µ–ª—å –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è, "
"—Å–ø–µ—Ü—ñ–∞–ª—å–Ω–æ —Ä–æ–∑—Ä–æ–±–ª–µ–Ω–∞ –¥–ª—è –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è —É—Å–ø—ñ—Ö—É –≤ —Ä–µ–∞–ª—å–Ω–∏—Ö –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∏—Ö "
"–≤–∏–ø–∞–¥–∫–∞—Ö –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:93
#, kde-format
msgid "State-of-the-art code generation model"
msgstr "–ù–∞–π—Å—É—á–∞—Å–Ω—ñ—à–∞ –º–æ–¥–µ–ª—å –ø–æ—Ä–æ–¥–∂–µ–Ω–Ω—è –ø—Ä–æ–≥—Ä–∞–º–Ω–æ–≥–æ –∫–æ–¥—É"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:95
#, kde-format
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"Stable Code 3B ‚Äî —Ü–µ –º–æ–¥–µ–ª—å –∫–æ–¥—É–≤–∞–Ω–Ω—è –∑ –≤–∞—Ä—ñ–∞–Ω—Ç–∞–º–∏ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ–π —Ç–∞ "
"–∞–≤—Ç–æ–¥–æ–ø–æ–≤–Ω–µ–Ω–Ω—è –∫–æ–¥—É, —â–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –º–æ–¥–µ–ª—è–º, —Ç–∞–∫–∏–º —è–∫ Code Llama 7B, —è–∫—ñ –≤ "
"2,5 —Ä–∞–∑–∏ –±—ñ–ª—å—à—ñ."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:97
#, kde-format
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"–ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞ –º–æ–¥–µ–ª—å —ñ–∑ 1,1 –º–ª—Ä–¥ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤, –Ω–∞–≤—á–µ–Ω–∞ –Ω–∞ –Ω–æ–≤–æ–º—É –Ω–∞–±–æ—Ä—ñ "
"–¥–∞–Ω–∏—Ö Dolphin 2.8 –ï—Ä—ñ–∫–æ–º –•–∞—Ä—Ç—Ñ–æ—Ä–¥–æ–º —Ç–∞ –∑–∞—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ TinyLlama."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:98
#, kde-format
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5 ‚Äî —Ü–µ –º–æ–¥–µ–ª—å —ñ–∑ 7B –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –¥–æ–æ–ø—Ä–∞—Ü—å–æ–≤–∞–Ω–∞ Teknium –Ω–∞ "
"Mistral –∑ –ø–æ–≤–Ω—ñ—Å—Ç—é –≤—ñ–¥–∫—Ä–∏—Ç–∏–º–∏ –Ω–∞–±–æ—Ä–∞–º–∏ –¥–∞–Ω–∏—Ö."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:100
#, kde-format
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""
"Mistral Large 2 ‚Äî —Ü–µ –Ω–æ–≤–∞ —Ñ–ª–∞–≥–º–∞–Ω—Å—å–∫–∞ –º–æ–¥–µ–ª—å Mistral, —è–∫–∞ –∑–Ω–∞—á–Ω–æ —Ä–æ–∑—à–∏—Ä—é—î "
"–º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ –ø–æ—Ä–æ–¥–∂–µ–Ω–Ω—è –ø—Ä–æ–≥—Ä–∞–º–Ω–æ–≥–æ –∫–æ–¥—É, –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ —Ç–∞ –ª–æ–≥—ñ—á–Ω–∏—Ö —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—ñ–≤, "
"–º–∞—î –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–µ –≤—ñ–∫–Ω–æ —Ä–æ–∑–º—ñ—Ä–æ–º 128 —Ç–∏—Å. —Ç–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫—É –¥–µ—Å—è—Ç–∫—ñ–≤ –º–æ–≤."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:103
#, kde-format
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""
"Qwen2 Math ‚Äî —Ü–µ —Å–µ—Ä—ñ—è —Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω–∏—Ö –º–æ–≤, –ø–æ–±—É–¥–æ–≤–∞–Ω–∏—Ö "
"–Ω–∞ –æ—Å–Ω–æ–≤—ñ LLM Qwen2, —è–∫—ñ –∑–Ω–∞—á–Ω–æ –ø–µ—Ä–µ–≤–µ—Ä—à—É—é—Ç—å –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ –º–æ–¥–µ–ª–µ–π "
"–∑ –≤—ñ–¥–∫—Ä–∏—Ç–∏–º –∫–æ–¥–æ–º —ñ –Ω–∞–≤—ñ—Ç—å –º–æ–¥–µ–ª–µ–π —ñ–∑ –∑–∞–∫—Ä–∏—Ç–∏–º –∫–æ–¥–æ–º (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, GPT4o)."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:105
#, kde-format
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr ""
"–ü–æ—Ç—É–∂–Ω–∞ –±–∞–≥–∞—Ç–æ–º–æ–≤–Ω–∞ –∑–∞–≥–∞–ª—å–Ω–∞ –º–æ–≤–Ω–∞ –º–æ–¥–µ–ª—å –∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—é –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—é "
"–ø–æ—Ä—ñ–≤–Ω—è–Ω–æ –∑ Llama 3."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:107
#, kde-format
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"table LM 2 ‚Äî —Ü–µ —Å—É—á–∞—Å–Ω–∞ –º–æ–≤–Ω–∞ –º–æ–¥–µ–ª—å —ñ–∑ 1,6B —Ç–∞ 12B –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –Ω–∞–≤—á–µ–Ω–∞ –Ω–∞ "
"–±–∞–≥–∞—Ç–æ–º–æ–≤–Ω–∏—Ö –¥–∞–Ω–∏—Ö –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—é, —ñ—Å–ø–∞–Ω—Å—å–∫–æ—é, –Ω—ñ–º–µ—Ü—å–∫–æ—é, —ñ—Ç–∞–ª—ñ–π—Å—å–∫–æ—é, "
"—Ñ—Ä–∞–Ω—Ü—É–∑—å–∫–æ—é, –ø–æ—Ä—Ç—É–≥–∞–ª—å—Å—å–∫–æ—é —Ç–∞ –≥–æ–ª–ª–∞–Ω–¥—Å—å–∫–æ—é –º–æ–≤–∞–º–∏."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:109
#, kde-format
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr ""
"BakLLaVA ‚Äî —Ü–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞ –º–æ–¥–µ–ª—å, —â–æ —Å–∫–ª–∞–¥–∞—î—Ç—å—Å—è –∑ –±–∞–∑–æ–≤–æ—ó –º–æ–¥–µ–ª—ñ Mistral "
"7B, –¥–æ–ø–æ–≤–Ω–µ–Ω–æ—ó –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–æ—é LLaVA."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:111
#, kde-format
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""
"–í–∏—Å–æ–∫–æ–ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–∞ –º–æ–¥–µ–ª—å, –Ω–∞–≤—á–µ–Ω–∞ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –Ω–æ–≤–æ—ó –º–µ—Ç–æ–¥–∏–∫–∏ –ø—ñ–¥ –Ω–∞–∑–≤–æ—é "
"Reflection-tuning, —è–∫–∞ –Ω–∞–≤—á–∞—î LLM –≤–∏—è–≤–ª—è—Ç–∏ –ø–æ–º–∏–ª–∫–∏ –≤ —Å–≤–æ—ó—Ö –º—ñ—Ä–∫—É–≤–∞–Ω–Ω—è—Ö —Ç–∞ "
"–≤–∏–ø—Ä–∞–≤–ª—è—Ç–∏ –∫—É—Ä—Å."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:113
#, kde-format
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr "–£–¥–æ—Å–∫–æ–Ω–∞–ª–µ–Ω–∞ –º–æ–≤–Ω–∞ –º–æ–¥–µ–ª—å, —Å—Ç–≤–æ—Ä–µ–Ω–∞ –∑ 2 —Ç—Ä–∏–ª—å–π–æ–Ω–∞–º–∏ –¥–≤–æ–º–æ–≤–Ω–∏—Ö —Ç–æ–∫–µ–Ω—ñ–≤."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:114
#, kde-format
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr ""
"–¶—è –º–æ–¥–µ–ª—å –∑–±—ñ–ª—å—à—É—î –¥–æ–≤–∂–∏–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É LLama-3 8B –∑ 8 —Ç–∏—Å—è—á –¥–æ –ø–æ–Ω–∞–¥ 1 "
"–º—ñ–ª—å–π–æ–Ω–∞ —Ç–æ–∫–µ–Ω—ñ–≤."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:115
#, kde-format
msgid "Model focused on math and logic problems"
msgstr "–ú–æ–¥–µ–ª—å, –æ—Ä—ñ—î–Ω—Ç–æ–≤–∞–Ω–∞ –Ω–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω—ñ —Ç–∞ –ª–æ–≥—ñ—á–Ω—ñ –∑–∞–¥–∞—á—ñ"

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:116
#, kde-format
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr ""
"moondream2 ‚Äî —Ü–µ –Ω–µ–≤–µ–ª–∏–∫–∞ –º–æ–¥–µ–ª—å –º–æ–≤–∏ –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è –≤—ñ–∑—É–∞–ª—å–Ω–æ–≥–æ –º–∏—Å–ª–µ–Ω–Ω—è, "
"—Ä–æ–∑—Ä–æ–±–ª–µ–Ω–∞ –¥–ª—è –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—ó —Ä–æ–±–æ—Ç–∏ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä—ñ–π–Ω–∏—Ö –ø—Ä–∏—Å—Ç—Ä–æ—è—Ö."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:117
#, kde-format
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr ""
"–¢–æ—á–Ω–æ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å –Ω–∞ –±–∞–∑—ñ Mistral –∑ –≥–∞—Ä–Ω–∏–º –æ—Ö–æ–ø–ª–µ–Ω–Ω—è–º –ø—Ä–µ–¥–º–µ—Ç–Ω–æ—ó "
"–æ–±–ª–∞—Å—Ç—ñ —Ç–∞ –º–æ–≤–∏."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:119
#, kde-format
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"–ú–æ–¥–µ–ª—å –≤—ñ–¥ NVIDIA –Ω–∞ –±–∞–∑—ñ Llama 3, —è–∫–∞ —á—É–¥–æ–≤–æ —Å–ø—Ä–∞–≤–ª—è—î—Ç—å—Å—è –∑ —Ä–æ–∑–º–æ–≤–Ω–∏–º–∏ "
"–ø–∏—Ç–∞–Ω–Ω—è–º–∏ —Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—î—é –¥–∞–Ω–∏—Ö –∑ –¥–æ–ø–æ–≤–Ω–µ–Ω–∏–º –ø–æ—à—É–∫–æ–º (RAG)."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:120
#, kde-format
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr ""
"–†–æ–∑–º–æ–≤–Ω–∞ –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤—ñ Llama 2, —è–∫–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä—É—î –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤ "
"—Ä—ñ–∑–Ω–∏—Ö —Ç–µ—Å—Ç–∞—Ö."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:121
#, kde-format
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr ""
"SQLCoder ‚Äî —Ü–µ –º–æ–¥–µ–ª—å –∞–≤—Ç–æ–¥–æ–ø–æ–≤–Ω–µ–Ω–Ω—è –∫–æ–¥—É, –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–∞ –Ω–∞ StarCoder –¥–ª—è "
"–∑–∞–≤–¥–∞–Ω—å –ø–æ—Ä–æ–¥–∂–µ–Ω–Ω—è –∫–æ–¥—É SQL."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:122
#, kde-format
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr ""
"–ú–æ–¥–µ–ª—ñ –∑–∞–≥–∞–ª—å–Ω–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ Llama —Ç–∞ Llama 2 –≤—ñ–¥ Nous Research."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:123
#, kde-format
msgid "Code generation model based on Code Llama."
msgstr "–ú–æ–¥–µ–ª—å –ø–æ—Ä–æ–¥–∂–µ–Ω–Ω—è –ø—Ä–æ–≥—Ä–∞–º–Ω–æ–≥–æ –∫–æ–¥—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ Code Llama."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:124
#, kde-format
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr ""
"–†–æ–∑—à–∏—Ä–µ–Ω–Ω—è Llama 2, —É —è–∫–æ–º—É –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–æ –ø—ñ–¥—Ç—Ä–∏–º–∫—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –¥–æ 128 —Ç–∏—Å—è—á "
"—Ç–æ–∫–µ–Ω—ñ–≤."

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:125
#, kde-format
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:126
#, kde-format
msgid "General use model based on Llama 2."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:127
#, kde-format
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:129
#, kde-format
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:130
#, kde-format
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:131
#, kde-format
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:133
#, kde-format
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:136
#, kde-format
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:137
#, kde-format
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:138
#, kde-format
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:139
#, kde-format
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:140
#, kde-format
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:142
#, kde-format
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:144
#, kde-format
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:145
#, kde-format
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:146
#, kde-format
msgid ""
"Mistral Small 3 sets a new benchmark in the ‚Äúsmall‚Äù Large Language Models "
"category below 70B."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:147
#, kde-format
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:148
#, kde-format
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:149
#, kde-format
msgid "Uncensored version of Wizard LM model"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:150
#, kde-format
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:151
#, kde-format
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:153
#, kde-format
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:155
#, kde-format
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:156
#, kde-format
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:158
#, kde-format
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:160
#, kde-format
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:162
#, kde-format
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:163
#, kde-format
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:164
#, kde-format
msgid "Great code generation model based on Llama2."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:165
#, kde-format
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:167
#, kde-format
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:170
#, kde-format
msgid ""
"Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:172
#, kde-format
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:173
#, kde-format
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:174
#, kde-format
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:175
#, kde-format
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:176
#, kde-format
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:177
#, kde-format
msgid ""
"MathŒ£tral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:178
#, kde-format
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:179
#, kde-format
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:181
#, kde-format
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:182
#, kde-format
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:183
#, kde-format
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:184
#, kde-format
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:186
#, kde-format
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:187
#, kde-format
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:189
#, kde-format
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:190
#, kde-format
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:191
#, kde-format
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:192
#, kde-format
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:194
#, kde-format
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:195
#, kde-format
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:197
#, kde-format
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:198
#, kde-format
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:200
#, kde-format
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:202
#, kde-format
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:204
#, kde-format
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:205
#, kde-format
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:206
#, kde-format
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:208
#, kde-format
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:210
#, kde-format
msgid ""
"T√ºlu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:212
#, kde-format
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:213
#, kde-format
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:215
#, kde-format
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:217
#, kde-format
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:219
#, kde-format
msgid ""
"A family of efficient AI models under 10B parameters performant in science, "
"math, and coding through innovative training techniques."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:221
#, kde-format
msgid ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM‚Äôs initial testing."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:224
#, kde-format
msgid ""
"The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:226
#, kde-format
msgid ""
"The IBM Granite Embedding 30M and 278M models models are text-only dense "
"biencoder embedding models, with 30M available in English only and 278M "
"serving multilingual use cases."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:228
#, kde-format
msgid "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:229
#, kde-format
msgid ""
"A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:231
#, kde-format
msgid ""
"Dolphin 3.0 Llama 3.1 8B üê¨ is the next generation of the Dolphin series of "
"instruct-tuned models designed to be the ultimate general purpose local "
"model, enabling coding, math, agentic, function calling, and general use "
"cases."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:234
#, kde-format
msgid ""
"DeepSeek's first-generation of reasoning models with comparable performance "
"to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on "
"Llama and Qwen."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:236
#, kde-format
msgid ""
"A strong Mixture-of-Experts (MoE) language model with 671B total parameters "
"with 37B activated for each token."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:238
#, kde-format
msgid ""
"OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. "
"These models are on par with or better than equivalently sized fully open "
"models, and competitive with open-weight models such as Llama 3.1 on English "
"academic benchmarks."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:241
#, kde-format
msgid ""
"The smallest model in Cohere's R series delivers top-tier speed, efficiency, "
"and quality to build powerful AI applications on commodity GPUs and edge "
"devices."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:243
#, kde-format
msgid ""
"A fully open-source family of reasoning models built using a dataset derived "
"by distilling DeepSeek-R1."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:245
#, kde-format
msgid ""
"A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the "
"performance of OpenAI‚Äôs o1-preview with just 1.5B parameters on popular math "
"evaluations."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:248
#, kde-format
msgid ""
"A version of the DeepSeek-R1 model that has been post trained to provide "
"unbiased, accurate, and factual information by Perplexity."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:249
#, kde-format
msgid "The current, most capable model that runs on a single GPU."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:251
#, kde-format
msgid ""
"Phi-4-mini brings significant enhancements in multilingual support, "
"reasoning, and mathematics, and now, the long-awaited function calling "
"feature is finally supported."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:254
#, kde-format
msgid ""
"A compact and efficient vision-language model, specifically designed for "
"visual document understanding, enabling automated content extraction from "
"tables, charts, infographics, plots, diagrams, and more."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:256
#, kde-format
msgid ""
"Granite-3.2 is a family of long-context AI models from IBM Granite fine-"
"tuned for thinking capabilities."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:258
#, kde-format
msgid ""
"A new state-of-the-art version of the lightweight Command R7B model that "
"excels in advanced Arabic language capabilities for enterprises in the "
"Middle East and Northern Africa."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:260
#, kde-format
msgid ""
"111 billion parameter model optimized for demanding enterprises that require "
"fast, secure, and high-quality AI"
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:262
#, kde-format
msgid ""
"EXAONE Deep exhibits superior capabilities in various reasoning tasks "
"including math and coding benchmarks, ranging from 2.4B to 32B parameters "
"developed and released by LG AI Research."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:265
#, kde-format
msgid ""
"Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-"
"art vision understanding and enhances long context capabilities up to 128k "
"tokens without compromising text performance."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:268
#, kde-format
msgid ""
"Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that "
"outperform the best available open models of the same size, including "
"counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:270
#, kde-format
msgid ""
"DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a "
"1.5B version also available."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:272
#, kde-format
msgid ""
"Qwen3 is the latest generation of large language models in Qwen series, "
"offering a comprehensive suite of dense and mixture-of-experts (MoE) models."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:274
#, kde-format
msgid "Meta's latest collection of multimodal models."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:276
#, kde-format
msgid ""
"IBM Granite 2B and 8B models are 128K context length language models that "
"have been fine-tuned for improved reasoning and instruction-following "
"capabilities."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:279
#, kde-format
msgid ""
"Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight "
"reasoning models that rival much larger models on complex reasoning tasks."
msgstr ""

#: plugins/ollama/modelsmanager/ollamamodelutils.cpp:282
#, kde-format
msgid ""
"Phi 4 mini reasoning is a lightweight open model that balances efficiency "
"with advanced reasoning ability."
msgstr ""

#: plugins/ollama/ollamacomboboxwidget.cpp:28
#, kde-format
msgctxt "@info:tooltip"
msgid "Reload Model"
msgstr "–ü–µ—Ä–µ–∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å"

#: plugins/ollama/ollamaconfiguredialog.cpp:25
#, kde-format
msgctxt "@title:window"
msgid "Configure Ollama"
msgstr "–ù–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏ Ollama"

#: plugins/ollama/ollamaconfigurewidget.cpp:38
#, kde-format
msgid "Server Url:"
msgstr "–ê–¥—Ä–µ—Å–∞ —Å–µ—Ä–≤–µ—Ä–∞:"

#: plugins/ollama/ollamaconfigurewidget.cpp:42
#, kde-format
msgid "Model:"
msgstr "–ú–æ–¥–µ–ª—å:"

#: plugins/ollama/ollamaconfigurewidget.cpp:45
#, kde-format
msgid "Prompt:"
msgstr "–ó–∞–ø–∏—Ç:"

#: plugins/ollama/ollamaconfigurewidget.cpp:46
#, kde-format
msgid "No system prompt"
msgstr "–ù–µ–º–∞—î –∑–∞–ø–∏—Ç—É —Å–∏—Å—Ç–µ–º–∏"

#: plugins/openai/openaiclient.cpp:27
#, kde-format
msgid "OpenAI"
msgstr "OpenAI"

#: plugins/openai/openaiconfiguredialog.cpp:25
#, kde-format
msgctxt "@title:window"
msgid "Configure Openai IA"
msgstr "–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –®–Ü Openai"

#: widgets/menu/textautogeneratemenuconfiguredialog.cpp:24
#, kde-format
msgctxt "@title:window"
msgid "Configure AI text plugins"
msgstr "–ù–∞–ª–∞—à—Ç–æ–≤—É–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –¥–æ–¥–∞—Ç–∫—ñ–≤ –®–Ü"

#: widgets/menu/textautogeneratemenulistview.cpp:41
#, kde-format
msgctxt "@action"
msgid "Add‚Ä¶"
msgstr "–î–æ–¥–∞—Ç–∏‚Ä¶"

#: widgets/menu/textautogeneratemenulistview.cpp:44
#, kde-format
msgid "Ask to AI"
msgstr "–ó–∞–ø–∏—Ç–∞—Ç–∏ —É –®–Ü"

#: widgets/menu/textautogeneratemenulistview.cpp:50
#: widgets/view/textautogeneratehistorylistview.cpp:114
#, kde-format
msgctxt "@action"
msgid "Modify‚Ä¶"
msgstr "–ó–º—ñ–Ω–∏—Ç–∏‚Ä¶"

#: widgets/menu/textautogeneratemenulistview.cpp:57
#: widgets/view/textautogeneratehistorylistview.cpp:151
#, kde-format
msgctxt "@action"
msgid "Remove‚Ä¶"
msgstr "–í–∏–ª—É—á–∏—Ç–∏‚Ä¶"

#: widgets/menu/textautogeneratemenulistview.cpp:60
#, kde-format
msgid "Do you want to remove it?"
msgstr "–•–æ—á–µ—Ç–µ –≤–∏–ª—É—á–∏—Ç–∏ –π–æ–≥–æ?"

#: widgets/menu/textautogeneratemenulistview.cpp:61
#, kde-format
msgctxt "@title"
msgid "Remove"
msgstr "–í–∏–ª—É—á–∏—Ç–∏"

#: widgets/menu/textautogeneratemenuwidget.cpp:22
#, kde-format
msgid "Ask AI‚Ä¶"
msgstr "–ó–∞–ø–∏—Ç–∞—Ç–∏ —É –®–Ü‚Ä¶"

#: widgets/menu/textautogeneratemenuwidget.cpp:49
#, kde-format
msgctxt "@action"
msgid "Configure‚Ä¶"
msgstr "–ù–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏‚Ä¶"

#: widgets/textautogenerateconfiguredialog.cpp:19
#, kde-format
msgctxt "@title:window"
msgid "Configure IA"
msgstr "–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –®–Ü"

#: widgets/textautogenerateconfigurewidget.cpp:27
#, kde-format
msgid "Engine:"
msgstr "–†—É—à—ñ–π:"

#: widgets/textautogeneratedialog.cpp:30
#, kde-format
msgctxt "@title:window"
msgid "Conversation"
msgstr "–°–ø—ñ–ª–∫—É–≤–∞–Ω–Ω—è"

#: widgets/textautogenerateheaderwidget.cpp:37
#, kde-format
msgctxt "@info:tooltip"
msgid "Configure‚Ä¶"
msgstr "–ù–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏‚Ä¶"

#: widgets/textautogenerateheaderwidget.cpp:45
#, kde-format
msgctxt "@info:tooltip"
msgid "Search‚Ä¶"
msgstr "–®—É–∫–∞—Ç–∏‚Ä¶"

#: widgets/textautogenerateheaderwidget.cpp:52
#, kde-format
msgctxt "@info:tooltip"
msgid "New Chat"
msgstr "–ù–æ–≤–µ —Å–ø—ñ–ª–∫—É–≤–∞–Ω–Ω—è"

#: widgets/textautogenerateheaderwidget.cpp:59
#, kde-format
msgctxt "@info:tooltip"
msgid "Favorite"
msgstr "–£–ª—é–±–ª–µ–Ω–µ"

#: widgets/textautogeneratehistorywidget.cpp:27
#: widgets/textautogeneratesearchwidget.cpp:30
#, kde-format
msgctxt "@info:placeholder"
msgid "Search‚Ä¶"
msgstr "–®—É–∫–∞—Ç–∏‚Ä¶"

#: widgets/textautogeneratenotworkingwidget.cpp:29
#, kde-format
msgid "Configure‚Ä¶"
msgstr "–ù–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏‚Ä¶"

#: widgets/textautogeneratesearchdialog.cpp:26
#, kde-format
msgctxt "@title:window"
msgid "Search"
msgstr "–ü–æ—à—É–∫"

#: widgets/textautogeneratetextlineedit.cpp:16
#, kde-format
msgctxt "@info:placeholder"
msgid "Enter a message"
msgstr "–í–≤–µ–¥—ñ—Ç—å –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è"

#: widgets/textautogeneratetextlineeditwidget.cpp:17
#, kde-format
msgid "Send"
msgstr "–ù–∞–¥—ñ—Å–ª–∞—Ç–∏"

#: widgets/textautogeneratewidget.cpp:94
#, kde-format
msgid "No plugin found."
msgstr "–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –¥–æ–¥–∞—Ç–∫–∞."

#: widgets/view/textautogeneratehistorylistview.cpp:103
#, kde-format
msgctxt "@action"
msgid "New Chat"
msgstr "–ù–æ–≤–µ —Å–ø—ñ–ª–∫—É–≤–∞–Ω–Ω—è"

#: widgets/view/textautogeneratehistorylistview.cpp:127
#, kde-format
msgctxt "@action"
msgid "Remove as Favorite"
msgstr "–í–∏–ª—É—á–∏—Ç–∏ –∑ —É–ª—é–±–ª–µ–Ω–∏—Ö"

#: widgets/view/textautogeneratehistorylistview.cpp:127
#, kde-format
msgctxt "@action"
msgid "Set as Favorite"
msgstr "–ó—Ä–æ–±–∏—Ç–∏ —É–ª—é–±–ª–µ–Ω–∏–º"

#: widgets/view/textautogeneratehistorylistview.cpp:140
#, kde-format
msgctxt "@action"
msgid "Restore"
msgstr "–í—ñ–¥–Ω–æ–≤–∏—Ç–∏"

#: widgets/view/textautogeneratehistorylistview.cpp:140
#, kde-format
msgctxt "@action"
msgid "Archive"
msgstr "–ê—Ä—Ö—ñ–≤—É–≤–∞—Ç–∏"

#: widgets/view/textautogeneratehistorylistview.cpp:155
#, kde-format
msgid "Do you want to remove this discussion?"
msgstr "–•–æ—á–µ—Ç–µ –≤–∏–ª—É—á–∏—Ç–∏ —Ü–µ –æ–±–≥–æ–≤–æ—Ä–µ–Ω–Ω—è?"

#: widgets/view/textautogeneratehistorylistview.cpp:156
#, kde-format
msgctxt "@title:window"
msgid "Remove Discussion"
msgstr "–í–∏–ª—É—á–µ–Ω–Ω—è –æ–±–≥–æ–≤–æ—Ä–µ–Ω–Ω—è"

#: widgets/view/textautogeneratelistview.cpp:89
#, kde-format
msgctxt "@action"
msgid "Copy Selection"
msgstr "–ö–æ–ø—ñ—é–≤–∞—Ç–∏ –ø–æ–∑–Ω–∞—á–µ–Ω–µ"

#: widgets/view/textautogeneratelistview.cpp:89
#, kde-format
msgctxt "@action"
msgid "Copy"
msgstr "–ö–æ–ø—ñ—é–≤–∞—Ç–∏"

#: widgets/view/textautogeneratelistview.cpp:97
#, kde-format
msgctxt "@action"
msgid "Select All"
msgstr "–ü–æ–∑–Ω–∞—á–∏—Ç–∏ –≤—Å–µ"

#: widgets/view/textautogeneratelistviewdelegate.cpp:369
#, kde-format
msgctxt "@info:tooltip"
msgid "Edit..."
msgstr "–ó–º—ñ–Ω–∏—Ç–∏‚Ä¶"

#: widgets/view/textautogeneratelistviewdelegate.cpp:373
#, kde-format
msgctxt "@info:tooltip"
msgid "Copy"
msgstr "–ö–æ–ø—ñ—é–≤–∞—Ç–∏"

#: widgets/view/textautogeneratelistviewdelegate.cpp:377
#, kde-format
msgctxt "@info:tooltip"
msgid "Cancel"
msgstr "–°–∫–∞—Å—É–≤–∞—Ç–∏"

#: widgets/view/textautogeneratelistviewdelegate.cpp:381
#, kde-format
msgctxt "@info:tooltip"
msgid "Refresh"
msgstr "–û–Ω–æ–≤–∏—Ç–∏"

#~ msgctxt "@action"
#~ msgid "New Chat‚Ä¶"
#~ msgstr "–ù–æ–≤–µ —Å–ø—ñ–ª–∫—É–≤–∞–Ω–Ω—è‚Ä¶"

#~| msgid "Favorite"
#~ msgctxt "@action"
#~ msgid "Favorite‚Ä¶"
#~ msgstr "–î–æ–¥–∞—Ç–∏ –¥–æ —É–ª—é–±–ª–µ–Ω–∏—Ö‚Ä¶"

#~ msgctxt "@info:tooltip"
#~ msgid "Clear"
#~ msgstr "–°–ø–æ—Ä–æ–∂–Ω–∏—Ç–∏"
